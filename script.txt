in this course I'm going to take you from a complete beginner to building powerful noode AI agents i don't have any coding experience and you don't need any either in the past eight months I've made over half a million dollars in revenue by building and teaching people how to build AI agents in this video together we're going to set up your 2e free and end trial we're going to set up credentials together and walk through step-by-step builds and by the end you'll have over 15 AI automations ready to take advantage of this opportunity all right so here is a quick look at the highle course agenda keep in mind everything will be timestamped below so you can jump around to where you need but I definitely recommend saving this for later as you can see this is extremely comprehensive packed with a ton of value so you can come back to this later when you want to explore different chapters but what we're going to do is start off with talking about AI agents and the opportunity that we are all living in right now then we'll move into Foundations i'll set up a free twoe trial with you guys i will talk about the UI we'll get familiar with it and go over some foundational knowledge you'll need from there we'll move into step-by-step workflows where we're actually using that knowledge and connecting to different integrations and setting up some pretty cool automations right away then we'll talk about APIs and HTTP request we'll set up a few common examples together and you'll see it's not that difficult then moving into the back half of the course we'll talk about AI agent tools and memory we will discuss multi-agent architectures i'll talk about prompting do a live example and some other cool tips that I want to share with you guys that could be helpful we will look at web hooks what those really mean and then we'll look at a few example workflows where we've triggered them with web hooks i'll talk about MCP servers what that really is and we'll do a step-by-step self-hosted setup of Naden and connect to some MCP servers and finally we'll close off with lessons from my first 6 months of building AI agents so if that all sounds good to you guys let's go ahead and get started all right so AI agents artificial intelligence whatever it is there is definitely a lot of hype there's no denying that and so the purpose of this section is just to make sure we can cut through all of that and actually understand what is an AI agent at its core what can they do and why do we need them you probably heard you know digital employee or virtual assistant all this kind of stuff but we need to understand what that actually means and what powers them so at this point I'm sure we are all familiar with something like chatbt which is a large language model at its core and so we're looking at right here is a very simple visualization of how a large language model works meaning right here in green we have a large language model let's say it's chatbt and we the user give it some sort of input so maybe that's like hey help me write an email to John the LLM would then take our input process this it would basically just create an email for us and then it would spit that out as an output and that's it this LLM at its core cannot take any action it's really not that practical it just kind of helps you be more productive because at the end of the process we'd have to take this output and copy and paste it into something that actually can take action like Gmail and so the power of these large language models really comes into play when we start to expose them to different tools and tools just means any of these integrations that we use every single day within our work that let us actually do something so whether that's send an email or update a row in our CRM or look at a database or Air Table whatever it is even Outlook that's a tool it just means connecting to an actual platform that we use to do something so now instead of having the LLM help us write an email that we would copy and paste or us exporting a Google sheet and giving it to an LLM to analyze it can basically just interact with any of its tools that we give it access to so when we add an LLM to tools we basically can get two different things and that is either an AI workflow or an AI agent so right away you can already tell what the difference is but you can also see some similarities so let's break it down starting with an AI workflow we can see that we have an input similar to like we did up top with our LLM but now instead of just going input LLM output we can work in those tools right into the actual AI workflow itself so here is an example of what an AI workflow could practically look like first of all we have a tool which is HubSpot and that's going to be the input for this workflow this will basically pass over a new lead that has been inserted into our CRM then we're hitting another tool which is Perplexity which helps us do research so we're going to do research on that lead from there after we get that research we're going to hit an LLM which is where this whole AI powered workflow terminology comes in because we're using that LLM to then take the research draft a personalized email and then it can use another tool to actually send that email and the reason that we do this as a workflow is because this is going to happen in the same four steps in that order every time new lead comes in research write the personalized email send the email and so whenever we know a process is linear or sequential or it's going to follow that order every time it's much much better to do an actual workflow rather than send that off to an AI agent where we have an input we have the LLM which is the AI agent this is the brain of the whole operation and it has access to all of the different tools it can use and then it has an output so yes it is true that this AI agent down here could do the exact same job as this AI workflow we could also over here with an AI agent get a new form and have a new row in our CRM the agent could then think about it and decide okay I'm going to use perplexity to do research and then after that I'm going to send an email with my email tool but it's not the most effective way to do it because it's going to be more expensive it's going to be slower and it's going to be more errorprone so basically the whole idea is AI agents can make decisions and act autonomously based on different inputs ai workflows follow the guardrails that we put in place there's no way they can deviate off the path that we chose for them so a big part of building effective systems is understanding okay do I need to build an AI workflow or am I going to build an AI agent is this process deterministic or nondeterministic or in other words is it predictable or is it unpredictable if something's unpredictable that's when we're going to use an AI agent with a brain and with different tools to actually do the job and that's where the whole autonomy comes into play and I don't want to dive too deep into the weeds of this right now we'll cover this later in a different section but real quick four main pros of AI workflows over AI agents reliability and consistency cost efficiency easier debugging and maintenance and scalability once again we have a whole section dedicated to this idea and we're going to dive into it after we've built out a few AI workflows but I wanted you guys to understand this because obviously the whole purpose you probably came here was to learn how to build AI agents but before we build AI agents we're going to learn how to build AI workflows it's the whole concept of crawl walk run you wouldn't just start running right away and trust me after you've built out a few AI workflows it's going to make a lot more sense when you hop into building some more complex agentic systems but just to give you that quick fix of AI agent knowledge and we'll revisit this later when we actually build our first agent together what is the anatomy of an AI agent what are the different parts that make one up so here's a simple diagram that I think illustrates AI agents as simple as possible we have an input we have our LLM and we have our output like we talked about earlier but then inside the AI agent you can see two main things we have a brain and we have instructions so the first thing is a brain this comes in the form of a large language model and also memory so first off the large language model this is an AI chat model that we'll choose whether that's an open AI model or an anthropic model or a Google model this is going to be what powers the AI agent to make decisions to reason to generate outputs that sort of stuff and then we also have the memory so this can come in the form of long-term memory as well as short-term memory but basically we want to make sure that if we're conversating with our agent it's not going to forget what we're talking about after every single sentence it's going to retain that context window and it can also remember things that we talked about a while back and then the other piece is the instructions for the AI agent which is also kind of referred to as a system prompt and this is really important because this is telling this AI agent you know here's your role here's what you do here are the tools you have this is basically like your job description so the same way you wouldn't expect a new hire to hop into the company and just start using its different tools and knowing what to do you would have to give it basically some pretty specific training on this is basically your end goal here are the tools you have and here's when you use each one to get the job done and the system prompt is different than the input which is kind of referred to as a user prompt and think of it like this when you're talking to chatbt in your browser and every single message that you're typing and sending off to it is a user message because that input changes every time it's dynamic but the system prompt is typically going to say the same over the course of this agent's life unless its role or actual instructions are going to change but anyways let's say the input is hey can you help me send an email to John what's going to happen is the agent's going to use its brain to understand the input it's going to check its memory to see if there's any other interactions that would help with this current input then it will look at its instructions and see okay how do I actually send an email to John and then it will call on its tool to actually send an email so at a high level that is the anatomy of an AI agent and I hope that that helps paint a clear picture in your mind cool so now that we've talked about what an AI agent is and what a workflow is and why we want to walk before we run let's actually get into Naden and start building some stuff all right right so before we dive into actually building AI agents I want to share some eyeopening research that underscores exactly why you're making such a valuable investment in yourself today this research report that I'm going to be walking through real quick will be available for free in my school community if you want to go ahead and take a look at it it's got a total of 48 sources that are all from within the past year so you know it's real you know it's relevant and it was completely generated for me using Perplexity which is an awesome AI tool so just a year ago AI was still considered experimental technology for most businesses now it's become the core driver of competitive advantage across every industry and business size what we're witnessing isn't just another tech trend it's a fundamental business transformation let me start with something that might surprise you 75% of small businesses now use AI tools that's right this isn't just enterprise technology anymore in fact the adoption rates are climbing fastest among companies generating just over a million dollars in revenue at 86% what's truly remarkable is the investment threshold the median annual AI investment for small businesses is just 1,800 that's less than 150 bucks per month to access technology that was science fiction just a few years ago now I know some of you might be skeptical about AI's practical value let's look at concrete outcomes businesses are achieving marketing teams are seeing a 22% increase in ROI for AIdriven campaigns customer service AI agents have reduced response time by 60% while resolving 80% of inquiries without human intervention supply chains optimized with AI have cut transportation costs by 5 to 10% through better routing and demand forecasting these are actual measured results from implementations over the past year now for those of you from small organizations consider these examples henry's House of Coffee used AIdriven SEO tools to improve their product descriptions resulting in a 200% improvement in search rankings and 25% revenue increase vanisec insurance implemented custom chat bots that cut client query resolution time from 48 hours to just 15 minutes small businesses using Zapier automations saved 10 to 15 hours weekly on routine data entry and CRM updates what's revolutionary here is that none of these companies needed to hire AI specialists or data scientists to achieve these results the economic case for AI skills is compelling 54% of small and medium businesses plan to increase AI spending this year 83% of enterprises now prioritize AI literacy in their hiring decisions organizations with AI trained teams are seeing 5 to 8% higher profitability than their peers but perhaps most telling is this small businesses using AI report 91% higher revenue growth than nonAI adopters that gap is only widening so the opportunity ahead the truth is mastering AI is no longer optional it's becoming the price of entry for modern business competitiveness those who delay risk irrelevance while early adopters are already reaping the benefits of efficiency innovation and market share gains now the good news is that we're still in the early stages by developing these skills now you're positioning yourself at the forefront of this transformation and going to be in extremely high demand over the next decade so let's get started building your first AI agent all right so here we are on Naden's website you can get here using the link in the description and what I'm going to do is go ahead and sign up for a free trial with you guys and this is exactly the process you're going to take and you're going to get two weeks of free playing around and like I said by the end of those two weeks you're already going to have automations up and running and tons of templates imported into your workflows and I'm not going to spend too much time here but basically Nitn just lets you automate anything any business process that you have you can automate it visually with no code which is why I love it so here you can see NIDN lets you automate business processes without limits on your logic it's a very visual builder we have a ton of different integrations we have the ability to use code if you want to lots of native nodes to do data transformation and we have tons of different triggers tons of different AI nodes and we're going to dive into this so you can understand what's all going on but there's also hundreds of templates to get you started not only on the end website itself but also in my free school community i have almost 100 templates in there that you can plug in right away anyways let's scroll back up to the top and let's get started here with a new account all right all right so I put in my name my email password and I give my account a name which will basically be up in the top search bar it'll be like nate herkdemo.app.n.cloud so that's what your account name means and you can see I'm going to go ahead and start our 14-day free trial just have to do some quick little onboarding so it asks us what type of team are we on i'm just going to put product and design it asks us the size of our company it's going to ask us which of these things do we feel most comfortable doing these are all pretty technical i just want to put none of them and that's fine and how did you hear about any let's go ahead with YouTube and submit that off and now you have the option to invite other members to your workspace if you want to collaborate and share some credentials for now I'm just going to go ahead and skip that option so from here our workspace is already ready there's a little quick start guide you could watch from Eniden's YouTube channel but I'm just going to go ahead and click on start automating all right so here we are this is what Eniden looks like and let's just familiarize with this dashboard a little bit real quick so up in the top left we can see we have 14 days left in our free trial and we've used zero out of a,000 executions an execution just basically means when you run a workflow from end to end that's going to be an execution so we can see on the lefth hand side we have overview we have like a personal set of projects we have things that have been shared with us we have the ability to add a project we have the ability to go to our admin panel where we can upgrade our instance of nodn we can turn it off that sort of stuff so here's my admin panel you can see how many executions I have how many active workflows I have which I'll explain what that means later we have the ability to go ahead and manage our nen versions and this is where you could kind of upgrade your plan and change your billing information stuff like that but you'll notice that I didn't even have to put any billing details to get started with my twoe free trial but then if I want to get back into my workspace I'm just going to click on open right here and that will send us right back into this dashboard that we were just on cool so right here we can see we can either start from scratch a new workflow or we can test a simple AI agent example so let's just click into here real quick and break down what is actually going on here so in order for us to actually access this demo where we're going to just talk to this AI agent it says that we have to start by saying hi so there's an open chat button down here i'm going to click on open chat and I'm just going to type in here hi and what happens is our AI agent fails because this is basically the brain that it needs to use in order to think about our message and respond to us and what happens is we can see there's an error message so because these things are red I can click into it and I can see what is the error it says error in subnode OpenAI model so that would be this node down here which is called OpenAI model i would click into this node and we can basically see that the error is there is no credentials so when you're in NADN what happens is in order to access any sort of API which we'll talk about later but in order to access something like your Gmail or OpenAI or your CRM you always need to import some sort of credential which is just a fancy word for a password in order to actually like get into that information so right here we can see there's 100 free credits from OpenAI i'm going to click on claim credits and now we just are using our NEN free OpenAI API credits and we're fine on this front but don't worry later in this video I'm going to cover how we can actually go to OpenAI and get an API key and create our own password in here but for now we've claimed 100 free credits which is great and what I'm going to do is just go ahead and resend this message that says hi so I can actually go to this hi text and I can just click on this button which says repost message and that's just going to send it off again and now our agent's going to actually be able to use its brain and respond to us so what it says here is welcome to NINDN let's start with the first step to give me memory click the plus button on the agent that says memory and choose simple memory just tell me once you've done that so sure why not let's click on the plus button under memory and we'll click on simple memory real quick and we're already set up good to go so now I'm just going to come down here and say done now we can see that our agent was able to use its memory and its brain in order to respond to us so now it can prompt us to add tools it can do this other stuff but we're going to break that down later in this video just wanted to show you real quick demo of how this works so what I would do is up in the top right I can click on save just to make sure that the what we've done is actually going to be saved and then to get back out to the main screen I'm going to click on either overview or personal but if I click on overview that just takes us back to that home screen but now let's talk about some other stuff that happens in a workflow so up in the top right I'm going to click on create workflow you can see now this opens up a new blank page and then you have the option up here in the top left to name it so I'm just going to call this one demo now we have this new workflow that's saved in our N environment called demo so a couple things before we actually drag in any nodes is up here you can see where is this saved if you have different projects you can save workflows in those projects if you want to tag them you can tag different things like if you have one for customer support or you have stuff for marketing you can give your workflows different tags just to keep everything organized but anyways every single workflow has to start off with some sort of trigger so when I click on add first step it opens up this panel on the right that says what triggers this workflow so we can have a manual trigger we can have a certain event like a new message in Telegram or a new row in our CRM we can have a schedule meaning we can set this to run at 6 a.m every single day we can have a web hook call form submission chat message like we saw earlier there's tons of ways to actually trigger a workflow so for this example let's just say I'm going to click on trigger manually which literally just gives us this button where if we click test workflow it goes ahead and executes cool so this is a workflow and this is a node but this is a trigger node what happens after a trigger node is different types of nodes whether that's like an action node or a data transformation node or an AI node some sort of node so what I would do is if I want to link up a node to this trigger I would click on the plus button right here and this pulls up a little panel on the right that says what happens next do you want to take action with AI do you want to take action within a certain app do you want to do data transformation there's all these other different types of nodes and what's cool is let's say we wanted to take action within an app if I clicked on this we can see all of the different native integrations that Nin has and once again in order to connect to any of these tons of different tools that we have here you always need to get some sort of password so let's say Google Drive now that I've clicked into Google Drive there's tons of different actions that we can take and they're all very intuitive you know would you want to copy a file would you want to share a file do you want to create a shared drive it's all very natural language and let's say for example I want to copy a file in order for nitn to tell Google drive which file do we want to copy we first of all have to provide a credential so every app you'll have to provide some sort of credential and then you have basically like a configuration panel right here in the middle which would be saying what is the resource you want what do you want to do what is the file all this kind of stuff so whenever you're in a node in nen what you're going to have is on the left you have an input panel which is basically any data that's going to be feeding into this current node in the middle you'll have your configuration which is like the different settings and the different little levers you can tweak in order to do different things and then on the right is going to be the output panel of what actually comes out of this node based on the way that you configured it so every time you're looking at a node you're going to have three main places input configuration and output so let's just do a quick example where I'm going to delete this Google Drive node by clicking on the delete button i'm going to add an AI node because there's a ton of different AI actions we can take as well and all I'm going to do is I'm just going to talk to OpenAI's kind of like chatbt so I'll click on that and I'm just going to click on message a model so once that pulls up we're going to be using our NEN free OpenAI credits that we got earlier and as you can see we have to configure this node what do we want to do the resource is going to be text it could be image audio assistant whatever we want the operation we're taking is we want to just message a model and then of course because we're messaging a model we have to choose from this list of OpenAI models that we have access to and actually it looks like this N free credits only actually give us access to a chat model and this is a bit different not exactly sure why probably just because they're free credits so what we're going to do real quick is head over to OpenAI and get a credential so I can just show you guys how this works with input configuration and output so basically you'd go to openai.com you'd come in here and you'd create an account if you don't already have one if you have a chat GBT account and you're on like maybe the 20 bucks a month plan that is different than creating an OpenAI API account so you'd come in here and create an OpenAI account as you see up here we have the option for Chatbt login or API platform login which is what we're looking for here so now that you've created an account with OpenAI's API what you're going to do is come up to your dashboard and you're going to go to your API keys and then all you'd have to do is click on create new key name this one whatever you want and then you have a new secret key but keep in mind in order for this key to work you have to have put in some billing information in your OpenAI account so throw in a few bucks they'll go a lot longer than you may think and then you're going to take that key that we just copied come back into Nitn and under the credential section we're going to click on create new credential all I had to do now was paste in that API key right there and then you have the option to name this credential if you have a ton of different ones so I can just say you know like demo on May 21st and now I have my credential saved and named because now we can tell the difference between our demo credential and our NAN free OpenAI credits credential and now hopefully we have the ability to actually choose a model from the list so as you can see we can access chat GBT for latest 3.5 Turbo 4 4.1 mini all this kind of stuff i'm going to choose 4.1 mini but as you can see you can come back and change this whenever you want and I'm going to keep this really simple in the prompt I'm just going to type in tell me a joke so now when this node executes it's basically just going to be sending this message to OpenAI's model which is GBT4.1 Mini and it's just going to say "Tell me a joke." And then what we're going to get on the output panel is the actual joke so what I can do is come up right here and click on test step this is going to run this node and then we get an output over here and as you can see both with the input and the output we have three options of how we want to view our data we can click on schema we can click on table or we can click on JSON and this is all the exact same data it's just like a different way to actually look at it i typically like to look at schema i think it just looks the most simple and natural language but what you can see here is the message that we got back from this open AAI model was sure here's a joke for you why don't scientists trust atoms because they make up everything and what's cool about schemas is that this is all drag and drop so now once we have this output we could basically just use it however we want so if I click out of here and I open up another node after this and for now I'm just going to grab a set node just to show you guys how we can drag and drop what I would do is let's say we wanted to add a new field and I'm just going to call this open AI's response so we're creating a field called open AI's response and as you can see it says drag an input field from the left to use it here so as we know every node we have input configuration output on the input we can basically choose which one of these things do we want to use i just want to reference this content which is the actual thing that OpenAI said to us so I would drag this from here right into the value and now we can see that we have what's called a variable so anything that's going to be wrapped in these two curly braces and it's going to be green is a variable and it's coming through as JSON message.content which is basically just something that represents whatever is coming from the previous node in the field called content so we can see right here JSON message.content we have message within message we have basically a subfolder called content and that's where we access this actual result this real text and you can see if I click into this variable if I make it full screen we have an expression which is our JSON variable and then we have our result which is the actual text that we want back so now if I go ahead and test this step we can see that we only get output to us OpenAI's response which is the text we want okay so this would basically be a workflow because we have a trigger and then we have our nodes that are going to execute when we hit test workflow so if I hit test workflow it's going to run the whole thing and as you can see super visual we saw that OpenAI was thinking and then we come over here and we get our final output which was the actual joke and now let me show you one more example of how we can map our different variables without using a manual trigger so let's say we don't want a manual trigger i'm just going to delete that but now we have no way to run this workflow because there's no sort of trigger so I'm just going to come back in here and grab a chat trigger just so we can talk to this workflow in Naden i'm going to hook it up right here i would just basically drag this plus into the node that I want so I just drag it into OpenAI and now these two things are connected so if I went into the chat and I said hello it's going to run the whole workflow but it's not really going to make sense because I said hello and now it's telling me a joke about why don't scientists trust atoms so what I would want to do is I'd want to come into this OpenAI node right here and I'm just going to change the actual prompt so rather than asking it to tell me a joke what I would do is I'd just delete this and what I want to do is I want OpenAI to go ahead and process whatever I type in this chat same way it would work if we were in chatbt in our browser and whatever we type OpenAI responds to so all I would have to do to do that is I would grab the chat input variable right here i would drag that into the prompt section and now if I open this up it's looking at the expression called JSON.input because this field right here is called chat input and then the result is going to be whatever we type anytime even if it's different 100 times in a row it's always going to come back as a result that's different but it's always going to be referenced as the same exact expression so just to actually show you guys this let's save this workflow and I'm going to say "My name is Nate i like to eat ice cream make up a funny story about me." Okay so we'll send this off and the response that we should get will be one that is actually about me and it's going to have some sort of element of a story with ice cream so let's take a look so it said "Sure Nate here's a funny story for you." And actually because we're setting it it's coming through a little weird so let's actually click into here to look at it okay so here is the story let me just make this a little bigger i can go ahead and drag the configuration panel around by doing this i can also make it larger or smaller if I do this so let's just make it small we'll move it all the way to the left and let's read the story so it said "Sure Nate here's a funny story just for you once upon a time there was a guy named Nate who loved ice cream more than anything else in the world one day Nate decided to invent the ultimate ice cream a flavor so amazing that it would make the entire town go crazy." So let's skip ahead to the bottom basically what happens is from that day on Nate's stand became the funniest spot in town a place where you never knew if you'd get a sweet savory or plain silly ice cream and Nate he became the legendary ice cream wizard that sounds awesome so that's exactly how you guys can see what happened was in this OpenAI node we have a dynamic input which was us talking to this thing in a chat trigger we drag in that variable that represents what we type into the user prompt and this is going to get sent to OpenAI's model of GPT 4.1 Mini because we configured this node to do so and the reason we were able to actually successfully do that is because we put in our API key or our password for OpenAI and then on the right we get this output which we can look at either in schema view table view or JSON view but they all represent the same data as you can see this is the exact story we just read something I wanted to talk about real quick that is going to be super helpful for the rest of this course is just understanding what is JSON and JSON stands for JavaScript object notation and it's just a way to identify things and the reason why it's so important to talk about is because over here right we all kind of know what schema is it's just kind of like the way something's broken down and as you can see we have different drill downs over here and we have different things to reference then we all understand what a table is it's kind of like a table view of different objects with different things within them kind of like the subfolders and once again you can also drag and drop from table view as well and then we have JSON which also you can drag and drop don't worry you can drag and drop pretty much this whole platform which is why it's awesome but this may look a little more cody or intimidating but I want to talk about why it is not so first of all JSON is so so important because everything that we do is pretty much going to be built on top of JSON even the workflows that you're going to download later when you'll see like hey you can download this template for free when you download that it's going to be a JSON file which means the whole workflow in NN is basically represented as JSON and so hopefully that doesn't confuse you guys but what it is is it's literally just key value pairs so what I mean by that is like over here the key is index and index equals zero and then we have like the role of the openi assistant and that's the key and the value of the role is assistant so it's very very natural language if you really break it down what is the content that we're looking at the content that we're looking at is this actual content over here but like I said the great thing about that is that pretty much every single large language model or like chat gbt cloud 3.5 they're all trained on JSON and they all understand it so well because it's universal so right here on the left we're looking at JSON if I was to just copy this entire JSON go into ChatgBT and say "Hey help me understand this JSON." And then I just basically pasted that in there it's going to be able to tell us exactly like which keys are in here and what those values are so it says this JSON represents the response from an AI model like chatbt in a structured format let me break it down for you so basically it's going to explain what each part of this JSON means we can see the index is zero that means it's the first response we can see the role equals assistant we can see that the content is the funny story about Nate we can see all this stuff and it basically is able to not only break it down for us but let's say we need to make JSON we could say "Hey I have this natural language can you make that into JSON for me?" Hey can you help me make a JSON body where my name is Nate i'm 23 years old i went to the University of Iowa i like to play pickle ball we'll send that off and basically it will be able to turn that into JSON for us so here you go we can see name Nate age 23 education University of Iowa interest pickle ball and so don't let it overwhelm you if you ever need help either making JSON or understanding JSON throw it into chat and it will do a phenomenal job for you and actually just to show you guys that I'm not lying let's just copy this JSON that chat gave us go back into our workflow and I'm just going to add a set field just to show you guys and instead of manual mapping I'm just going to set some data using JSON so I'm going to delete this paste in exactly what chat gave me hit test step and what do we see over here we see the name of someone named Nate we see their age we see their education and we see their interest in either schema table or JSON view so hopefully that gives you guys some reassurance and just once again JSON's super important and it's not even code that is just a really quick foundational understanding of a trigger different nodes action nodes AI nodes you have a ton to play with and that's kind of like the whole most overwhelming part about NIN is you know what you need to do in your brain but you don't know maybe which is the best nen node to actually get that job done so that's kind of the tough part is it's a lot of just getting the reps in understanding what node is best for what but I assure you by the time your twoe trial is up you'll have mastered pretty much all that all right but something else I want to show you guys is now what we're looking at is called the editor so if you look at the top middle right here we have an editor and this is where we can you know zoom out we can move around we can basically edit our workflow right here and it moves from left to right as you guys saw the same way we we read from left to right and now because we've done a few runs and we've tested out these different nodes what we'll click into is executions and this will basically show us the different times we've ran this workflow and what's cool about this is it will show us the data that has moved through so let's say you set up a workflow that every time you get an email it's going to send some sort of automated response you could come into this workflow you could click on executions and you could go look at what time they happened what actually came through what email was sent all that kind of stuff so if I go all the way down to this third execution we can remember that what I did earlier was I asked this node to tell us a joke we also had a manual trigger rather than a chat trigger and we can see this version of the workflow i could now click into this node and I could see this is when we had it configured to tell us a joke and we could see the actual joke it told us which was about scientists not trusting atoms and obviously we can still manipulate this stuff look at schema look at table and do the same thing on that left-hand side as well so I wanted to talk about how you can import templates into your own NN environment because it's super cool and like I said they're all kind of built on top of JSON so I'm going to go to NN's website and we're going to go to product and we're going to scroll down here to templates and you can see there's over 2100 workflow automation templates so let's scroll down let's say we want to do this one with cloning viral Tik Toks with AI avatars and we can use this one for free so I'll click on use for free and what's cool is we can either copy the template to clipboard or since we're in the cloud workspace we could just import it right away and so this is logged into my other kind of my main cloud instance but I'll still show you guys how this works i would click on this button it would pull up this screen where I just get to set up a few things so there's going to be different things we'd have to connect to so you would basically just select your different credentials if you already had them set up if not you could create them right here and then you would just basically be able to hit continue and as this loads up you see we have the exact template right there to play with or let's say you're scrolling on YouTube and you see just a phenomenal Nate Herk YouTube video that you want to play around with all you have to do is go to my free school community and you will come into YouTube resources or search for the title of the video and let's say you wanted to play with this shorts automation that I built what you'll see right here is a JSON file that you'll have to download once you download that you'll go back into Nitn create a new workflow and then when you import that from file if you click on this button right here you can see the entire workflow comes in and then all you're going to have to do is follow the setup guide in order to connect your own credentials to these different nodes all right and then the final thing I wanted to talk about is inactive versus active workflows so you may have noticed that none of our executions actually counted up from zero and the reason is because this is counting active workflow executions and if we come up here to the top right we can see that we have the ability to make a workflow active but it has to have a trigger node that requires activation so real quick let's say that we come in here and we want a workflow to start when we have a schedule trigger so I would go to schedule and I would basically say okay I want this to go off every single day at midnight as we have here and what would happen is while this workflow is inactive it's only actually going to run if we hit test workflow and then it runs but if we were to flick this on as active now it says your schedule trigger will now trigger executions on the schedule you have defined these executions will not show up immediately in the editor but you can see them in the execution list so this is basically saying two things it's saying now that we have the schedule trigger set up to run at midnight it's actually going to run at midnight because it's active if we left this inactive it would not actually run and all it meant by the second part is if we were sitting in this workflow at midnight we wouldn't see it execute and go spinning and green and red in live real time but it would still show up as an execution but if it's an active workflow you just don't get to see them live visually running and spinning anymore so that's the difference between an active workflow and an inactive workflow let's say you have a trigger that's like um let's say you have a HubSpot trigger where you want this basically to fire off the workflow whenever a new contact is created so you'd connect to HubSpot and you would make this workflow active so that it actually runs if a new contact's created if you left this inactive even though it says it's going to trigger on new contact it would not actually do so unless this workflow was active so that's a super important thing to remember all right and then one last thing I want to talk about which we were not going to dive into because we'll see examples later is there is one more way that we can see data rather than schema table or JSON and it's something called binary so binary basically just means an image or maybe a big PDF or a word doc or a PowerPoint file it's basically something that's not explicitly textbased so let me show you exactly what that might look like what I'm going to do is I'm going to add another trigger under this workflow and I'm going to click on tab and even though it doesn't say like what triggers this workflow we can still access different triggers so I'm just going to type in form and this is going to give us a form submission that basically is an NAND native form and you can see there's an option at the bottom for triggers so I'm going to click on this trigger now basically what this pulls up is another configuration panel but obviously we don't have an input because it's a trigger but we are going to get an output so anyways let me just set up a quick example form i'm just going to say the title of this form is demo the description is binary data and now what happens if I click on test step it's going to pull up this form and as you can see we haven't set up like any fields for people to actually submit stuff so the only option is to submit but when I hit submit you can see that the node has been executed and now there's actually data in here submitted at with a timestamp and then we have different information right here so let me just show you guys we can add a form element and when I'm adding a form element we can basically have this be you know date it can be a drop down it can be an email it can be a file it can be text so real quick I'm just going to show you an example where let's say we have a form where someone has to submit their name we have the option to add a placeholder or make it required and this isn't really the bulk of what I'm trying to show you guys i just want to show you binary data but anyways let's say we're adding another field that's going to be a file i'm just going to say file and this will also be required and now if I go ahead and hit test step it's going to pull up a new form for us with a name parameter and a file parameter so what I did is I put my name and I put in just a YouTube short that I had published and you can see it's an MP4 file so if I hit submit we're going to get this data pulled into N as you can see in the background just go ahead and watch the form is going to actually capture this data there you go form submitted and now what we see right here is binary data so this is interesting right we still have our schema we still have our table we still have our JSON but what this is showing us is basically okay the name that the person submitted was Nate the file here are some information about it as far as the name of it the mime type and the size but we don't actually access the file through table or JSON or schema view the only way we can access a video file is through binary and as you can see if I clicked on view it's my actual video file right here and so that's all I really wanted to show you guys was when you're working with PDFs or images or videos a lot of times they're going to come through as binary which is a little confusing at first but it's not too bad and we will cover an example later in this tutorial where we look at a binary file and we process it but as you can see now if we were doing a next node we would have schema table JSON and binary so we're still able to work with the binary we're still able to reference it but I just wanted to throw out there when you see binary don't get scared it just basically means it's a different file type it's not just textbased okay so that's going to do it for just kind of setting up the foundational knowledge and getting familiar with the dashboard and the UI a little bit and as you move into these next tutorials which are going to be some step by steps I'm going to walk through every single thing with you guys setting up different accounts with Google and something called Pine Cone and we'll talk about all this stuff step by step but hopefully now it's going to be a lot better moving into those sections because you've seen you know some of the input stuff and how you configure nodes and just like all this terminology that you may not have been familiar with like JSON JavaScript variables workflows executions that sort of stuff so like I said let's move into those actual step-by-step builds and I can assure you guys you're going to feel a lot more comfortable after you have built a workflow end to end all right we're going to talk about data types in Nadn and what those look like it's really important to get familiar with this before we actually start automating things and building agents and stuff like that so what I'm going to do is just pull in a set node as you guys know this just lets us modify add or remove fields and it's very very simple we basically would just click on this to add fields we can add the name of the field we choose the data type and then we set the value whether that's a fixed value which we'll be looking at here or if we're dragging in some sort of variable from the lefth hand side but clearly right now we have no data incoming we just have a manual trigger so what I'm going to do is zoom in on the actual browser so we can examine this data on the output a bit bigger and I don't have to just keep cutting back and forth with the editing so as you can see there's five main data types that we have access to and end it in we have a string which is basically just a fancy name for a word um as you can see it's represented by a little a a letter a then we have a number which is represented by a pound sign or a hashtag whatever you want to call it um it's pretty self-explanatory then we have a boolean which is basically just going to be true or false that's basically the only thing it can be represented by a little checkbox we have an array which is just a fancy word for list and we'll see exactly what this looks like and then we have an object which is probably the most confusing one which basically means it's just this big block which can have strings in them numbers in them it can have booleans in them it can have arrays in them and it can also have nested objects within objects so we'll take a look at that let's just start off real quick with the string so let's say a string would be a name and that would be my name so if I hit test step on the right hand side in the JSON it comes through as key value pair like we talked about name equals Nate super simple you can tell it's a string because right here we have two quotes around the word Nate so that represents a string or you could go to the schema and you can see that with name equals Nate there's the little letter A and that basically says okay this is a string as you see it matches up right here cool so that's a string let's switch over to a number now we'll just say we're looking at age and we'll throw in the number 50 hit test step and now we see age equals 50 with the pound sign right here as the symbol in the schema view or if we go to JSON view we have the key value pair age equals 50 but now there are no double quotes around the actual number it's green so that's how we know it's not a string this is a number and um that's where you may run into some issues where if you had like age coming through as a string you wouldn't be able to like do any summarizations or filters you know like if age is greater than 50 send it off this way if it's less than 50 send it that way in order to do that type of filtering and routing you would need to make sure that age is actually a number variable type or data type cool so there's age let's go to a boolean so we're going to basically just say adult and that can only be true or false you see I don't have the option to type anything here it's only going to be false or it's only going to be true and as you can see it'll come through it'll look like a string but there's no quotes around it it's green and that's how we know it's a boolean or we could go to schema and we can see that there's a checkbox rather than the letter A symbol now we're going to move on to an array and this one's interesting right so let's just say we we want to have a list of names so if I have a list of names and I was typing in my name and I tried to hit test step this is where you would run into an error because it's basically saying okay the field called names which we set right here it's expecting to get an array but all we got was Nate which is basically a string so to fix this error change the type for the field names or you can ignore type conversions whatever um so if we were to come down to the option and ignore type conversions so when we hit ignore type conversions and tested the step it basically just converted the field called names to a string because it just could understand that this was a string rather than an array so let's turn that back off and let's actually see how we could get this to work if we wanted to make an array so like we know an array just is a fancy word for a list and in order for us to actually send through an end and say okay this is a list we have to wrap it in square brackets like this but we also have to wrap each item in the list in quotes so I have to go like this and go like that and now this would pass through as a list of a of different strings and those are names and so if I wanted to add another one after the first item I would put a comma i put two quotes and then inside that I could put another name hit test step and now you can see we're getting this array that's made up of different strings and they're all going to be different names so I could expand that i could close it out um we could drag in different names and in JSON what that looks like is we have our key and then we have two closed brackets which is basically exactly what like right here this is exactly what we typed right here so that's how it's being represented within these square brackets right here okay cool so the final one we have to talk about is an object and this one's a little more complex so if I was to hit test step here it's going to tell us names expects an object but we got an array so once again you could come in here ignore type conversions and then it would just basically come through as a string but it's not coming through as an array so that's not how we want to do it and I don't want to mess with the actual like schema of typing in an object so what I'm going to do is go to chat i literally just said give me an example JSON object to put into naden it gives me this example JSON object i'm going to copy that come into the set node and instead of manual mapping I'm just going to customize it with JSON paste the one that chat just gave us and when I hit test step what we now see first of all in the schema view is we have one item with you know this is an object and all this different stuff makes it up so we have a string which is name herk we have a string which is email nate example.com we have a string which is company true horizon then we have an array of interests within this object so I could close this out i could open it up and we have three interests ai automation nadn and YouTube content and this is you know chat GBT's long-term memory about me making this and then we also have an object within our object which is called project and the interesting difference here with an object or an array is that when you have an array of interests every single item in that array is going to be called interest zero interest one interest two and by the way this is three interests but computers start counting from zero so that's why it says 0 one two but with an object it doesn't all have to be the same thing so you can see in this project object project object we have one string called title we have one string called called called status and we have one string called deadline and this all makes up its own object as you can see if we went to table view this is literally just one item that's really easy to read and you can tell that this is an array because it goes 012 and you can tell that this is an object because it has different fields in it this is a one item it's one object it's got strings up top it has no numbers actually so the date right here this is coming through as a string variable type we can tell because it's not green we can tell because it has double quotes around it and we can also tell because in schema it comes through with the letter A but this is just how you can see there's these different things that make up um this object and you can even close them down in JSON view we can see interest is an array that has three items we could open that up we can see project is an object because it's wrapped in in um curly braces not not um the closed square brackets as you can see so there's a difference and I know this wasn't super detailed and it's just something really really important to know heading into when you actually start to build stuff out because you're probably going to get some of those errors where you're like you know blank expects an object but got this or expects an array and got this so just wanted to make sure I came in here and threw that module at you guys and hopefully it'll save you some headaches down the road real quick guys if you want to be able to download all the resources from this video they'll be available for free in my free school community which will be the link in the pinned comment there'll be a zip file in there that has all 23 of these workflows as you can see and also two PDFs at the bottom which are covered in the video so like I said join the Free School community not only does it have all of my YouTube resources but it's also a really quick growing community of people who are obsessed with AI automation and using ND every day all you'll have to do is search for the title of this video using the search bar or you can click on YouTube resources and find the post associated with this video and then you'll have the zip file right here to download which once again is going to have all 23 of these JSON N workflows and two PDFs and there may even be some bonus files in here you'll just have to join the free school community to find out okay so we talked about AI agents we talked about AI workflows we've gotten into NADN and set up our account we understand workflows nodes triggers JSON stuff like that and data types now it's time to use all that stuff that we've talked about and start applying it so we're going to head into this next portion of this course which is going to be about step-by-step builds where I'm going to walk you through every single step live and we'll have some pretty cool workflows set up by the end so let's get into it today we're going to be looking at three simple AI workflows that you can build right now to get started learning NAND we're going to walk through everything step by step including all of the credentials and the setups so let's take a look at the three workflows we're going to be building today all right the first one is going to be a rag pipeline and chatbot and if you don't know what rag means don't worry we're going to explain it all but at a high level what we're doing is we're going to be using Pine Cone as a vector database if you don't know what a vector database is we'll break it down we're going to be using Google Drive we're going to be using Google Docs and then something called Open Router which lets us connect to a bunch of different AI models like OpenAI's models or Anthropics models the second workflow we're going to look at is a customer support workflow that's kind of going to be building off of the first one we just built because in the first workflow we're going to be putting data into a Pine Cone vector database and in this one we're going to use that data in there in order to respond to customer support related emails so we'll already have had Pine Cone set up but we're going to set up our credentials for Gmail and then we're also going to be using an NAN AI agent as well as Open Router once again and then finally we're going to be doing LinkedIn content creation and in this one we'll be using an NAN AI agent and open router once again but we'll have two new credentials to set up the first one being Tavi which is going to let us search the web and then the second one will be Google Sheets where we're going to store our content ideas pull them in and then have the content written back to that Google sheet so by the end of this video you're going to have three workflows set up and you're going to have a really good foundation to continue to learn more about NADN you'll already have gotten a lot of credentials set up and understand what goes into connecting to different services one of the trickiest being Google so we'll walk through that step by step and then you'll have it configured and you'll be good and then from there you'll be able to continuously build on top of these three workflows that we're going to walk through together because there's really no such thing as a finished product in the space different AI models keep getting released and keep getting better there's always ways to improve your templates and the cool thing about building workflows in NAN is that you can make them super customized for exactly what you're looking for so if this sounds good to you let's hop into that first workflow okay so for this first workflow we're building a rag pipeline and chatbot and so if that sounds like a bunch of gibberish to you let's quickly understand what rag is and what a vector database is so rag stands for retrieval augmented generation and in the simplest terms let's say you ask me a question and I don't actually know the answer i would just kind of Google it and then I would get the answer from my phone and then I would tell you the answer so in this case when we're building a rag chatbot we're going to be asking the chatbot questions and it's not going to know the answer so it's going to look inside our vector database find the answer and then it's going to respond to us and so when we're combining the elements of rag with a vector database here's how it works so the first thing we want to talk about is actually what is a vector database so essentially this is what a vector database would look like we're all familiar with like an x and yaxis graph where you can plot points on there on a two dimensional plane but a vector database is a multi-dimensional graph of points so in this case you can see this multi-dimensional space with all these different points or vectors and each vector is placed based on the actual meaning of the word or words in the vector so over here you can see we have wolf dog and cat and they're placed similarly because the meaning of these words are all like animals whereas over here we have apple and banana which the meaning of the words are food more likely fruits and that's why they're placed over here together so when we're searching through the database we basically vectorize a question the same way we would vectorize any of these other points and in this case we were asking for a kitten and then that query gets placed over here near the other animals and then we're able to say okay well we have all these results now so what that looks like and what we'll see when we get into NAND is we have a document that we want to vectorize we have to split the document up into chunks because we can't put like a 50page PDF as one chunk so it gets split up and then we're going to run it through something called an embeddings model which basically just turns text into numbers just as simple as that and as you can see in this case let's say we had a document about a company we have company data finance data and marketing data and they all get placed differently because they mean different things and the the context of those chunks are different and then this visual down here is just kind of how an LLM or in this case this agent takes our question turns it into its own question we vectorize that using the same embeddings model that we used up here to vectorize the original data and then because it gets placed here it just grabs back any vectors that are nearest maybe like the nearest four or five and then it brings it back in order to respond to us so don't want to dive too much into this don't want to over complicate it but hopefully this all makes sense cool so now that we understand that let's actually start building this workflow so what we're going to do here is we are going to click on add first step because every workflow needs a trigger that basically starts the workflow so I'm going to type in Google Drive because what we're going to do is we are going to pull in a document from our Google Drive in order to vectorize it so I'm going to choose a trigger which is on changes involving a specific folder and what we have to do now is connect our account as you can see I'm already connected but what we're going to do is click on create new credential in order to connect our Google Drive account and what we have to do is go get a client ID and a secret so what we want to do is click on open docs which is going to bring us to Naden's documents on how to set up this credential we have a prerequisite which is creating a Google Cloud account so I'm going to click on Google Cloud account and we're going to set up a new project okay so I just signed into a new account and I'm going to set up a whole project and walk through the credentials with you guys you'll click up here you'll probably have something up here that says like new project and then you'll click into new project all we have to do now is um name it and you you'll be able to start for free so don't worry about that yet so I'm just going to name this one demo and I'm going to create this new project and now up here in the top right you're going to see that it's kind of spinning up this project and then we'll move forward okay so it's already done and now I can select this project so now you can see up here I'm in my new project called demo i'm going to click on these three lines in the top left and what we're going to do first is go to APIs and services and click on enabled APIs and services and what we want to do is add the ones we need and so right now all I'm going to do is add Google Drive and you can see it's going to come up with Google Drive API and then all we have to do is really simply click enable and there we I just enabled it so you can see here the status is enabled and now we have to set up something called our OOTH consent screen which basically is just going to let Nadn know that Google Drive and Naden are allowed to talk to each other and have permissions so right here I'm going to click on OOTH consent screen we don't have one yet so I'm going to click on get started i'm going to give it a name so we're just going to call this one demo once again I'm going to add a support email i'm going to click on next because I'm not using a Google Workspace account I'm just using a you know nate88@gmail.com i'm going to have to choose external i'm going to click on next for contact information I'm putting the same email as I used to create this whole project click on next and then agree to terms and then we're going to create that OOTH consent screen okay so we're not done yet the next thing we want to do is we want to click on audience and we're going to add ourselves as a test user so we could also make the app published by publishing it right here but I'm just going to keep it in test and when we keep it in test mode we have to add a test user so I'm going to put in that same email from before and this is going to be the email of the Google Drive we want to access so I put in my email you can see I saved it down here and then finally all we need to do is come back into here go to clients and then we need to create a new client we're going to click on web app we're going to name it whatever we want of course I'm just going to call this one demo once again and now we need to basically add a redirect URI so if you click back in Nitn we have one right here so we're going to copy this go back into cloud and we're going to add a URI and paste it right in there and then hit create and then once that's created it's going to give us an ID and a secret so all we have to do is copy the ID go back into Nit and paste that right here and then we need to go grab our secret from Google Cloud and then paste that right in there and now we have a little button that says sign in with Google so I'm going to open that up it's going to pull up a window to have you sign in make sure you sign in with the same account that you just had yourself as a test user that one and then you'll have to continue and then here is basically saying like what permissions do we have does anyone have to your Google Drive so I'm just going to select all i'm going to hit continue and then we should be good connection successful and we are now connected and you may just want to rename this credential so you know you know which email it is so now I've saved my credential and we should be able to access the Google Drive now so what I'm going to do is I'm going to click on this list and it's going to show me the folders that I have in Google Drive so that's awesome now for the sake of this video I'm in my Google Drive and I'm going to create a new folder so new folder we're going to call this one um FAQ create this one because we're going to be uploading an FAQ document into it so here's my FAQ folder um right here and then what I have is down here I made a policy and FAQ document which looks like this we have some store policies and then we also have some FAQs at the bottom so all I'm going to do is I'm going to drag in my policy and FAQ document into that new FAQ folder and then if we come into NAN we click on the new folder that we just made so it's not here yet i'm just going to click on these dots and click on refresh list now we should see the FAQ folder there it is click on it we're going to click on what are we watching this folder for i'm going to be watching for a file created and then I'm just going to hit fetch test event and now we can see that we did in fact get something back so let's make sure this is the right one yep so there's a lot of nasty information coming through i'm going to switch over here on the right hand side this is where we can see the output of every node i'm going to click on table and I'm just going to scroll over and there should be a field called file name here it is name and we have policy and FAQ document so we know we have the right document in our Google Drive okay so perfect every time we drop in a new file into that Google folder it's going to start this workflow and now we just have to configure what happens after the workflow starts so all we want to do really is we want to pull this data into n so that we can put it into our pine cone database so off of this trigger I'm going to add a new node and I'm going to grab another Google Drive node because what happened is basically we have the file ID and the file name but we don't have the contents of the file so we're going to do a download file node from Google Drive i'm going to rename this one and just call it download file just to keep ourselves organized we already have our credential connected and now it's basically saying what file do you want to download we have the ability to choose from a list but if we choose from the list it's going to be this file every time we run the workflow and we want to make this dynamic so we're going to change from list to by ID and all we have to do now is we're going to look on the lefth hand side for that file that we just pulled in and we're going to be looking for the ID of the file so I can see that I found it right down here in the spaces array because we have the name right here and then we have the ID right above it so I'm going to drag ID put it right there in this folder it's coming through as a variable called JSON ID and that's just basically referencing you know whenever a file comes through on the the Google Drive trigger i'm going to use the variable JSON id which will always pull in the files ID so then I'm going to hit test step and we're going to see that we're going to get the binary data of this file over here that we could download and this is our policy and FAQ document okay so there's step two we have the file downloaded in NADN and now it's just as simple as putting it into pine cone so before we do that let's head over to pine cone.io okay so now we are in pine cone.io which is a vector database provider you can get started for free and what we're going to do is sign up okay so I just got logged in and once you get signed up you should see us a page similar to this it's a get started page and what we want to do is you want to come down here and click on you know begin setup because we need to create an index so I'm going to click on begin setup we have to name our index so you can call this whatever you want we have to choose a configuration for a text model we have to choose a configuration for an embeddings model which is sort of what I talked about right in here this is going to turn our text chunks into a vector so what I'm going to do is I'm going to choose text embedding three small from OpenAI it's the most cost effective OpenAI embedding model so I'm going to choose that then I'm going to keep scrolling down i'm going to keep mine as serverless i'm going to keep AWS as the cloud provider i'm going to keep this region and then all I'm going to do is hit create index once you create your index it'll show up right here but we're not done yet you're going to click into that index and so I already obviously have stuff in my vector database you won't have this what I'm going to do real quick is just delete this information out of it okay so this is what yours should look like there's nothing in here yet we have no name spaces and we need to get this configured so on the left hand side go over here to API keys and you're going to create a new API key name it whatever you want of course hit create key and then you're going to copy that value okay back in NDN we have our API key copied we're going to add a new node after the download file and we're going to type in pine cone and we're going to grab a pine cone vector store then we're going to select add documents to a vector store and we need to set up our credential so up here you won't have these and you're going to click on create new credential and all we need to do here is just an API key we don't have to get a client ID or a secret so you're just going to paste in that API key once that's pasted in there and you've given it a name so you know what this means you'll hit save and it should go green and we're connected to Pine Cone and you can make sure that you're connected by clicking on the index and you should have the name of the index right there that we just created so I'm going to go ahead and choose my index i'm going to click on add option and we're going to be basically adding this to a Pine Cone namespace which back in here in Pine Cone if I go back into my database my index and I click in here you can see that we have something called namespaces and this basically lets us put data into different folders within this one index so if you don't specify an index it'll just come through as default and that's going to be fine but we want to get into the habit of having our data organized so I'm going to go back into NADN and I'm just going to name this name space FAQ because that's the type of data we're putting in and now I'm going to click out of this node so you can see the next thing that we need to do is connect an embeddings model and a document loader so let's start with the embeddings model i'm going to click on the plus and I'm going to click on embeddings open AAI and actually this is one thing I left out of the Excalaw is that we also will need to go get an OpenAI key so as you can see when we need to connect a credential you'll click on create new credential and we just need to get an API key so you're going to type in OpenAI API you'll click on this first link here if you don't have an account yet you'll sign in and then once you sign up you want to go to your dashboard and then on the lefth hand side very similar thing to Pine Cone you'll click on API keys and then we're just going to create a new key so you can see I have a lot we're going to make a new one and I'm calling everything demo but this is going to be demo number three create new secret key and then we have our key so we're going to copy this and we're going to go back into Nit paste that right here we paste it in our key we've given in a name and now we'll hit save and we should go green just keep in mind that you may need to top up your account with a few credits in order for you to actually be able to run this model um so just keep that in mind so then what's really important to remember is when we set up our pine cone index we use the embedding model text embedding three small from OpenAI so that's why we have to make sure this matches right here or this automation is going to break okay so we're good with the embeddings and now we need to add a document loader so I'm going to click on this plus right here i'm going to click on default data loader and we have to just basically tell Pine Cone the type of data we're putting in and so you have two options JSON or binary in this case it's really easy because we downloaded a a Google Doc which is on the lefth hand side you can tell it's binary because up top right here on the input we can switch between JSON and binary and if we were uploading JSON all we'd be uploading is this gibberish nonsense information that we don't need we want to upload the binary which is the actual policy and FAQ document so I'm just going to switch this to binary i'm going to click out of here and then the last thing we need to do is add a text splitter so this is where I was talking about back in this Excal we have to split the document into different chunks and so that's what we're doing here with this text splitter i'm going to choose a recursive character text splitter there's three options and I won't dive into the difference right now but recursive character text splitter will help us keep context of the whole document as a whole even though we're splitting it up so for now chunk size is a th00and that's just basically how many characters am I going to put in each chunk and then is there going to be any overlap between our chunks of characters so right now I'm just going to leave it default a,000 and zero so that's it you just built your first automation for a rag pipeline and now we're just going to click on the play button above the pine cone vector store node in order to see it get vectorized so we're going to basically see that we have four items that have left this node so this is basically telling us that our Google doc that we downloaded right here so this document got turned into four different vectors so if I click into the text splitter we can see we have four different responses and this is the contents that went into each chunk so we can just verify this by heading real quick into Pine Cone we can see we have a new name space that we created called FAQ number of records is four and if we head over to the browser we can see that we do indeed have these four vectors and then the text field right here as you can see are the characters that were put into each chunk okay so that was the first part of this workflow but we're going to real quick just make sure that this actually works so we're going to add a rag chatbot okay so what I'm going to do now is hit the tab or I could also have just clicked on the plus button right here and I'm going to type in AI agent and that is what we're going to grab and pull into this workflow so we have an AI agent and let's actually just put him right over here um and now what we need to do is we need to set up how are we actually going to talk to this agent and we're just going to use the default N chat window so once again I'm going to hit tab i'm going to type in chat and we have a chat trigger and all I'm going to do is over here I'm going to grab the plus and I'm going to drag it into the front of the AI agent so basically now whenever we hit open chat and we talk right here the agent will read that chat message and we know this because if I click into the agent we can see the user message is looking for one in the connected chat trigger node which we have right here connected okay so the first step with an AI agent is we need to give it a brain so we need to give it some sort of AI model to use so we're going to click on the plus right below chat model and what we could do now is we could set up an OpenAI chat model because we already have our API key from OpenAI but what I want to do is click on open router because this is going to allow us to choose from all different chat models not just OpenAIs so we could do Claude we could do Google we could do Plexity we have all these different models in here which is going to be really cool and in order to get an Open Router account all you have to do is go sign up and get an API key so you'll click on create new credential and you can see we need an API key so you'll head over to openouter.ai you'll sign up for an account and then all you have to do is in the top right you're going to click on keys and then once again kind of the same as all all the other ones you're going to create a new key you're going to give it a name you're going to click create you have a secret key you're going to click copy and then when we go back into NN and paste it in here give it a name and then hit save and we should go green we've connected to Open Router and now we have access to any of these different chat models so in this case let's use let's use Claude um 3.5 Sonnet and this is just to show you guys you can connect to different ones but anyways now we could click on open chat and actually let me make sure you guys can see him if we say hello it's going to use its brain claw 3.5 sonnet and now it responded to us hi there how can I help you so just to validate that our information is indeed in the Pine Cone vector store we're going to click on a tool under the agent we're going to type in Pine Cone um and grab a Pine Cone vector store and we're going to grab the account that we just selected so this was the demo I just made we're going to give it a name so in this case I'm just going to say knowledge base we're going to give a description call this tool to access the policy and FAQ database so we're basically just describing to the agent what this tool does and when to use it and then we have to select the index and the name space for it to look inside of so the index is easy we only have one it's called sample but now this is important because if you don't give it the right name space it won't find the right information so we called ours FAQ if you remember in um our Pine Cone we have a namespace and we have FAQ right here so that's why we're doing FAQ and now it's going to be looking in the right spot so before we can chat with it we have to add an embeddings model to our Pine Cone vector store which same thing as before we're going to grab OpenAI and we're going to use embedding3 small and the same credential you just made and now we're going to be good to go to chat with our rag agent so looking back in the document we can see we have some different stuff so I'm going to ask this chatbot what the warranty policy is so I'm going to open up the chat window and say what is our warranty policy send that off and we should see that it's going to use its brain as well as the vector store in order to create an answer for us because it didn't know by itself so there we go just finished up and it said based on the information from our knowledge base here's the warranty policy we have one-year standard coverage we have you know this email for claims processes you must provide proof of purchase and for warranty exclusions that aren't covered damage due to misuse water damage blah blah blah back in the policy documentation we can see that that is exactly what we have in our knowledge base for warranty policy so just because I don't want this video to go too long I'm not going to do more tests but this is where you can get in there and make sure it's working one thing to keep in mind is within the agent we didn't give it a system prompt and what a system prompt is is just basically a message that tells the agent how to do its job so what you could do is if you're having issues here you could say you know like this is the name of our tool which is called knowledgeb you could tell the agent and in system prompt hey like your job is to help users answer questions about the um you know our policy database you have a tool called knowledgebase you need to use that in order to help them answer their questions and that will help you refine the behavior of how this agent acts all right so the next one that we're doing is a customer support workflow and as always you have to figure out what is the trigger for my workflow in this case it's going to be triggered by a new email received so I'm going to click on add first step i'm going to type in Gmail grab that node and we have a trigger which is on message received right here and we're going to click on that so what we have to do now is obviously authorize ourselves so we're going to click on create new credential right here and all we have to do here is use OOTH 2 so all we have to do is click on sign in but before we can do that we have to come over to our Google Cloud once again and now we have to make sure we enable the Gmail API so we'll click on Gmail API and it'll be really simple we'll just have to click on enable and now we should be able to do that OOTH connection and actually sign in you'll click on the account that you want to access the Gmail you'll give it access to everything click continue and then we're going to be connected as you can see and then you'll want to name this credential as always okay so now we're using our new credential and what I'm going to do is if I hit fetch test event so now we are seeing an email that I just got in this inbox which in this case was nencloud was granted access to your Google account blah blah blah um so that's what we just got okay so I just sent myself a different email and I'm going to fetch that email now from this inbox and we can see that the snippet says what is the privacy policy i'm concerned about my data and passwords and what we want to do is we want to turn off simplify because what this button is doing is it's going to take the content of the email and basically you know cut it off so in this case it didn't matter but if you're getting long emails it's going to cut off some of the email so if we turn off simplify fetch test event once again we're now going to get a lot more information about this email but we're still going to be able to access the actual content which is right here we have the text what is privacy policy i'm concerned about my data and passwords thank you and then you can see we have other data too like what the subject was who the email is coming from what their name is all this kind of stuff but the idea here is that we are going to be creating a workflow where if someone sends an email to this inbox right here we are going to automatically look up the customer support policy and respond back to them so we don't have to okay so the first thing I'm actually going to do is pin this data just so we can keep it here for testing which basically means whenever we rerun this it's not going to go look in our inbox it's just going to keep this email that we pulled in which helps us for testing right okay cool so the next step here is we need to have AI basically filter to see is this email customer support related if yes then we're going to have a response written if no we're going to do nothing because maybe the use case would be okay we're going to give it an access to an inbox where we're only getting customer support emails but sometimes maybe that's not the case and let's just say we wanted to create this as sort of like an inbox manager where we can route off to different logic based on the type of email so that's what we're going to do here so I'm going to click on the plus after the Gmail trigger and I'm going to search for a text classifier node and what this does is it's going to use AI to read the incoming email and then determine what type of email it is so because we're using AI the first thing we have to do is connect a chat model we already have our open router credential set up so I'm going to choose that i'm going to choose the credential and then I'm for this one let's just keep it with 40 mini and now this AI node actually has AI and I'm going to click into the text classifier and the first thing we see is that there's a text to classify so all we want to do here is we want to grab the actual content of the email so I'm going to scroll down i can see here's the text which is the email content we're going to drag that into this field and now every time a new email comes through the text classifier is going to be able to read it because we put in a variable which basically represents the content of the email so now that it has that it still doesn't know what to classify it as or what its options are so we're going to click on add category the first category is going to be customer support and then basically we need to give it a description of what a customer support email could look like so I wanted to keep this one simple it's pretty vague but you could make this more detailed of course and I just sent an email that's related to helping out a customer they may be asking questions about our policies or questions about our products or services and what we can do is we can give it specific examples of like here are some past customer support emails and here's what they've looked like and that will make this thing more accurate but in this case that's all we're going to do and then I'm going to add one more category that's just going to be other and then for now I'm just going to say any email that is not customer support related okay cool so now when we click out of here we can see we have two different branches coming off of this node which means when the text classifier decides it's either going to send it off this branch or it's going to send it down this branch so let's quickly hit play it's going to be reading the email using its brain and now you can see it has outputed in the customer support branch we can also verify by clicking into here and we can see customer support branch has one item and other branch has no items and just to keep ourselves organized right now I'm going to click on the other branch and I'm just going to add an operation that says do nothing just so we can see you know what would happen if it went this way for now but now is where we want to configure the logic of having an agent be able to read the email hit the vector database to get relevant information and then help us write an email so I'm going to click on the plus after the customer support branch i'm going to grab an AI agent so this is going to be very similar to the way we set up our AI agent in the previous workflow so it's kind of building on top of each other and this time if you remember in the previous one we were talking to it with a connected chat trigger node and as you can see here we don't have a connected chat trigger node so the first thing we want to do is change that we want to define below and this is where you would think okay what do we actually want the agent to read we want it to read the email so I'm going to do the exact same thing as before i'm going to go into the Gmail trigger node scroll all the way down until we can find the actual email content which is right here and just drag that right in that's all we're going to do and then we definitely want to add a system message for this agent we are going to open up the system message and I'm just going to click on expression so I can expand this up full screen and we're going to write a system prompt again for the sake of the video keeping this prompt really concise but if you want to learn more about prompting then definitely check out my communities linked down below as well as this video up here and all the other tutorials on my channel but anyways what we said here is we gave it an overview and instructions the overview says you are a customer support agent for TechHaven your job is to respond to incoming emails with relevant information using your knowledgebased tool and so when we do hook up our Pine Cone vector database we're just going to make sure to call it knowledgebase because that's what the agent thinks it has access to and then for the instructions I said your output should be friendly and use emojis and always sign off as Mr helpful from TechHaven Solutions and then one more thing I forgot to do actually is we want to tell it what to actually output so if we didn't tell it it would probably output like a subject and a body but what's going to happen is we're going to reply to the incoming email we're not going to create a new one so we don't need a subject so I'm just going to say output only the body content of the email so then we'll give it a try and see what that prompt looks like we may have to come back and refine it but for now we're good um and as you know we have to connect a chat model and then we have to connect our pine cone so first of all chat model we're going to use open router and just to show you guys we can use a different type of model here let's use something else okay so we're going to go with Google Gemini 2.0 Flash and then we need to add the Pine Cone database so I'm going to click on the plus under tool i'm going to search for Pine Cone Vector Store grab that and we have the operation is going to be retrieving documents as a tool for an AI agent we're going to call this knowledge capital B and we're going to once again just say call this tool to access policy and FAQ information we need to set up the index as well as the namespace so sample and then we're going to call the namespace you know FAQ because that's what it's called in our pine cone right here as you can see and then we just need to add our embeddings model and we should be good to go which is embedded OpenAI text embedding three small so we're going to hit the play above the AI agent and it's going to be reading the email as you can see once again the prompt user message it's reading the email what is the privacy policy i'm concerned about my data and my passwords thank you so we're going to hit the play above the agent we're going to watch it use its brain we're going to watch it call the vector store and we got an error okay so I'm getting this error right and it says provider returned error and it's weird because basically why it's erroring is because of our our chat model and it's it's weird because it goes green right so anyways what I would do here is if you're experiencing that error it means there's something wrong with your key so I would go reset it but for now I'm just going to show you the quick fix i can connect to a OpenAI chat model real quick and I can run this here and we should be good to go so now it's going to actually write the email and output super weird error but I'm honestly glad I caught that on camera to show you guys in case you face that issue because it could be frustrating so we should be able to look at the actual output which is "Hey there thank you for your concern about privacy policy at Tech Haven we take your data protection seriously." So then it gives us a quick summary with data collection data protection cookies if we clicked into here and went to the privacy policy we could see that it is in fact correct and then it also was friendly and used emojis like we told it to right here in the system prompt and finally it signed off as Mr helpful from Tech Haven Solutions also like we told it to so we're almost done here the last thing that we want to do is we want to have it actually reply to this person that triggered the whole workflow so we're going to click on the plus we're going to type in Gmail grab a Gmail node and we're going to do reply to a message once we open up this node we already know that we have it connected because we did that earlier we need to configure the message ID the message type and the message and so all I'm going to do is first of all email type i'm going to do text for the message ID I'm going to go all the way down to the Gmail trigger and we have an ID right here this is the ID we want to put into the message ID so that it responds in line on Gmail rather than creating a new thread and then for the message we're going to just drag in the output from the agent that we just had write the message so I'm going to grab this output put it right there and now you can see this is how it's going to respond in email and the last thing I want to do is I want to click on add option append nadn attribution and then just check that off so then at the bottom of the email it doesn't say this was sent by naden so finally we'll hit this test step we will see we get a success message that the email was sent and I'll head over to the email to show you guys okay so here it is this is the one that we sent off to that inbox and then this is the one that we just got back as you can see it's in the same thread and it has basically the privacy policy outlined for us cool so that's workflow number two couple ways we could make this even better one thing we could do is we could add a node right here and this would be another Gmail one and we could basically add a label to this email so if I grab add label to message we would do the exact same thing we'd grab the message ID the same way we grabbed it earlier so now it has the message ID of the label to actually create and then we would just basically be able to select the label we want to give it so in this case we could give it the customer support label we hit test step we'll get another success message and then in our inbox if we refresh we will see that that just got labeled as customer support so you could add on more functionality like that and you could also down here create more sections so we could have finance you know a logic built out for finance emails we could have logic built out for all these other types of emails and um plug them into different knowledge bases as well okay so the third one we're going to do is a LinkedIn content creator workflow so what we're going to do here is click on add first step of course and ideally you know in production what this workflow would look like is a schedule trigger you know so what you could do is basically say every day I want this thing to run at 7:00 a.m that way I'm always going to have a LinkedIn post ready for me at you know 7:30 i'll post it every single day and if you wanted it to actually be automatic you'd have to flick this workflow from inactive to active and you know now it says um your schedule trigger will now trigger executions on the schedule you have defined so now it would be working but for the sake of this video we're going to turn that off and we are just going to be using a manual trigger just so we can show how this works um but it's the same concept right it would just start the workflow so what we're going to do from here is we're going to connect a Google sheet so I'm going to grab a Google sheet node i'm going to click on get rows and sheet and we have to create our credential once again so we're going to create new credential we're going to be able to do ooth to sign in but we're going to have to go back to Google Cloud and we're going to have to grab a sheet and make sure that we have the Google Sheets API enabled so we'll come in here we'll click enable and now once this is good to go we'll be able to sign in using OOTH 2 so very similar to what we just had to do for Gmail in that previous workflow but now we can sign in so once again choosing my email allowing it to have access and then we're connected successfully and then giving this a good name and now what we can do is choose the document and the sheet that it's going to be pulling from so I'm going to show you i have one called LinkedIn posts and I only have one sheet but let's show you the sheet real quick so LinkedIn posts what we have is a topic a status and a content and we're just basically going to be pulling in one row where the status equals to-do and then we are going to um create the content upload it back in right here and then we're going to change the status to created so then this same row doesn't get pulled in every day so how this is going to work is that we're going to create a filter so the first filter is going to be looking within the status column and it has to equal to-do and if we click on test step we should see that we're going to get like all of these items where there's a bunch of topics but we don't want that we only want to get the first row so at the bottom here add option i'm going to say return only first matching row check that on we'll test this again and now we're only going to be getting that top row to create content on cool so we have our first step here which is just getting the content from the Google sheet now what we're going to do is we need to do some web search on this topic in order to create that content so I'm going to add a new node this one's going to be called an HTTP request so we're going to be making a request to a specific API and in this case we're going to be using Tavly's API so go on over to tavly.com and create a free account you're going to get a,000 searches for free per month okay here we are in my account i'm on the free researcher plan which gives me a thousand free credits and right here I'm going to add an API key we're going to name it create a key and we're going to copy this value and so you'll start to get to the point when you connect to different services you always need to have some sort of like token or API key but anyways we're going to grab this in a sec what we need to do now is go to the documentation that we see right here we're going to click on API reference and now we have right here this is going to be the API that we need to use in order to search the web so I'm not going to really dive into like everything about HTTP requests right now i'm just going to show you the simple way that we can get this set up so first thing that we're going to do is we obviously see that we're using an endpoint called Tavali search and we can see it's a post request which is different than like a git request and we have all these different things we need to configure and it can be confusing so all we want to do is on the top right we see this curl command we're going to click on the copy button we're going to go back into our NEN hit import curl paste in the curl command hit import and now the whole node magically just basically filled in itself so that's really awesome and now we can sort of break down what's going on so for every HTTP request you have to have some sort of method typically when you're sending over data to a service which in this case we're going to be sending over data to Tavali it's going to search the web and then bring data back to us that's a post request because we're sending over body data if we were just like kind of trying to hit an and if we were just trying to access like you know um bestbuy.com and we just wanted to scrape the information that could just be a simple git request because we're not sending anything over anyways then we're going to have some sort of base URL and endpoint which is right here the base URL we're hitting is api.com/tavaly and then the endpoint we're hitting is slash search so back in the documentation you can see right here we have slash search but if we were doing like an extract we would do slash extract so that's how you can kind of see the difference with the endpoints and then we have a few more things to configure the first one of course is our authorization so in this case we're doing it through a header parameter as you can see right here the curl command set it up basically all we have to do is replace this um token with our API key from Tavi so I'm going to go back here copy that key in N i'm going to get rid of token and just make sure that you have a space after the word bearer and then you can paste in your token and now we are connected to Tavi but we need to configure our request before we send it off so right here are the parameters within our body request and I'm not going to dive too deep into it you can go to the documentation if you want to understand like you know the main thing really is the query which is what we're searching for but we have other things like the topic it can be general or news we have search depth we have max results we have a time range we have all this kind of stuff right now I'm just going to leave everything here as default we're only going to be getting one result and we're going to be doing a general topic we're going to be doing basic search but right now if we hit test step we should see that this is going to work but it's going to be searching for who is Leo Messi and here's sort of like the answer we get back as well as a URL so this is an actual website we could go to about Lionel Messi and then some content from that website right so we are going to change this to an expression so that we can put a variable in here rather than just a static hard-coded who is Leo Messi we'll delete that query and all we're going to do is just pull in our topic so I'm just going to simply pull in the topic of AI image generation obviously it's a variable right here but this is the result and then we're going to test step and this should basically pull back an article about AI image generation and you know so here is a deep AI um link we'll go to it and we can see this is an AI image generator so maybe this isn't exactly what we're looking for what we could do is basically just say like you know we could hardcode in search the web for and now it's going to be saying search the web for AI image generation we could come in here and say yeah actually you know let's get three results not just one and then now we could test that step and we're going to be getting a little bit different of a search result um AI image generation uses text descriptions to create unique visuals and then now you can see we got three different URLs rather than just one anyways so that's our web search and now that we have a web search based on our defined topic we just need to write that content so I'm going to click on the plus i'm going to grab an AI agent and once again we're not giving it the connected chat trigger node to look at that's nowhere to be found we're going to feed in the research that was just done by Tavi so I'm going to click on expression to open this up i'm going to say article one with a colon and I'm just going to drag in the content from article one i'm going to say article 2 with a colon and just drag in the content from article 2 and then I'm going to say article 3 colon and just drag in the content from the third article so now it's looking at all three article contents and now we just need to give it a system prompt on how to write a LinkedIn post so open this up click on add option click on system message and now let's give it a prompt about turning these three articles into a LinkedIn post okay so I'm heading over to my custom GPT for prompt architect if you want to access this you can get it for free by joining my free school community um you'll join that it's linked in the description and then you can just search for prompt architect and you should find the link anyways real quick it's just asking for some clarification questions so anyways I'm just shooting off a quick reply and now it should basically be generating our system prompt for us so I'll check in when this is done okay so here is the system prompt i am going to just paste it in here and I'm just going to you know disclaimer this is not perfect at all like I don't even want this tool section at all because we don't have a tool hooked up to this agent um we're obviously just going to give it a chat model real quick so in this case what I'm going to do is I'm going to use Claude 3.5 Sonnet just because I really like the way that it writes content so I'm using Claude through Open Router and now let's give it a run and we'll just see what the output looks like um I'll just click into here while it's running and we should see that it's going to read those articles and then we'll get some sort of LinkedIn post back okay so here it is the creative revolution is here and it's AI powered gone are the days of hiring expensive designers or struggling with complex software today's entrepreneurs can transform ideas into a stunning visuals instantly using AI image generators so as you can see we have a few emojis we have some relevant hashtags and then at the end it also said this post you know it kind of explains why it made this post we could easily get rid of that if all we want is the content we would just have to throw that in the system prompt but now that we have the post that we want all we have to do is send it back into our Google sheet and update that it was actually made so we're going to grab another sheets node we're going to do update row and sheet and this one's a little different it's not just um grabbing stuff from a row we're trying to update stuff so we have to say what document we want what sheet we want but now it's asking us what column do we want to match on so basically I'm going to choose topic and all we have to do is go all the way back down to the sheet we're going to choose the topic and drag it in right here which is basically saying okay when this node gets called whenever the topic equals AI image generation which is a variable obviously whatever whatever topic triggered the workflow is what's going to pop up here we're going to update that status so back in the sheets we can see that the status is currently to-do and we need to change it to created in order for it to go green so I'm just going to type in created and obviously you have to spell this correctly the same way you have it in your Google Sheets and then for the content all I'm going to do is we're just going to drag in the output of the AI agent and as you can see it's going to be spitting out the result and now if I hit test step and we go back into the sheet we'll basically watch this change now it's created and now we have the content of our LinkedIn post as well with some justification for why it created the post like this and so like I said you could basically have this be some sort of you know LinkedIn content making machine where every day it's going to run at 7:00 a.m it's going to give you a post and then what you could do also is you can automate this part of it where you're basically having it create a few new rows every day if you give it a certain sort of like general topic to create topics on and then every day you can just have more and more pumping out so that is going to do it for our third and final workflow okay so that's going to do it for this video i hope that it was helpful you know obviously we connected to a ton of different credentials and a ton of different services we even made a HTTP request to an API called Tavali now if you found this helpful and you liked this sort of live step-by-step style and you're also looking to accelerate your journey with NAN and AI automations I would definitely recommend to check out my paid community the link for that is down in the description okay so hopefully those three workflows taught you a ton about connecting to different services and setting up credentials now I'm actually going to throw in one more bonus step-by-step build which is actually one that I shared in my paid community a while back and I wanted to bring it to you guys now so definitely finish out this course and if you're still looking for some more and you like the way I teach then feel free to check out the paid community the link for that's down in the description we've got a course in there that's even more comprehensive than what you're watching right now on YouTube we've also got a great community of people that are using Niten to build AI automations every single day so I'd love to see you guys in that community but let's move ahead and build out this bonus workflow hey guys so today I wanted to do a step by step of an invoice workflow and this is because there's different ways to approach stuff like this right there's the conversation of OCR there's a conversation of maybe extracting text from PDFs um there's the conversation of if you're always getting invoices in the exact same format you probably don't need AI because you could use like a code node to extract the different parameters and then push that through so that's kind of stuff we're going to talk about today and I I haven't showed this one on YouTube it's not like a YouTube build but it's not an agent it's an AI powered workflow and I also wanted to talk about like just the foundational elements of connecting pieces thinking about the workflow so what we're going to do first actually is we're going to hop into Excalar real quick and I'm going to create a new one and we're just going to real quickly wireframe out what we're doing so first thing we're going to draw out here is the trigger so we'll make this one yellow we'll call this the trigger and what this is going to be is invoice sorry we're going to do new invoice and this is going to be um Google Drive so the Google Drive node it's going to be triggering the workflow and it's going to be when a new invoice gets dropped into um the folder that we're watching so that's the trigger from there and like I said this is going to be a pretty simple workflow from there what we're going to do is basically it's going to be a PDF so the first thing to understand is actually let me just put Google Drive over here so the first thing to understand from here is um you know what what do the invoices look like these are the questions that we're going to have so the first one's what do the invoices look like um because that determines what happens next so if they are PDFs that happen every single time and they're always in the same format then next we'd want to do okay well we can just kind of extract the text from this and then we can um use a code node to extract the information we need per each parameter now if it is a scanned invoice where it's maybe not as we're not maybe not as able to extract text from it or like turn it into a text doc we'll probably have to do some OCR element um but if it's PDF that's generated by a computer so we can extract the text but they're not going to come through the same every time which is what we have in this case i have two example invoices so we know we're overall we're looking for like business name client name invoice number invoice date due date payment method bank details maybe stuff like that right but both of these are formatted very differently they all have the same information but they're formatted differently so that's why we can't that's why we want to use an AI sort of information extractor node um so that's one of the main questions the other ones we'd think about would be like you know where do they go so once we get them where do they go um you know the frequency of them coming in and then also like really any other action so bas building off of where do they go it's also like what actions will we take so does that mean um are we just going to throw it in a CRM or are we just going to throw it in a CRM or maybe a database or are we also going to like send them an automated follow-up based on you know the email that we extract from it and say "Hey we received your invoice thanks." So like what does that look like so those are the questions we were initially going to ask um and then that helps us pretty much plan out the next steps so because we figured out um basically we figured out that we want to extract the same like x amount of information the x the same x fields so because we found out we want to extract the same X fields but the formats may not be [Music] consistent we will use an AI information extractor um that is just a long sentence so shorten this up a little bit or sorry make it smaller a little bit okay so we have that um the invoice will be um like updated to our Google sheet which will just be like a database of invoice which I'll just call invoice database and then a follow-up email can be sent or no not a follow-up email we'll just say an email an internal email will be sent so an email will be sent to the internal billing team okay so this is what we've got right we have our questions we've kind of answered the questions so now we know what the rest of the flow is going to look like we already know this is not going to be an agent it's going to be a workflow so what we're going to do is we're going to add another node right here which is going to be you know PDF comes in and what we want to do is we want to extract the text from that PDF um let's make this text smaller so we're going to extract the text and we'll do this by using a um extract text node okay cool now once we have the text extracted what do we need to do we need to um just moving over these initial questions so we have the text extracted extracted what comes next what comes next is we need to um like decide on the fields to extract and how do we get this we get this from our invoice database so let's quickly set up the invoice database i'm going to do this by opening up a Google sheet which we are just going to call the oops invoice DB so now we need to figure out what we actually want to put into our invoice DB so first thing we'll do is um you know we're pretending that our business is called Green Grass so we don't need that we don't need the business information we really just need the client information so invoice number will be the first thing we want so we're just setting up our database here so invoice number from there we want to get client name client address client email client phone so client name client email [Music] oops client name client email client address and then we want client phone okay so we have those five things and let's see what else we want probably the amount so we'll just do total amount due total amount um and due date invoice date and due date okay invoice date and due date okay so we have these what are these eight eight fields and I'm just going to change these colors so it looks visually better for us so here are the fields we have and this is what we want to extract from every single invoice that we are going to receive cool so we know we have these eight things i'm just going to actually No we're fine so we have our eight fields to extract um and then they're going to be pushed to invoice DB and then we'll set up the once we have these fields we can basically um create our email so this is going to be an AI node that's going to info extract so it's going to extract the eight fields that we have over here so we're going to send the data into there and it's going to extract those fields once we extract those fields we don't probably need to set the data because because coming out of this will basically be those eight fields so um you know every time what's going to happen is actually sorry let me add another node here so we can connect these so what's going to come out of here is one item which will be the one PDF and then what's coming out of here will be eight items every time so that's what we've got we could also want to think about maybe if two invoices get dropped in at the same time how do we want to handle that loop or just push through but we won't worry about that yet so we've got one item coming in here the node that's extracting the info will push out the eight items and the eight items only and then what we can do from there is update invoice DB and then from there we can also and this could be like out of here we do two things or it could be like a uh sequential if that makes sense so well what else we know we need to do is we know that we also need to email billing team and so what I was saying there is we could either have it like this where at the same time it branches off and it does those two things and it really doesn't matter the order because they're both going to happen either way so for now to keep the flow simple we'll just do this or we're going to email the billing team um and what's going to happen is you know essentially because this is internal because this is internal we already know like the billing email so you know billing@acample.com this is what we're going to feed in because we already know the billing email we don't have to extract this from anywhere um so we have all the info we need we will what else do we need to feed in here so some of these some of these fields we'll have to filter in so some of the extracted fields because like we want to say hey you know we got this invoice on this date um to this client and it's due on this date so we'll have some of the extracted fields we'll have a billing example and then potentially like potentially like previous or like an email template potentially like that's that's something we can think about or we can just prompt an agent to send off the email so yeah okay okay so what we want to do here is actually this what we need to do is the email has to be generated somewhere so before we feed into an emailing team node and let me actually change this so we're going to have green nodes be AI and then blue nodes are going to be not AI so we're going to get another AI node right here which is going to be craft email so we'll connect these pieces once again um and so I hope this I hope you guys can see like this is me trying to figure out the workflow before we get into nit because then we can just plug in these pieces right um and so I didn't even think about this i mean obviously we would have got in there and end and realized okay well we need an email to actually configure these next fields but that's just how it works right so anyways this stuff is actually hooked up to the wrong place we need this to be hooked up over here to the craft email tool so email template will also be hooked up here and then the billing example will be hooked up this is the No this will still go here because that's actually the email team or the email node so email node send email node which is an action and we'll be feeding in this as well as the actual email so the email that's written by AI will be fed in and I think that ends the process right so we'll just add a quick Oops we'll just add a quick yellow note over here and I always my my colors always change but just trying to keep things consistent like in here we're just saying okay the process is going to end now okay so this is our workflow right new invoice PDF comes through we want to extract the text we're using an extract text node which is just going to be a static extract from PDF PDF or convert PDF to text file type of thing we'll get one item sent to an AI node to extract the eight fields we need the eight items will be fed into the next node which is going to update our Google sheet um and I'll just also signify here this is going to be a Google sheet because it's important to understand the integrations and like who's involved in each process so this is going to be AI this is going to be AI and that's going to be an extract node this is going to be a Gmail node and then we have the process end cool so this is our wireframe now we can get into naden and start building out we can see that this is a very very sequential flow we don't need an agent we just need two AI nodes here so let us get into niten and start building this thing so um we know we know what's starting this process which is which is a trigger so I'm going to grab a Google Drive trigger we're going to do um on changes to a specific file or no no specific folder sorry changes involving a specific folder we're going to choose our folder which is going to be the projects folder and we're going to be watching for a file created so we've got our ABC Tech Solutions i'm going to download this as a PDF real quick so download as a PDF i'm going to go to my projects folder in the drive and I'm going to drag this guy in here um there it is okay so there's our PDF we'll come in here and we'll hit fetch test event so we should be getting our PDF okay nice we will just make sure it's the right one so we we should see a ABC Tech Solutions Invoice cool so I'm going to pin this data just so we have it here so just for reference pinning data all it does is just keeps it here so if we were to refresh this this page we'll still have our pinned data which is that PDF to play with but if we would have not pinned it then we would have had to fetch test event once again so not a huge deal with something like this but if you're maybe doing web hooks or API calls you don't want to have to do it every time so you can pin that data um or like an output of an AI node if you don't want to have to rerun the AI but anyway so we have our our PDF we know next based on our wireframe and let me just call this um invoice flow wireframe so we know next is we need to extract text so perfect we'll get right into NADN we'll click on next and we will do an extract from file so let's see we want to extract from PDF and although what do we have here we don't have any binary so we were on the right track here but we forgot that in order to we get the we get the PDF file ID but we don't actually have it so what we need to do here first is um basically download the file because we need the binary to then feed that into the extract text node so we need the binary so sorry if that's like I mean really small but basically in order to extract the text we need to download the file first to get the binary and then we can um actually do that so little little thing we missed in the wireframe but not a huge deal right so we're going to extend this one off we're going to do a Google Drive node once again and we're going to look at download file so now we can say okay we're downloading a file um we can choose from a list but this has to be dynamic because it's going to be based on that new trigger every time so I'm going to do by ID and now on the lefth hand side we can look for the file ID so I'm going to switch to schema real quick um so we can find the the ID of the file we're just going to have to go through so we have a permissions ID right here i don't think that's the right one we have a spaces ID i don't think that's the right one either we're looking for an actual file ID so let's see parents icon link thumbnail link and sometimes you just have to like find it and test things out right so I feel like I probably have just skipped right over it otherwise we'll just try out some of these other IDs maybe it is this one yeah I think Okay sorry i think it is this one because we see the name is right here and the ID is right here so we'll try this we're referencing that dynamically we also see in here we could do a Google file conversion which basically says um you know if it's docs convert it to HTML if it's drawings convert it to that if it's this convert it to that there's not a PDF one so we'll leave this off and we'll hit test step so now we will see we got the invoice we can click view and this is exactly what we're looking at here with the invoice so this is the correct one now since we have it in our binary data over here we have binary now we can extract it from the file so um you know on the left is the inputs on the right is going to be our output so we're extracting from PDF we're looking in the input binary field called data which is right here so I'll hit test step and now we have text so here's the actual text right um the invoice the information we need and out of this is what we're going to pass over to extract so let's go back to the wireframe we have our text extracted now what we want to do is extract um the specific eight fields that we need so hopping back into the workflow we know that this is going to be an AI node so it's going to be an information extractor we have to first of all classify we we know that one item is going in here and that's right here for us in the table which is the actual text of the invoice so we can open this up and we can see this is the text of the invoice we want to do it from attribute description so that's what it's looking for so we can add our eight attributes so we know there's going to be eight of them right so we can create eight but let's just first of all go into our database to see what we want so the first one's invoice number so I'm going to copy this over here invoice number and we just have to describe what that is so I'm just going to say the number of the invoice and this is required we're going to make them all required so number of the invoice then we have the client name paste that in here um these should all be pretty self um explanatory so the name of the client we're going to make it required client email so this is going to be a little bit repetitive but the email of the client and let me just quickly copy this for the next two client address so there's client address and we're going to say the address of the client required and then what's the last one here client phone paste that in there which is obviously going to be the phone number of the client and here we can say is this going to be a string or is it going to be a number i'm going to leave it right now as a string just because over here on the left you can see the phone we have parenthesis in there and maybe we want the format to come over with the parenthesis and the little hyphen so let's leave it as a string for now we can always test and we'll come back but client phone we're going to leave that we have total amount same reason here i'm going to leave this one as a string because I want to keep the dollar sign when we send it over to sheets and we'll see how it comes over but the total amount of the invoice required what's coming next is invoice date and due date so invoice date and due date we can say these are going to be dates so we're changing the var the data type here they're both required and the date the invoice was sent and then we're going to say the date the invoice is due so we're going to make sure this works if we need to we can get in here and make these descriptions more descriptive but for now we're good we'll see if we have any options you're an expert extraction algorithm only extracts relevant information from the text if you do not know the value of the attribute to extract you may omit the attributes value so we'll just leave that as is um and we'll hit test step it's going to be looking at this text and of course we're using AI so we have to connect a chat model so this will also alter the performance right now we're going to go with a Google Gemini 20 flash see if that's powerful enough i think it should be and then we're going to hit play once again so now it's going to be extracting information using AI and what's great about this is that we already get everything out here in its own item so it's really easy to map this now into our Google sheet so let's make sure this is all correct um invoice number that looks good i'm going to open up the actual one yep client name ABC yep client email finance at ABC Tech yep address and phone we have address and phone perfect we have total amount is 141 175 14175 we have um March 8th and March 22nd if we go back up here March 8th March 22nd perfect so that one extracted it well and um okay so we have one item coming out but technically there's eight like properties in there so anyways let's go back to our our uh wireframe so after we extracted the eight items what do we do next we're going to put them into our Google Sheet um database so what we know is we're going to grab a Google Sheets we're going to do an append row because we're adding a row um we already have a credential selected so hopefully we can choose our invoice database it's just going to be the first sheet sheet one and now what happens is we have to map the columns so you can see these are dragable we can grab each one if I go to schema it's a little more apparent so we have these eight items and it's going to be really easy now that we use an information extractor because we can just map you know invoice number to invoice number client name client name email email and it's referencing these variables because every time after we do our information extractor they're going to be coming out as JSON.output and then invoice number and then for client name JSON.output client name so we have these dynamic variables that will happen every single time and obviously I'll show this when we do another example but we can keep mapping everything in and we also did it in that order so it's really really easy to do we're just dragging and dropping and we are finished cool so if I hit test step here this is going to give us a message that says like here are the fields basically so there are the fields they're mapped correctly come into the sheets we now have automatically gotten this updated in our invoice database and um that's that so let me just change some of these nodes so this is going to be update database um this is information extractor extract from file i'm just going to say this is download binary so now we know what's going on in each step and we'll go back to the wireframe real quick what happens after we update the database now we need to craft the email and this is going to be using AI and what's going to go into this is some of the extracted fields and maybe an email template what we're going to do more realistically is just a system prompt so back into nitn let's add a um open AI message and model node so what we're going to do is we're going to choose our model to talk to in this case we'll go 40 mini it should be powerful enough and now we're going to set up our system prompt and our user prompt so at this point if you don't understand the difference the system prompt is the instructions so we're telling this node how to behave so first I'm going to change this node name to create email because that's like obviously what's going on keeping you organized and now how do we explain to this node what its role is so you are an email expert you will receive let me actually just open this up you will receive um invoice information your job is to notify the internal billing team that um an invoice was received receive/s sent okay so honestly I'm going to leave it at that for now it's really simple if we wanted to we can get in here and change the prompting as far as like here is the format here is the way you should be doing it one thing I like to do is I like to say you know this is like your overview and then if we need to get more granular we can give it different sections like output or rules or anything like that i'm also going to say you are an email expert for green grass corp named [Music] um named um Greeny okay so we have Greenie from Green Grass Corp that's our email expert that's going to email the billing team every time this workflow happens so that's the overview now in the user prompt think of this as like when you're talking to chatbt so obviously I had chatbt create these invoices chatgbt this when we say hello that's a user message because this is an interact like an an interaction and it's going to change every time but behind the scenes in this chatbt openai has a system prompt in here that's basically like you're a helpful assistant you help you know users answer questions so this window right here that we type in is our user message and behind the scenes telling the node how to act is our system prompt cool so in here I like to have dynamic information go into the user message while I like to have static information in the actual system prompt so except for maybe the except the exception usually of like giving it the current time and day because that's an expression so anyways let's change this to an expression let's make this full screen we are going to be giving it the invoice information that it needs to write the email because that's what it that's what it's expecting in the system prompt we said you will receive invoice information so first thing is going to be invoice number we are going to grab invoice number and just drag it in we're going to grab client name and just drag it in so it's going to dynamically get these different things every time right so let's say maybe it doesn't even we don't need client email okay maybe we do we want client email um so we'll give it that but the billing team right now doesn't need the address or phone let's just say that but it does want we do want them to know the total amount of that invoice and we definitely want them to know the invoice date and the invoice due date so we can we can now drag in these two things so this was us just being able to customize what the AI node sees just keep in mind if we don't drag anything in here even if it's all on the input the AI node doesn't see any of it so let's hit test step and we'll see the type of email we get we're going to have to make some changes i already know because you know we have to separate everything but what it did is it created a subject which is new invoice received and then the invoice number dear billing team I hope this message finds you well we've received an invoice that requires your attention and then it lists out some information and then it also signs off Greeny Green Grass Corp so first thing we want to do is um if we go back to our wireframe what we have to send in and we didn't document this well enough actually but what goes into here is a um you know in order to send an email we need a two we need a subject and we need the email body so that those are the three things we need the two is coming from here so we know that and the subject and email are going to come from the um craft email node so we have the the two and then actually I'm going to move this up here so now we can just see where we're getting all of our pieces from so the two is coming from internal knowledge this can be hardcoded but the subject and email are going to be dynamic from the AI note cool so what we want to do now is we're going to say output and we're going to tell it how to output information so output output the following parameters separately and we're just going to say subject and email so now it should be outputting two parameters separately but it's not going to because even though it says here's the subject and then it gives us a subject and then it says here's the email and gives us an email they're still in one field meaning if we hook up another node which would be a Gmail send email as we know which is going to be where right here okay so now this is the next node here's the fields we need but as you can see coming out of the create email AI node we have this whole parameter called content which has the subject and the email and we need to get these split up so that we can drag one into the subject and one into the two right so first of all I'm just making these expressions just so we can drag stuff in later um and so that's what we need to do and our fix there is we come into here and we just check this switch that says output content is JSON which will then will rerun and now we'll get subject and body subject and email in two different fields right here we can see which is awesome because then we can open up our send email node we can grab our subject it's going to be dynamic and we can grab our email it's going to be dynamic perfect we're going to change this to text and we're going to add an option down here and we're just going to say append nadn attribution and turn that off because we just don't want to see the message at the bottom that says this was sent by nadn and if we go back to our wireframe wherever that is over here we know that this is the email that's going to be coming through or we're going to be sending to every time because we're sending internally so we can put that right in here not as a variable every time this is going to be sending to billing@acample.com so this really could be fixed it doesn't have to be an expression cool so we will now hit test step and we can see that we got this this email sent so let me open up a new tab let me go into whoa into our Gmail i will go to the sent items and we will see we just got this billing email so obviously it was a fake email but this is what it looks like we've received a new invoice from ABC Tech please find the details below we got invoice number client name client email total amount total invoice date due date please process these this invoice accordingly so that's perfect um we could also if we wanted to we could prompt it a little bit differently to say you know like this has been updated within the database and um you can check it out here so let's do that real quick what we're going to do is we're going to say because we've already updated the database I'm going to come into our Google sheet i'm going to copy this link and I'm going to we're basically going to bake this into the email so I'm going to say we're going to give it a section called email inform the billing team of the invoice let them know we have also updated this in the invoice database and they can view it here and we'll just give them this link to that Google doc so every time they'll just be able to send that over so I'm going to hit test up we should see a new email over here which is going to include that link I hope so there's the link we'll run this email tool again to send a new email hop back into Google Gmail we got a new one and now we can see we have this link so you can view it here we've already updated this in the invoice database we click on the link and now we have our database as well so cool now let's say at this point we're happy with our prompting we're happy with the email this is done if we go back to the wireframe the email is the last node so um maybe just to make it look consistent we will just add over something here that just says nothing and now we know that the process is done because nothing to do so this is basically like this is what we wireframed out so we know that we're happy with this process we understand what's going on um but now let's unpin this data real quick and let's drop in another invoice to make sure that even though it's formatted differently so this XYZ formatted differently but the AI should still be able to extract all the information that we need so I'm going to come in here and download this one as a PDF we have it right there i'm going to drop it into our Google Drive so we have XYZ Enterprises now come back into the workflow and we'll hit test fetch test event let's just make sure this is the right one so XYZ Enterprises nice and I'm just going to hit test workflow and we'll watch it download extract get the information update the database create the email send the email and then nothing else should happen after that so boom we're done let's click into our email here we have our new invoice received so it updated differently like the subjects dynamic because it was from XYZ a different invoice number as you remember the ABC one it started with TH AI and this one starts with INV so that's why the subject is different dear billing team we have received a new invoice from XYZ Enterprises please find the details below there's the number the name all this kind of information um the total amount was 13856 let's go make sure that's right total amount 13856 um March 8th March 22nd once again is that correct march 8th March 22nd nice and finance XYZ XYZ perfect okay the invoice has been updated in the database you can view it here so let's click on that link nice we got our information populated into the spreadsheet as you can see it all looks correct to me as well our strings are coming through nice and our dates are coming through nice so I'm going to leave it as is now keep in mind because these are technically coming through as strings um that's fine for phone but Google Sheets automatically made these numbers I believe so if we wanted to we could sum these up because they're numbers perfect okay cool so that's how that works right um that's the email we wireframed it out we tested it with two different types of invoices they weren't consistent formatting which means we couldn't probably have used a code node but the AI is able to read this and extract it as you can see right here we got the same eight items extracted that we were looking for so that's perfect um cool so going to call this one here i will yeah I will attach the actual flow and I will attach the just a picture of this wireframe I suppose in this um post and by now you guys have already seen that I'm sure but yeah I hope this was helpful um the whole process of like the way that I approached and I know this was a 35minut build so it's not like the same as like building something more complex but as far as like a general workflow you know this is a pretty solid solid one to get started with um it it shows elements of using AI within a simple workflow that's going to be sequential and it shows like you know the way we have to reference our variables and how we have to drag things in and um obviously the component of like wireframing out in the beginning to understand the full flow at least 80% 85% of the full flow before you get in there so cool hope you guys enjoy this one and I will see you guys in the community thanks all right all right I hope you guys enjoyed those step-by-step builds hopefully right now you're feeling like you're in a really good spot with Naden and everything starting to piece together this next video we're going to move into is about APIs because in order to really get more advanced with our workflows and our AI agents we have to understand the most important thing which is APIs they let our Nin workflows connect to anything that you actually want to use so it's really important to understand how to set up and when you understand it the possibilities are endless and it's really not even that difficult so let's break it down if you're building AI agents but you don't really understand what an API is or how to use them don't worry you're not alone i was in that exact same spot not too long ago i'm not a programmer i don't know how to code but I've been teaching tens of thousands of people how to build real AI systems and what changed the game for me was when I understood how to use APIs so in this video I'm going to break it down as simple as possible no technical jargon and by the end you'll be confidently setting up API calls within your own Agentic workflows let's make this easy so the purpose of this video is to understand how to set up your own requests so you can access any API because that's where the power truly comes in and before we get into NDN and we set up a couple live examples and I show you guys my thought process when I'm setting up these API calls first I thought it would just be important to understand what an API really is and APIs are so so powerful because let's say we're building agents within NADN basically we can only do things within NADN's environment unless we use an API to access some sort of server so whether that's like a Gmail or a HubSpot or Air Table whatever we want to access that's outside of Niden's own environment we have to use an API call to do so and so that's why at the end of this video when you completely understand how to set up any API call you need it's going to be a complete gamecher for your workflows and it's also going to unlock pretty much unlimited possibilities all right now that we understand why APIs are important let's talk about what they actually do so API stands for application programming interface and at the highest level in the most simple terms it's just a way for two systems to talk to each other so NAND and whatever other system we want to use in our automations so keeping it limited to us it's our NAN AI agent and whatever we want it to interact with okay so I said we're going to make this as simple as possible so let's do it what we have here is just a scenario where we go to a restaurant so this is us right here and what we do is we sit down and we look at the menu and we look at what food that the restaurant has to offer and then when we're ready to order we don't talk directly to the kitchen or the chefs in the kitchen we talk to the waiter so we'd basically look at the menu we'd understand what we want then we would talk to the waiter and say "Hey I want the chicken parm." The waiter would then take our order and deliver it to the kitchen and after the kitchen sees the request that we made and they understand okay this person wants chicken parm i'm going to grab the chicken parm not the salmon and then we're basically going to feed this back down the line through the waiter all the way back to the person who ordered it in the first place and so that's how you can see we use an HTTP request to talk to the API endpoint and receive the data that we want and so now a little bit more of a technical example of how this works in NADN okay so here is our AI agent and when it wants to interact with the service it first has to look at that services API documentation to see what is offered once we understand that we'll read that and we'll be ready to make our request and we will make that request using an HTTP request from there that HTTP request will take our information and send it to the API endpoint the endpoint will look at what we ordered and it will say "Okay this person wants this data so I'm going to go grab that i'm going to send it back send it back to the HTTP request." And then the HTTP request is actually what delivers us back the data that we asked and we know that it was available because we had to look at the API documentation first so I hope that helps i think that looking at it visually makes a lot more sense especially when you hear you know HTTP API endpoint all this kind of stuff but really it's just going to be this simple so now let me show an example of what actually this looks like in Naden and when you would use one and when you wouldn't need to use one so here we have two examples where we're accessing a service called open weather map which basically just lets us grab the weather data from anywhere in the world and so on the left what we're doing is we're using open weather's native integration within nadn and so what I mean by native integration is just that when we go into nadn and we click on the plus button to add an app and we want to see like you know the different integrations it has air tableable it has affinity it has airtop it has all these AWS things it has a ton of native integrations and all that a native integration is is an HTTP request but it's just like wrapped up nicely in a UI for us to basically fill in different parameters and so once you realize that it really clears everything up because the only time you actually need to use an HTTP request is if the service you want to use is not listed in this list of all the native integrations anyways let me show you what I mean by that so like I said on the left we have Open Weather Maps native integration so basically what we're doing here is we're sending over okay I'm using open weather map i'm going to put in the latitude and the longitude of the city that I'm looking for and as you can see over here what we get back is Chicago as well as a bunch of information about the current weather in Chicago and so if you were to fill this out it's super super intuitive right all you do is put in the Latin long you choose your format as far as imperial or metric and then you get back data and that's the exact same thing we're doing over here where we use an HTTP request to talk to Open Weather's API endpoint and so this is just looks a little more scary and intimidating because we have to set this up ourselves but if we zoom in we can see it's pretty simple we're making a git request to open weather maps URL endpoint and then we're putting over the lat and the long which is basically the exact same from the one on the left and then as you can see we get the same information back about Chicago and then some weather information about Chicago and so the purpose of that was just to show you guys that these native integrations all we're doing is we're accessing some sort of API endpoint it just looks simpler and easier and there's a nice user interface for us rather than setting everything up manually okay so hopefully that's starting to make a little more sense let's move down here to the way that I think about setting up these HTTP requests which is we're basically just setting up filters and making selections all we're doing is we're saying okay I want to access server X when I access server X I need to tell it basically what do I want from you so it's the same way when you're going to order some pizza you have to first think about which pizza shop do I want to call and then once you call them it's like okay I need to actually order something it has to be small medium large it has to be pepperoni or cheese you have to tell it what you want and then they will send you the data back that you asked for so when we're setting these up we basically have like five main things to look out for the first one you have to do every time which is a method and the two most common are going to be a get or a post typically a get is when you're just going to access an endpoint and you don't have to send over any information you're just going to get something back but a post is when you're going to send over certain parameters and certain data and say okay using this information send me back what I'm asking for the great news is and I'll show you later when we get into any end to actually do a live example it'll always tell you to say you know is this a get or a post then the next thing is the endpoint you have to tell it like which website or you know which endpoint you want to actually access which URL from there we have three different parameters to set up and also just realize that this one should say body parameters but this used to be the most confusing part to me but it's really not too bad at all so let's break it down so keep in mind when we're looking at that menu that API documentation it's always going to basically tell us okay here are your query parameters here are your header parameters and here are your body parameters so as long as you understand how to read the documentation you'll be just fine but typically the difference here is that when you're setting up query parameters this is basically just saying a few filters so if you search pizza into Google it'll come google.com/arch which would be Google's endpoint and then we would have a question mark and then Q equals and then a bunch of different filters so as you can see right here the first filter is just Q equals pizza and the Q is you know it stands for query parameters and you don't even have to understand that that's just me showing you kind of like a real example of how that works from there we have to set up a header parameter which is pretty much always going to exist and I basically just think of header parameters as you know authorizing myself so usually when you're doing some sort of API where you have to pay you have to get a unique API key and then you'll send that key and if you don't put your key in then you're not going to be able to get the data back so like if you're ordering a pizza and you don't give them your credit card information they're not going to send you a pizza and usually an API key is something you want to keep secret because let's say you know you put 10 bucks into some sort of API that's going to create images for you if that key gets leaked then anyone could use that key and could go create images for themselves for free but they'd be running down your credits and these can come in different forms but I just wanted to show you a really common one is you know you'll have your key value pairs where you'll put authorization as the name and then in the value you'll put bearer space your API key or in the name you could just put API_key and then in the value you'd put your API key but once again the API documentation will tell you how to configure all this and then finally the body parameters if you need to send something over to get something back let's say we're you know making an API call to our CRM and we want to get back information about John we could send over something like name equals John the server would then grab all records that have name equal John and then it would send them back to you so those are basically like the five main things to look out for when you're reading through API documentation and setting up your HTTP request but the beautiful thing about living in 2025 is that we now have the most beautiful thing in the world which is a curl command and so what a curl command is is it lets you hit copy and then you basically can just import that curl into nadn and it will pretty much set up the request for you then at that point it really is just like putting in your own API key and tweaking a few things if you want to so let's take a look at this curl statement for a service called Tavi as you can see that's the endpoint is api.tavi.com all this basically does is it lets you search the internet so you can see here this curl statement tells us pretty much everything we need to know to use this so it's telling us that it's going to be a post it's showing us the API endpoint that we're going to be accessing it shows us how to set up our header so that's going to be authorization and then it's going to be bearer space API token it's basically just telling us that we're going to get this back in JSON format and then you can see all of these different key value pairs right here in the data section and these are basically going to be body parameters where we can say you know query is who is Leo Messi so that's what we' be searching the internet for we have topic equals general we have search depth equals basic so hopefully you can see all of these are just different filters where we can choose okay do we want you know do we want one max result or do we want four or do we have a time range or do we not so this is really just at the end of the day it's basically like ordering Door Dash because what we would have up here is you know like what actual restaurant do we want to order food from we would put in our credit card information we would say do we want this to be delivered to us do we want to pick it up we would basically say you know do you want a cheeseburger no pickles no onions like what are the different things that you want to flip do you want a side do you want fries or do you want salad like what do you want and so once you get into this mindset where all I have to do is understand this documentation and just tweak these little things to get back what I want it makes setting up API calls so much easier and if another thing that kind of intimidates you is the aspect of JSON it shouldn't because all it is is a key value pair like we kind of talked about you know this is JSON right here and you're going to send your body parameter over as JSON and you're also going to get back JSON so the more and more you use it you're going to recognize like how easy it is to set up so anyways I hope that that made sense and broke it down pretty simply now that we've seen like how it all works it's going to be really valuable to get into niten i'm going to open up a API documentation and we're just going to set up a few requests together and we'll see how it works okay so here's the example you know I did open weather's native integration and then also open weather as an HTTP request and you can see it was like basically the exact same thing um so let's say that what we want to do is we want to use Perplexity which if you guys don't know what Perplexity is it is basically you know kind of similar to Chatbt but it has really good like internet search and research so let's say we wanted to use this and hook it up to an AI agent so it can do web search for us but as you can see if I type in Perplexity there's no native integration for Perplexity so that basically signals to us okay we can only access Perplexity using an HTTP request and real quick side note if you're ever thinking to yourself hm I wonder if I can have my agent interact with blank the answer is yes if there's API documentation and all you have to do typically to find out if there's API documentation is just come in here and be like you know Gmail API documentation and then we can see Gmail API is a restful API which means it has an API and we can use it within our automations anyways getting back to this example of setting up a perplexity HTTP request we have our HTTP request right here and it's left completely blank so as you can see we have our method we have our endpoint we have query header and body parameters but nothing has been set up yet so what we need to do is we would head over to Perplexity as you can see right here and at the bottom there's this little thing called API so I'm going to click on that and this opens up this little page and so what I have here is Perplexity's API if I click on developer docs and then right here I have API reference which is integrate the API into your workflows which is exactly what we want to do this page is where people might get confused and it looks a little bit intimidating but hopefully this breakdown will show you how you can understand any API doc especially if there's a curl command so all I'm going to do first of all is I'm just going to right away hit copy and make sure you know you're in curl if you're in Python it's not the same so click on curl i copied this curl command and I'm going to come back into nit hit import curl and all I have to do is paste click import and basically what you're going to see is this HTTP request is going to get basically populated for us so now we have the method has been changed to post we have the correct URL which is the API endpoint which basically is telling this node okay we're going to use Perplexity's API you can see that the curl had no query parameters so that's left off it did turn on headers which is basically just having us put our API key in there and then of course we have the JSON body that we need to send over okay so at this point what I would do is now that we have this set up we know we just need to put in a few things of our own so the first thing to tackle is how do we actually authorize ourselves into Perplexity all right all right so I'm back in Perplexity i'm going to go to my account and click on settings and then all I'm going to do is basically I need to find where I can get my API key so on the lefth hand side if I go all the way down I can see API keys so I'll click on that and all this is going to do is this shows my API key right here so I'll have to click on this hit copy come back into NN and then all I'm going to do is I'm going to just delete where this says token but I'm going to make sure to leave a space after bearer and hit paste so now this basically authorizes ourselves to use Perplexity's endpoint and now if we look down at the body request we can see we have this thing set up for us already so if I hit test step this is real quick going to make a request over it just hit Perplexity's endpoint and as you can see it came back with data and what this did is it basically searched Perplexity for how many stars are there in our galaxy and that's where right here we can see the Milky Way galaxy which is our galaxy is estimated to contain between 100 billion and 400 billion stars blah blah blah so we know basically okay if we want to change how this endpoint works what data we're going to get back this right here is where we would change our request and if we go back into the documentation we can see what else we have to set up so the first thing to notice is that there's a few things that are required and then some things that are not so right here we have you know authorization that's always required the model is always required like which perplexity model are we going to use the messages are always required so this is basically a mix of a system message and a user message so here the example is be precise and concise and then the user message is how many stars are there in the galaxy so if I came back here and I said you know um be funny in your answer so I'm basically telling this model how to act and then instead of how many stars are there in the galaxy I'm just going to say how long do cows live and I'll make another request off to perplexity so you can see what comes back is this longer content so it's not being precise and concise and it says so you're wondering how long cows live well let's move into the details so as you can see it's being funny okay back into the API documentation we have a few other things that we could configure but notice how these aren't required the same way that these ones are so we have max tokens we could basically put in an integer and say how many tokens do you want to use at the maximum we could change the temperature which is you know like how random the response would be and this one says you know it has to be between zero and two and as we keep scrolling down you can see that there's a ton of other little levers that we can just tweak a little bit to change the type of response that we get back from Plexity and so once you start to read more and more API documentation you can understand how you're really in control of what you get back from the server and also you can see like you know sometimes you have to send over booleans which is basically just true or false sometimes you can only send over numbers sometimes you can only send over strings and sometimes it'll tell you you know like what will the this value default to and also what are the only accepted values that you actually could fill out so for example if we go back to this temperature setting we can see it has to be a number and if you don't fill that out it's going to be 0.2 but we can also see that if you do fill this out it has to be between zero or two otherwise it's not going to work okay cool so that's basically how it works we just set up an HTTP request and we change the system prompt and we change the user prompt and that's how we can customize this thing to work for us and that's really cool as a node because we can set up you know a workflow to pass over some sort of variable into this request so it searches the web for something different every time but now let's say we want to give our agent access to this tool and the agent will decide what am I going to search the web for based on what the human asks me so it's pretty much the exact same process we'll click on add a tool and we're going to add an HTTP request tool only because Plexity doesn't have a native integration and then once again you can see we have an import curl button so if I click on this and I just import that same curl that we did last time once again it fills out this whole thing for us so we have post we have the perplexity endpoint we have our authorization bearer but notice we have to put in our token once again and so a cool little hack is let's say you know you're going to use perplexity a lot rather than having to go grab your API key every single time what we can do is we can just send it over right here in the authentication tab so let me show you what I mean by that if I click into authentication I can click on generic credential type and then from here I can basically choose okay is this a basic O a bearer O all this kind of stuff a lot of times it's just going to be header off so that's why we know right here we can click on header off and as you can see we know that because we're sending this over as a header parameter and we just did this earlier and it worked so as you can see I have header offs already set up i probably already have a Plexity one set up right here but I'm just going to go ahead and create a new one with you guys to show you how this works so I just create a new header off and all we have to do is the exact same thing that we had down in the request that we just sent over which means in the name we're just going to type in authorization with a capital A and once again we can see in the API docs this is how you do it so authorization and then we can see that the value has to be capital B bearer space API token so I'm just going to come into here bearer space API token and then all I have to do is you know first of all name this so we can can save it and then if I hit save now every single time we want to use perplexity's endpoint we already have our credentials saved so that's great and then we can turn off the headers down here because we don't need to send it over twice so now all we have to do is change this body request a little bit just to make it more dynamic so in order to make it dynamic the first thing we have to do is change this to an expression now we can see that we can basically add a variable in here and what we can do is we can add a variable that basically just tells the AI model the AI agent here is where you're going to send over your internet search query and so we already know that all that that is is the user content right here so if I delete this and basically if I do two curly braces and then within the curly braces I do a dollar sign and I type in from I can grab a from AI function and this from AI function just indicates to the AI agent I need to choose something to send over here and you guys will see an example and it will make more sense i also did a full video breaking this down so if you want to see that I'll tag it right up here anyways as you can see all we have to really do is enter in a key so I'm just going to do you know two quotes and within the quote I'm going to put in search term and so now the agent will be reading this and say okay whenever the user interacts with me and I know I need to search the internet I'm just going to fill this whole thing in with the search term so now that that's set up I'm just going to change this request to um actually I'm just going to call it web search to make that super intuitive for the AI agent and now what we're going to do is we are going to talk to the agent and see if it can actually search the web okay so I'm asking the AI agent to search the web for the best movies it's going to think about it it's going to use this tool right here and then we'll basically get to go in there and we can see what it filled in in that search term placeholder that we gave it so first of all the answer it gave us was IMDb top 250 um Rotten Tomatoes all this kind of stuff right so that's movie information that we just got from Perplexity and what I can do is click into the tool and we can see in the top left it filled out search term with best movies and we can even see that in action if we come down to the body request that it sent over and we expand this we can see on the right hand side in the result panel this is the JSON body that it sent over to Perplexity and it filled it in with best movies and then of course what we got back was our content from Perplexity which is you know here are some of the best movies across major platforms all right then real quick before we wrap up here I just wanted to talk about some common responses that you can get from your HTTP requests so the rule of thumb to follow is if you get data back and you get a 200 you're good sometimes you'll get a response back but you won't explicitly see a 200 message but if you're getting the data back then you're good to go and a quick example of this is down here we have that HTTP request which we went over earlier in this video where we went to open weather maps API and you can see down here we got code 200 and there's data coming back and 200 is good that's a success code now if you get a request in the 400s that means that you probably set up the request wrong so 400 bad request that could mean that your JSON's invalid it could just mean that you have like an extra quotation mark or you have you know an extra comma something as silly as that so let me show a quick example of that we're going to test this workflow and what I'm doing is I'm trying to send over a query to Tavi and you can see what we get is an error that says JSON parameter needs to be valid JSON and this would be a 400 error and the issue here is if we go into the JSON body that we're trying to send over you can see in the result panel we're trying to send over a query that has basically two sets of quotation marks if you can see that but here's the great news about JSON it is so universally used and it's been around for so long that we could basically just copy the result over to chatbt paste it in here and say I'm getting an error message that says JSON parameter needs to be valid JSON what's wrong with my JSON and as you can see it says the issue with your JSON is the use of double quotes around the string value in this line so now we'd be able to go fix that and if we go back into the workflow we take away these double quotes right here test the step again now you can see it's spinning and it's going to work and we should get back some information about pineapples on pizza another common error you could run into is a 401 meaning unauthorized this typically just means that your API key is wrong you could also get a 403 which is forbidden that just means that maybe your account doesn't have access to this data that you're requesting or something like that and then another one you could get is a 404 which sometimes you'll get that if you type in a URL that doesn't exist it just means this doesn't exist we can't find it and a lot of times when you're looking at the actual API documentation that you want to set up a request to so here's an example with Tavi it'll show you what typical responses could look like so here's one where you know we're using Tavi to search for who is Leo Messi this was an example we looked at earlier and with a 200 response we are getting back like a query an answer results stuff like that we could also see we could get a 400 which would be for bad request you know invalid topic we could have a 401 which means invalid API key we could get all these other ones like 429 432 but in general 400 is bad and then even worse is a 500 and this just basically means something's wrong with the server maybe it doesn't exist anymore or there's a bug on the server side but the good news about a 500 is it's not your fault you didn't set up the request wrong it just means something's wrong with the server and it's really important to know that because if you think you did something wrong but it's really not your fault at all you may be banging your head against the wall for hours so anyways what I wanted to highlight here is there's never just like a one-sizefits-all i know how to set up this one API call so I can just set up every single other API call the exact same way the key is to really understand how do you read the API documentation how do you set up your body parameters and your different header parameters and then if you start to run into issues the key is understanding and actually reading the error message that you're getting back and adjusting from there all right so that's going to do it for this video hopefully this has left you feeling a lot more comfortable with diving into API documentation walking through it just step by step using those curl commands and really just understanding all I'm doing is I'm setting up filters and levers here i don't have to get super confused it's really not that technical i'm pretty much in complete control over what my API is going to send me back the same way I'm in complete control when I'm you know ordering something on Door Dash or ordering something on Amazon whatever it is hopefully by now the concept of APIs and HTTP requests makes a lot more sense but really just to drive it home what we're going to do is hop into some actual setups in NADN of connecting to some different popular APIs and walk through a few more step by steps just to really make sure that we understand the differences that can come with different API documentation and how you read it and how you set up stuff like your credentials and the body requests so let's move into this next part which I think is going to be super valuable to see different API calls in action okay so in nodn when we're working with a large language model whether that's an AI agent or just like an AI node what happens is we can only access the information that is in the large language models training data and a lot of times that's not going to be super up-to-date and real time so what we want to do is access different APIs that let us search the web or do real-time search and what we saw earlier in that third step-by-step workflow was we used a tool called Tavi and we accessed it through an HTTP request node which as you guys know looks like this and we were able to use this to communicate with Tavali's API server so if we ever want to access real-time information or do research on certain search terms we have to use some sort of API to do that so like I said we talked about Tavi but in this video I'm going to help you guys set up Perplexity which if you don't know what it is it's kind of like Chat GBT but it's really really good for web search and in-depth research and it has that same sort of like you know chat interface as chatbt but what you also have is access to the API so if I click on API we can see this little screen but what we want to go to is the developer docs and in the developer docs what we're looking for is the API reference we can also click on the quick start guide right here which just shows you how you can set up your API key and get all that kind of stuff so that's exactly what we're going to do is set up an API call to Perplexity so I'm going to click on API reference and what we see here is the endpoint to access Perplexi's API and so what I'm going to do is just grab this curl command from that right hand side go back into our NEN and I'm just going to import the curl right into here and then all we have to do from there is basically configure what we want to research and put in our own API key so there we go we have our node pretty much configured and now the first thing we see we need to set up is our authorization API key and what we could do is set this up in here as a generic credential type and save it but right now we're just going to keep things as simple as possible where we imported the curl and now I'm just going to show you where to plug in little things so we have to go back over to Perplexity and we need to go get an API key so I'm going to come over here to the left and I'm going to click on my settings and hopefully in here we're able to find where our API key lives now we can see in the bottom left over here we have API keys and what I'm going to do is come in here and just create a new secret key and we just got a new one generated so I'm just going to click on this button click on copy and all we have to do is replace the word right here that says token so I'm just going to delete that i'm going to make sure to leave a space after the word bearer and I'm going to paste in my Perplexity API key so now we should be connected and now what we need to do is we need to set up the actual body request so if I go back into the documentation we can see this is basically what we're sending over so that first thing is a model which is the name of the model that will complete your prompt and if we wanted to look at different models we could click into here and look at other supported models from Perplexity so it took us to the screen we click on models and we can see we have Sonar Pro or Sonar we have Sonar Deep Research we have some reasoning models as well but just to keep things simple I'm going to stick with the default model right now which is just sonar then we have an object that we're sending over which is messages and within the messages object we have a few things so first of all we're sending over content which is the contents of the message in turn of conversation it can be in a string or an array of parts and then we have a role which is going to be the role of the speaker in the conversation and we have available options system user or assistant so what you can see in our request is that we're sending over a system message as well as a user message and the system message is basically the instructions for how this AI model on perplexity should act and then the user message is our dynamic search query that is going to change every time and if we go back into the documentation we can see that there are a few other things we could add but we don't have to we could tell Perplexity what is the max tokens we want to use what is the temperature we want to use we could have it only search for things in the past week or day so this documentation is basically going to be all the filters and settings that you have access to in order to customize the type of results that you want to get back but like I said keeping this one really simple we just want to search the web all I'm going to do is keep it as is and if I disconnect this real quick and we come in and test step it's basically going to be searching perplexity for how many stars are there in our galaxy and then the AI model of sonar is the one that's going to grab all of these five sources and it's going to answer us and right here it says the Milky Way galaxy which is our home galaxy is estimated to contain between 100 billion and 400 billion stars this range is due to the difficulty blah blah blah blah blah so that's basically how it was able to answer us because it used an AI model called sonar so now if we wanted to make this search a little bit more dynamic we could basically plug this in and you can see in here what I'm doing is I'm just setting a search term so let's test this step what happens is the output of this node is a research term then we could reference that variable of research term right in here in our actual body request to perplexity so I would delete this fixed message which is how many stars are there in our galaxy and all I would do is I'd drag in research term from the left put it in between the two quotes and now it's coming over dynamically as anthropic latest developments and all I'd have to do now is hit test step and we will get an answer from Perplexity about Anthropic's recent developments there we go it just came back we can see there's five different sources right here it went to Anthropic it went to YouTube it went to TechCrunch and what we get is that today May 22nd so real time information Claude Opus 4 was released and that literally came out like 2 or 3 hours ago so that's how we know this is searching the web in real time and then all we'd have to do is have you know maybe an AI model is changing our search term or maybe we're pulling from a Google sheet with a bunch of different topics we need to research but whatever it is as long as we are passing over that variable this actual search result from Perplexity is going to change every single time and that's the whole point of variables right they they vary they're dynamic so I know that one was quick but Perplexity is a super super versatile tool and probably an API that you're going to be calling a ton of times so just wanted to make sure I threw that in there so Firecall is going to allow us to turn any website into LLM ready data in a matter of seconds and as you can see right here it's also open source so once you get over to Firecol click on this button and you'll be able to get 500 free credits to play around with as you can see there's four different things we can do with Firecrawl we can scrape we can crawl we can map or we can do this new extract which basically means we can give firecraw a URL and also a prompt like can you please extract the company name and the services they offer and an icebreaker out of this URL so there's some really cool use cases that we can do with firecrawl so in this video we're going to be mainly looking at extract but I'm also going to show you the difference between scrape and extract and we're going to get into end and connect up so you can see how this works but the playground is going to be a really good place to understand the difference between these different endpoints all right so for the sake of this video this is the website we're going to be looking at it's called quotes to scrape and as you can see it's got like 10 on this first page and it also has different pages of different categories of quotes and as you can see if we click into them there are different quotes so what I'm going to do is go back to the main screen and I'm going to copy the URL of this website and we're going to go into niten we're going to open up a new node which is going to be an HTTP request and this is just to show you what a standard get request to a static website looks like so we're going to paste in the URL hit test step and on the right hand side we're going to get all the HTML back from the quotes to scrape website like I said what we're looking at here is a nasty chunk of HTML it's pretty hard for us to read but basically what's going on here is this is the code that goes to the website in order to have it be styled and different fonts and different colors so right here what we're looking at is the entire first page of this website so if we were to search for Harry if I copy this we go back into edit and we control F this you can see there is the exact quote that has the word Harry so everything from the website's in here it's just wrapped up in kind of an ugly chunk of HTML now hopping back over to the fireall playground using the scrape endpoint we can replace that same URL we'll run this and it's going to output markdown formatting so now we can see we actually have everything we're looking for with a different quotes and it's a lot more readable for a human so that's what a web scrape is right we get the information back whether that's HTML or markdown but then we would typically feed that into some sort of LLM in order to extract the information we're looking for in this case we'd be looking for different quotes but what we can do with extract is we can give it the URL and then also say hey get all of the quotes on here and using this method we can say not just these first 10 on this page i want you to crawl through the whole site and basically get all of these quotes all of these quotes all of these quotes all of these quotes so it's going to be really cool so I'm going to show how this works in firecrawl and then we're going to plug it into noden all right so what we're doing here is we're saying extract all of the quotes and authors from this website i gave it the website and now what it's doing is it's going to generate the different parameters that the LLM will be looking to extract out of the content of the website okay so here's the run we're about to execute we have the URL and then we have our schema for what the LLM is going to be looking for and it's looking for text which would be the quote and it's a string and then it's also going to be looking for the author of that quote which is also a string and then the prompt we're feeding here to the LLM is extract all quotes and their corresponding authors from the website so we're going to hit run and we're going to see that it's not only going to go to that first URL it's basically going to take that main domain which is quotes to scrape.com and it's going to be crawling through the other sections of this website in order to come back and scrape all the quotes on there also quick plug go ahead and use code herk10 to get 10% off the first 12 months on your Firecrawl plan okay so it just finished up as you can see we have 79 quotes so down here we have a JSON response where it's going to be an object called quotes and in there we have a bunch of different items which has you know text author text author text author and we have pretty much everything from that website now okay cool but what we want to do is look at how we can do this in n so that we have you know a list of 20 30 40 URLs that we want to extract information from we can just loop through and send off that automation rather than having to come in here and type that out in firecrawl okay so what we're going to do is go back into edit end and I apologize because there may be some jumping around here but we're basically just gonna clear out this HTTP request and grab a new one now what we're going to do is we want to go into Firecrawl's documentation so all we have to do is import the curl command for the extract endpoint rather than trying to figure out how to fill out these different parameters so back in Firecrawl once you set up your account up in the top right you'll see a button called docs you want to click into there and now we can see a quick start guide we have different endpoints and what we're going to do is on the left scroll down to features and click on extract and this is what we're looking for so we've got some information here the first thing to look at is when we're using the extract you can extract structured data from one or multiple URLs including wild cards so what we did was we didn't just scrape one single page we basically scraped through all of the pages that had the main base domain of um quotescrape.com or something like that and if you put a asterk after it it's going to basically mean this is a wild card and it's going to go scrape all pages that are after it rather than just scraping this one predefined page as you can see right here it'll automatically crawl and parse all the URLs it can discover then extract the requested data and we can see that's how it worked because if we come back into the request we just made we can see right here that it added a slash with an asterisk after quotes to scrape.com okay anyway so what we're looking for here is this curl command this is basically going to fill out the method which is going to be a post request it's going to fill out the endpoint it'll fill out the content type and it'll show us how to set up our authorization and then we'll have a body request that we'll need to make some minor changes to so in the top right I'm going to click copy and I'm going to come back into edit end hit import curl paste that in there hit import and as you can see everything pretty much just got populated so like I said the method is going to be a post we have the endpoint already set up and what I want to do is show you guys how to set up this authorization so that we can keep it saved forever rather than having to put it in here in the configuration panel every time so first of all head back over to your firecrawl go to API keys on the lefth hand side and you're just going to want to copy that API key so once you have that copied head back into NN and now let's look at how we actually set this up so typically what you do is we have this as a header parameter not all authorizations are headers but this one is a header and the key or the name is authorization and the value is bearer space your API key so what you'd typically do is just paste in your API key right there and you'd be good to go but what we want to do is we want to save our firecrawl credential the same way you'd save you know a Google Sheets credential or a Slack credential so we're going to come into authentication click on generic we're going to click on generic type and choose header because we know down here it's a header off and then you can see I have some other credentials already saved we're going to create a new one i'm just going to name this firecrawl to keep ourselves organized for the name we're going to put authorization and for the value we're going to type bearer with a capital B space and then paste in our API key and we'll hit save and this is going to be the exact same thing that we just did down below except for now we have it saved so we can actually flick this field off we don't need to send headers because we're sending them right here and now we just need to figure out how to configure this body request okay so I'm going to change this to an expression and open it up just so we can take a look at it the first thing we notice is that by default there are three URLs in here that we would be extracting from we don't want to do that here so I'm going to grab everything within the array but I'm going to keep the two quotation marks now all we need to do is put the URL that we're looking to extract information from in between these quotation marks so here I just put in the quotes to scrape.com but what we want to do if you remember is we want to put an asterisk after that so that it will go and crawl all of the pages not just that first page and which would only have like nine or 10 quotes and now the rest is going to be really easy to configure because we already did this in the playground so we know exactly what goes where so I'm going to click back into our playground example first thing is this is the quote that firecross sent off so I'm going to copy that go back and edit in and I'm just going to replace the prompts right here we don't want the company mission blah blah blah we want to paste this in here and we're looking to extract all quotes and their corresponding authors from the website and then next is basically telling the LLM what are you pulling back so we just told it it's pulling back quotes and authors so we need to actually make the schema down here in the body request match the prompt so all we have to do is go back into our playground right here is the schema that we sent over in our example and I'm just going to click on JSON view and I'm going to copy this entire thing which is wrapped up in curly braces we'll come back into end and we'll start after schema colon space replace all this with what we just had in um fire crawl and actually I think I've noticed the way that this copied over it's not going to work so let me show you guys that real quick if we hit test step it's going to say JSON parameter needs to be valid JSON so what I'm going to do is I'm going to copy all of this now I came into chat GBT and I'm just saying fix this JSON what it's going to do is it's going to just basically push these over when you copy it over from Firecrol it kind of aligns them on the left but you don't want that so as you can see it just basically pushed everything over we'll copy this into our Nit end right there and all it did was bump everything over once and now we should be good to go so real quick before we test this out I'm just going to call this extract and then we'll hit test step and we should see that it's going to be pulling and it's going to give us a message that says um true and it gives us an ID and so now what we need to do next is pull this ID back to see if our request has been fulfilled yet so I'm back in the documentation and now we are going to look at down here asynchronous extraction and status checking so this is how we check the status of a request as you saw we just made one so here I'm going to click on copy this curl command we're going to come back and end it in and we're going to add another HTTP request and we're going to import that in there and you can see this one is going to be a get command it's going to have a different endpoint and what we need to do if you look back at the documentation is at the end of the extract slash we have to put the extract ID that we're looking to check the status of so back in n the ID is going to be coming from the left hand side the previous node every time so I'm just going to change the URL field to an expression put a backslash and then I'm going to grab the ID pull it right in there and we're good to go except we need to set up our credential and this is why it's great we already set this up as a generic as a header and now we can just pull in easily our fire crawl off and hit test step so what happens now is our request hasn't been done yet so as you can see it comes back as processing and the data is an empty array so what we're going to set up real quick is something called polling where we're basically checking in on a specific ID which is this one right here and we're going to check and if it's if it's empty if the data field is empty then that means we're going to wait a certain amount of time and come back and try again so after the request I'm going to add a if so this is just basically going to help us create our filter so we're dragging in JSON.data which as you can see is an empty array and we're just going to say is empty but one thing you have to keep in mind is this doesn't match as you can see we're dragging in an array and we were trying to do a filter of a string so we have to go to array and then say is empty and we'll hit test step and this is going to say true the data field is empty and so if true what we want to do is we're going to add a wait and this will wait for you know let's in in this case we'll just say five seconds so if we hit test step it's going to wait for five seconds and um I wish actually I switched the logic so that this would be on the bottom but whatever and then we would just drag this right back into here and we would try it again so now after 5 seconds had passed or however much time we would try this again and now we can see that we have our item back and the data field is no longer empty because we have our quotes object which has 83 quotes so even got more than that time we did it in the playground and I'm thinking this is just because you know the extract is kind of still in beta so it may not be super consistent but that's still way better than if we were to just do a simple getit request and then as you can see now if we ran this next step this would come out ah but this is interesting so before it knows what it's pulling back the JSON.data field is an array and so we're able to set up is the array empty but now it's an object so we can't put it through the same filter because we're looking at a filter for an array so what I'm thinking here is we could set up this continue using error output so because this this node would error we could hit test step and we could see now it's going to go down the false branch and so this basically just means it's going to let us continue moving through the process and we could do then whatever we want to do down here obviously this isn't perfect because I just set this up to show you guys and ran into that but that's typically sort of the way we would think is how can we make this a little more dynamic because it has to deal with empty arrays or potentially full objects anyways what I wanted to show you guys now is back in our request if we were to get rid of this asterk what would happen so we're just going to run this whole process again i'll hit test workflow and now it's going to be sending that request only to you know one URL rather than the other one aha and I'm glad we are doing live testing because I made the mistake of putting this in as JSON ID which doesn't exist if we're pulling from the weight node so all we have to do in here is get rid of JSON id and pull in a basically a you know a node reference variable so we're going to do two curly braces we're going to be pulling from the extract node and now we just want to say item.json ID and we should be good to go now so I'm just going to refresh this and we'll completely do it again so test workflow we're doing the exact same thing it's not ready yet so we're going to wait 5 seconds and then we're going to go check again we hopefully should see okay it's not ready still so we're going to wait five more seconds come check again and then whenever it is ready now as you can see it goes down this branch and we can see that we actually get our items back and what you see here is that this time we only got 10 quotes um you know it says nine but computers count from zero but we only got 10 quotes because um we didn't put an asterisk after the URL so Firecrawl didn't know I need to go scrape everything out of this whole base URL i'm only going to be scraping this one specific page which is this one right here which does in fact only have 10 quotes and by the way super simple template here but if you want to try it out and just plug in your API key and different URLs you can grab that in the free school community you'll hop in there you will click on YouTube resources and click on the post associated with this video and you'll have the JSON right there to download once you download that all you have to do is import it from file right up here and you'll have the workflow so there's a lot of cool use cases for firecrawl it'd be cool to be able to pull from a a sheet for example of 30 or 40 or 50 URLs that we want to run through and then update based on the results you could do some really cool stuff here like researching a ton of companies and then having it also create some initial outreach for you so I hope you guys enjoyed that one firecrawl is a super cool tool there's lots of functionality there and there's lots of uses of AI in Firecrawl which is awesome we're going to move into a different tool that you can use to scrape pretty much anything which is called Appify which has a ton of different actors and you can scrape like I said almost anything so let's go into the setup video so Ampify is like a marketplace for actors which essentially let us scrape anything on the internet as you can see right here we're able to explore 4,500 plus pre-built actors for web scraping and automation and it's really not that complicated an actor is basically just a predefined script that was already built for us that we can just send off a certain request to so you can think of it like a virtual assistant where you're saying "Hey I want you to I want to use the Tik Tok virtual assistant and I want you to scrape you know videos that have the hashtag of AI content." Or you could use the LinkedIn job scraper and you could say "I want to find jobs that are titled business analyst." So there's just so many ways you could use Appify you could get leads from Google Maps you could get Instagram comments you could get Facebook posts there's just almost unlimited things you can do here you can even tap into Apollo's database of leads and just get a ton so today I'm just going to show you guys in NAN the easiest way to set up this Aify actor where you're going to start the actor and then you're going to just grab those results so what you're going to want to do is head over to Aify using the link in the description and then use code 30 Nate Herk to get 30% off okay like I said what we're going to be covering today is a two-step process where you make one request to Aify to start up an actor and then you're going to wait for it to finish up and then you're just going to pull those results back in so let me show you what that looks like what I'm going to do is hit test workflow and this is going to start the Google Maps actor and what we're doing here is we're asking for dentists in New York and then if I go to my Appify console and I go over here to actors and click on the Google Maps extractor one if I click on runs we can see that there's one currently finishing up right now and now that it's finished I can go back into our workflow i can hook it up to the get results node hit test step and this is going to pull in those 50 dentists that we just scraped in New York and you can see this contains information like their address their website their phone number all this kind of stuff so you can just basically scrape these lists of leads so anyways that's how this works but let's walk through a live setup so once you're in your Appify console you click on the Appify store and this is where you can see all the different actors and let's do an example of like a social media one so I'm going to click on this Tik Tok scraper since it's just the first one right here and this may seem a little bit confusing but it's not going to be too bad at all we get to basically do all this with natural language so let me show you guys how this works so basically we have this configuration panel right here when you open up any sort of actor they won't always all be the same but in this one what we have is videos with this hashtag so we can put something in i put in AI content to play around with earlier and then you can see it asks how many videos do you want back so in this case I put 10 let's just put 25 for the sake of this demo and then you have the option to add more settings so down here we could do you know we could add certain profiles that we want to scrape we could add a different search functionality we could even have it download the videos for us so once you're good with this configuration and just don't over complicate it think of it the same way you would like put in filters on an e-commerce website or the same way you would you know fill in your order when you're door dashing some food so now that we have this filled out the way we want it all I'm going to do is come up to the top right and hit API and click API endpoints the first thing we're going to do is we're going to use this endpoint called run actor this is the one that's basically just going to send a request to Apify and start this process but it's not going to give us the live results back that's why the second step later is to pull the results back what you could do is you could run the actor synchronously meaning it's going to send it off and it's just going to spin in and it end until we're done and until it has the results but I found this way to be more consistent so anyways all you have to do is click on copy and it's already going to have copied over your appy API key so it's really really simple all we're going to do here is open up a new HTTP request i'm going to just paste in that URL that we just copied right here and that's basically all we have to do except for we want to change this method to post because as you can see right here it says post and so this is basically just us putting in the actor's phone number and so we're giving it a call but now what we have to do is actually tell it what we want so right here we've already filled this out i'm going to click on JSON and all I have to do is just copy this JSON right here go back into N flick this on to send a body and we want to send over just JSON and then all I have to do is paste that in there so as you can see what we're sending over to this Tik Tok scraper is I want AI content and I want 25 results and then all this other stuff is false so I'm just going to hit test step and so this basically returns us with an ID and says okay the actor started if we go back into here and we click on runs we can see that this crawler is now running and it's going to basically tell us how much it costed how long it took and all this kind of stuff and now it's already done so what we need to do now is we need to click on API up in the top right click on API endpoints again and scroll all the way down to the bottom where we can see get last run data set items so all I need to do is hit this copy button right here go back into Nitn and then open up another HTTP request and then I'm just going to paste that URL right in there once again and I don't even have to change the method because if we go in here we can see that this is a get so all I have to do is hit test step and this is going to pull in those 25 results from our Tik Tok scrape based on the search term AI content so you can see right here it says 25 items and just to show you guys that it really is 25 items I'm just going to grab a set field we're going to just drag in the actual text from here and hit test step and it should Oh we have to connect a trigger so I'm just going to move this trigger over here real quick and um what you can do is because we already have our data here I can just pin it so we don't actually have to run it again but then I'll hit test step and now we can see we're going to get our 25 items right here which are all of the text content so I think just the captions or the titles of these Tik Toks and we have all 25 Tik Toks as you can see so I just showed you guys the two-step method and why I've been using it because here's an example where I did the synchronous run so all I did was I came to the Google maps and I went to API endpoints and then I wanted to do run actor synchronously which basically means that it would run it in n and it would spin until the results were done and then it should feed back the output so I copied that I put it into here and as you can see I just ran it with the Google maps looking for plumbers and we got nothing back so that's why we're taking this two-step approach where as you can see here we're going to do that exact same request we're doing a request for plumbers and we're going to fire this off and so nothing came back in Nitn but if we go to our actor and we go to runs we can see right here that this was the one that we just made for plumbers and if we click into it we can see all the plumbers so that's why we're taking the two-step approach i'm going to make the exact same request here for New York plumbers and what I'm going to do is just run this workflow and now I wanted to talk about what we have to do because what happens is we started the actor and as you can see it's running right now and then it went to grab the results but the results aren't done yet so that's why it comes back and says this is an item but it's empty so what we want to do is we want to go to our runs and we want to see how long this is taking on average for 50 leads as you can see the most amount of time it's ever taken was 19 seconds so I'm just going to go in here and in between the start actor and grab results I'm going to add a wait and I'm just going to tell this thing to wait for 22 seconds just to be safe and now what I'm going to do is just run this thing again it's going to start the actor it's going to wait for 22 seconds so if we go back into Ampify you can see that the actor is once again running after about 22 seconds it's going to pass over and then we should get all 50 results back in our HTTP request there we go just finished up and now you can see that we have 50 items which are all of the plumbers that we got in New York so from here now that you have these 50 leads and remember if you want to come back into Ampify and change up your input you can change how many places you want to extract so if you changed this to 200 and then you clicked on JSON and you copied in that body you would now be searching for 200 results but anyways that's the hard part is getting the leads into end but now we have all this data about them and we can just you know do some research send them off a email whatever it is we can just basically have this thing running 24/7 and if you wanted to make this workflow more advanced to handle a little bit more dynamic amount of results what you'd want to use is a technique called polling so basically you'd wait you check in and then if the results were all done you continue down the process but if they weren't all done you would basically wait again and come back and you would just loop through this until you're confident that all of the results are done so that's going to be it for this one i'll have this template available in my free school community if you want to play around with it just remember you'll have to come in here and you'll have to switch out your own API key and don't forget when you get to Ampify you can use code 30 Nate Herk to get 30% off okay so those were some APIs that we can use to actually scrape information now what if we want to use APIs to generate some sort of content we're going to look at an image generation API from OpenAI and we're going to look at a video generation API called Runway so these next two workflows will explain how you set up those API calls and also how you can bake them into a workflow to be a little bit more practical so let's take a look so this workflow right here all I had to do was enter in ROI on AI automation and it was able to spit out this LinkedIn post for me and if you look at this graphic it's insane it looks super professional it even has a little LinkedIn logo in the corner but it directly calls out the actual statistics that are in the post based on the research and for this next one all I typed in was mental health within the workplace and it spit out this post according to Deote Insights organizations that support mental health can see up to 25% increase in productivity and as you can see down here it's just a beautiful graphic so a few weeks ago when Chacht came out with their image generation model you probably saw a lot of stuff on LinkedIn like this where people were turning themselves into action figures or some stuff like this where people were turning themselves into Pixar animation style photos or whatever it is and obviously I had to try this out myself and of course this was very cool and everyone was getting really excited but then I started to think about how could this image generation model actually be used to save time for a marketing team because this new image model is actually good at spelling and it can make words that don't look like gibberish it opens up a world of possibilities so here's a really quick example of me giving it a one-s sentence prompt and it spits out a poster that looks pretty solid of course we were limited to having to do this in chatbt and coming in here and typing but now the API is released so we can start to save hours and hours of time and so the automation I'm going to show with you guys today is going to help you turn an idea into a fully researched LinkedIn post with a graphic as well and of course we're going to walk through setting up the HTTP request to OpenAI's image generation model but what you can do is also download this entire template for free and you can use it to post on LinkedIn or you can also just kind of build on top of it to see how you can use image generation to save you hours and hours within some sort of marketing process so this workflow right here all I had to do was enter in ROI on AI automation and it was able to spit out this LinkedIn post for me and if you look at this graphic it's insane it looks super professional it even has a little LinkedIn logo in the corner but it directly calls out the actual statistics that are in the post based on the research so 74% of organizations say their most advanced AI initiatives are meeting or exceeding ROI expectations right here and on the other side we can see that only 26% of companies have achieved significant AIdriven gains so far which is right here and I was just extremely impressed by this one and for this next one all I typed in was mental health within the workplace and to spit out this post according to Deote Insights organizations that support mental health can see up to 25% increase in productivity and as you can see down here it's just a beautiful graphic something that would probably take me 20 minutes in Canva and if you can now push out these posts in a minute rather than 20 minutes you can start to push out more and more throughout the day and save hours every week and because the post is being backed by research the graphic is being backed by the research post you're not polluting anything into the internet a lot of people in my comments call it AI slop anyways let's do a quick live run of this workflow and then I'll walk through step by step how to set up this API call and as always if you want to download this workflow for free all you have to do is join my free school community link is down in the description and then you can search for the title of the video you can go into YouTube resources you need to find the post associated with this video and then when you're in there you'll be able to download this JSON file and that is the template so you download the JSON file you'll go back into Nitn you'll open up a new workflow and in the top right you'll go to import from file import that JSON file and then there'll be a little sticky note with a setup guide just sort of telling you what you need to plug in to get this thing to work for you okay quick disclaimer though i'm not actually going to post this to LinkedIn you certainly could but um I'm just going to basically send the post as well as the attachment to my email because I don't want to post on LinkedIn right now anyways as you can see here this workflow is starting with a form submission so if I hit test workflow it's going to pop up with a form where we have to enter in our email for the workflow to send us the results topic of the post and then also I threw in here a target audience so you could have these posts be kind of flavored towards a specific audience if you want to okay so this form is waiting for us i put in my email i put the topic of morning versus night people and the target audience is working adults so we'll hit submit close out of here and we'll see the LinkedIn post agent is going to start up it's using Tavi here for research and it's going to create that post and then pass the post on to the image prompt agent and that image prompt agent is going to read the post and basically create a prompt to feed into OpenAI's image generator and as you can see it's doing that right now we're going to get that back as a base 64 string and then we're just converting that to binary so we can actually post that on LinkedIn or send that in email as an attachment and we'll break down all these steps but let's just wait and see what these results look like here okay so all that just finished up let me pop over to email so in email we got our new LinkedIn post are you a morning lark or a night owl the science of productivity i'm not going to read through this right now exactly but let's take a look at the image we got when are you most productive in the morning plus 10% productivity or night owls thrive in flexibility i mean this is insane this is a really good graphic okay so now that we've seen again how good this is let's just break down what's going on we're going to start off with the LinkedIn post agent all we're doing is we're feeding in two things from the form submission which was what is the topic of the post as well as who's the target audience so right here you can see morning versus night people and working adults and then we move into the actual system prompt which I'm not going to read through this entire thing if you download the template the prompt will be in there for you to look at but basically I told it you are an AI agent specialized in creating professional educational and engaging LinkedIn posts based on a topic provided by the user we told it that it has a tool called Tavly that it will use to search the web and gather accurate information and that the post should be written to appeal to the provided target audience and then basically just some more information about how to structure the post what it should output and then an example which is basically you receive a topic you search the web you draft the post and you format it with source citations clean structure optional hashtags and a call to action at the end and as you can see what it outputs is a super clean LinkedIn post right here so then what we're going to do is basically we're feeding this output directly into that next agent and by the way they're both using chat GBT 4.1 through open router all right but before we look at the image prompt agent let's just take a look at these two things down here so the first one is the chat model that plugs into both image prompt agent and the LinkedIn post agent so all you have to do is go to open router get an API key and then you can choose from all these different models and in here I'm using GPT4.1 and then we have the actual tool that the LinkedIn agent uses for its research which is Tavi and what we're doing here is we're sending off a post request using an HTTP request tool to the Tavi endpoint so this is where people typically start to feel overwhelmed when trying to set up these requests because it can be confusing when you're trying to look through that API documentation which is exactly why in my paid community I created a APIs and HTTP requests deep dive because truthfully you need to understand how to set up these requests because being able to connect to different APIs is where the magic really happens so Tavi just lets your LLM connect to the web and it's really good for web search and it also gives you a thousand free searches per month so that's the plan that I'm on anyways once you're in here and you have an account and you get an API key all I did was went to the Tavali search endpoint and you can see we have a curl statement right here where we have this endpoint we have post as the method we have this is how we authorize ourselves and this is all going to be pretty similar to the way that we set up the actual request to OpenAI's image generation API so I'm not going to dive into this too much when you download this template all you have to do is plug in your Tavi API but later in this video when we walk through setting up the request to OpenAI this should make more sense anyways the main thing to take away from this tool is that we're using a placeholder for the request because in the request we sent over to Tavali we basically say okay here's the search query that we're going to search the internet for and then we have all these other little settings we can tweak like the topic how many results how many chunks per source all this kind of stuff all we really want to touch right now is the query and as you can see I put this in curly braces meaning it's a placeholder i'm calling the placeholder search term and down here I'm defining that placeholder as what the user is searching for so as you can see this data in the placeholder is going to be filled in by the model so based on our form submission when we asked it to you know create a LinkedIn post about morning versus night people it fills out the search term with latest research on productivity morning people versus night people and that's basically how it searches the internet and then we get our results back and now it creates a LinkedIn post that we're ready to pass off to the next agent so the output of this one gets fed into this next one which all it has to do is read the output as you can see right here we gave it the LinkedIn post which is the full one that we just got spit out and then our system message is basically telling it to turn that into an image prompt this one is a little bit longer not too bad though i'm not going to read the whole thing but essentially we're telling it that it's going to be an AI agent that transforms a LinkedIn post into a visual image prompt for a textto-image AI generation model so we told it to read the post identify the message identify the takeaways and then create a compelling graphic prompt that can be used with a textto image generator we gave it some output instructions like you know if there's numbers try to work those into the prompt um you can use you know text charts icons shapes overlays anything like that and then the very bottom here we just gave it sort of like an example prompt format and you can see what it spits out is a image prompt so it says a dynamic split screen infographic style graphic left side has a sunrise it's bright yellow and it has morning larks plus 10% productivity and the right side is a morning night sky cool blue gradients a crescent moon all this kind of stuff and that is exactly what we saw back in here when we look at our image and so this is just so cool to me because first of all I think it's really cool that it can read a post and kind of use its brain to say "Okay this would be a good you know graphic to be looking at while I'm reading this post." But then on top of that it can actually just go create that for us so I think this stuff is super cool you know I remember back in September I was working on a project where someone wanted me to help them with LinkedIn automated posting and they wanted visual elements as well and I was like uh I don't know like that might have to be a couple month away thing when we have some better models and now we're here so it's just super exciting to see but anyways now we're going to feed that output the image prompt into the HTTP request to OpenAI so real quick let's go take a look at OpenAI's documentation so of course we have the GBT image API which lets you create edit and transform images you've got different styles of course you can do like memes with a with text you can do creative things you can turn other images into different images you can do all this kind of stuff and this is where it gets really cool these posters and the visuals with words because that's the kind of stuff where typically AI image gen like wasn't there yet and one thing real quick in your OpenAI account which is different than your chatbt account this is where you add the billing for your OpenAI API calls you have to have your organization verified in order to actually be able to access this model through API right now it took me 2 minutes you basically just have to submit an ID and it has to verify that you're human and then you'll be verified and then you can use it otherwise you're going to get an error message that looks like this that I got earlier today but anyways the verification process does not take too long anyways then you're going to head over to the API documentation that I will have linked in the description where we can see how we can actually create an image in NAN so we're going to dive deeper into this documentation in the later part of this video where I'm walking through a step-by-step setup of this but we're using the endpoint um which is going to create an image so we have this URL right here we're going to be creating a post request and then we just obviously have our things that we have to configure like the prompt in the body we have to obviously send over some sort of API key we have to you know we can choose the size we can choose the model all this kind of stuff so back in NN you can see that I'm sending a post request to that endpoint for the headers I set up my API key right here but I'm going to show you guys a better way to do that in the later part of this video and then for the body we're saying okay I want to use the GBT image model here's the actual prompt to use for the image which we dragged in from the image prompt agent and then finally the size we just left it as that 1024 * 1024 square image and so this is interesting because what we get back is we get back a massive base 64 code like this thing is huge i can't even scroll right now my screen's kind of frozen anyways um yeah there it goes it just kind of lagged but we got back this massive file we can see how many tokens this was and then what we're going to do is we're going to convert that to binary data so that's how we can actually get the file as an image as you can see now after we turn that nasty string into a file we have the binary image right over here so all I did was I basically just dragged in this field right here with that nasty string and then when you hit test step you'll get that binary data and then from there you have the binary data you have the LinkedIn post all you have to do is you know activate LinkedIn drag it right in there or you can just do what I did which is I'm sending it to myself in email and of course before you guys yell at me let's just talk about how much this run costed me so this was 4,273 tokens and if we look at this API and we go down to the pricing section we can see that for image output tokens which was generated images it's going to be 40 bucks for a million tokens which comes out to about 17 cents if you can see that right here hopefully I did the math right but really for the quality and kind of for the industry standard I've seen for price that's on the cheaper end and as you can see down here it translates roughly to 2 cents 7 cents 19 cents per generated image for low medium blah blah blah blah blah but anyways now that that's out of the way let's just set up an HTTP request to that API and generate an image so I'm going to add a first step i'm just going to grab an HTTP request so I'm just going to head over to the actual API documentation from OpenAI on how to create an image and how to hit this endpoint and all we're going to do is we're going to copy this curl command over here on the right if it you're not seeing a curl command if you're seeing Python just change that to curl copy that and then we're going to go back into Nitn hit import curl paste that in there and then once we hit import we're almost done so that curl statement basically just autopop populated almost everything we need to do now we just have a few minor tweaks but as you can see it changed the method to post it gave us the correct URL endpoint already it has us sending a header which is our authorization and then it has our body parameters filled out where all we'd really have to change here is the prompt and if we wanted to we can customize this kind of stuff and that's why it's going to be really helpful to be able to understand and read API documentation so you know how to customize these different requests basically all of these little things here like prompt background model n output format they're just little levers that you can pull and tweak in order to change your output but we're not going to dive too deep into that right now let's just see how we can create an image anyways before we grab our API key and plug that in when you're in your OpenAI account make sure that your organization is verified otherwise you're going to get this error message and it's not going to let you access the model doesn't take long just submit an ID and then also make sure that you have billing information set up so you can actually pay for um an image but then you're going to go down here to API keys you're going to create new secret key this one's going to be called image test just for now and then you're going to copy that API key now back in any then it has this already set up for us where all we need to do is delete all this we're going to keep the space after bearer and we can paste in our API key like that and we're good to go but if you want a better method to be able to save this key in Nadn so you don't have to go find it every time what you can do is come to authentication go to general or actually no it's generic and then you're going to choose header off and we know it's header because right here we're sending headers as a header parameter and this is where we're authorizing oursel so we're just going to do the same up here with the header off and then we're going to create a new one i'm just going to call this one openai image just so we can keep ourselves organized and then you're going to do the same thing as what we saw down in that header parameter field meaning the authorization is the name and then the value was bearer space API key so that's all I'm going to do i'm going to hit save we are now authorized to access this endpoint and I'm just going to turn off sending headers because we're technically sending headers right up here with our authentication so we should be good now right now we'll be getting an image of a cute baby sea otter um and I'm just going to say making pancakes and we'll hit test step and this should be running right now um okay so bad request please check your parameters invalid type for n it expected an integer but it got a string instead so if you go back to the API documentation we can see n right here it should be integer or null and it's also optional so I'm just going to delete that we don't really need that and I'm going to hit test step and while that's running real quick we'll just go back at n and this basically says the number of images to generate must be between 1 and 10 so that's like one of those little levers you could tweak like I was talking about if you want to customize your request but right now by default it's only going to give us one looks like this HTTP request is working so I'll check in with you guys in 20 seconds when this is done okay so now that that finished up didn't take too long we have a few things and all we really need is this base 64 but we can see again this one costed around 17 and now we just have to turn this into binary so we can actually view an image so I'm going to add a plus after the HTTP request i'm just going to type in binary and we can see convert to file which is going to convert JSON data to binary data and all we want to do here is move a B 64 string to file because this is a B 64 JSON and this basically represents the image so I'm going to drag that into there and then when I hit test step we should be getting a binary image output in a field called data as you can see right here and this should be our image of a cute sea otter making pancakes as you can see um it's not super realistic and that's because the prompt didn't have any like photorealistic hyperrealistic elements in there but you can easily make it do so and of course I was playing around with this earlier and just to show you guys you can make some pretty cool realistic images here was um a post I made about um if ancient Rome had access to iPhones and obviously this is not like a real Twitter account um but this is a dinosaurs evolved into modern-day influencers this was just for me testing like an automation using this API and auto posting but not as practical as like these LinkedIn graphics but if you guys want to see a video sort of like this let me know or if you also want to see a more evolved version of the LinkedIn posting flow and how we can make it even more robust and even more automated then definitely let me know about that as well okay okay so all I have to do in this form submission is enter in a picture of a product enter in the product name the product description and my email address and we'll send this off and we'll see the workflow over here start to fire off so we're going to upload the photo we're going to get an image prompt we're going to download that photo now we're creating a professional graphic so after our image has been generated we're uploading it to a API to get a public URL so we can feed that URL of the image into Runway to generate a professional video now we're going to wait 30 seconds and then we'll check in to see if the video is done if it's not done yet we're going to come down here and pull wait five more seconds and then go check in and we're going to do this infinitely until our video is actually done so anyways it just finished up it ended up hitting this check eight times which indicates I should probably increase the wait time over here but anyways let's go look at our finished products so we just got this new email here are the requested marketing materials for your toothpaste so first let's look at the video cuz I think that's more exciting so let me open up this link wow we got a 10-second video it's spinning it's 3D the lighting is changing this looks awesome and then of course it also sends us that image in case we want to use that as well and one of the steps in the workflow is that it's going to upload your original image to your Google Drive so here you can see this was the original and then this was the finished product so now you guys have seen a demo we're going to build this entire workflow step by step so stick with me because by the end of this video you'll have this exact system up and running okay so when we're setting up a system where we're creating an image from text and then we're creating a video from that image the two most important things are going to be that image prompt and that video prompt so what we're going to do is head over to my school community the link for that will be down in the description it's a free school community and then what you're going to do is either search for the title of this video or click on YouTube resources and find the post associated with this video and when you click into there there'll be a doc that will look like this or a PDF and it will have the two prompts that you'll need in order to run the system so head over there get that doc and then we can hop into the step by step and that way we can start to build this workflow and you guys will have the prompts to plug right in cool so once you have those let's get started on the workflow so as you guys know a workflow always has to start with some sort of trigger so in this case we're going to be triggering this workflow with a form submission so I'm just going to grab the native NAN form on new form event so we're going to configure what this form is going to look like and what it's going to prompt a user to input and then whenever someone actually submits a response that's when the workflow is going to fire off okay so I'm going to leave the authentication as none the form title I'm just putting go to market for the form description I'm going to say give us a product photo title and description and we'll get back to you with professional marketing materials and if you guys are interested in what I just used to dictate that text there'll be a link for Whisper Flow down in the description and now we need to add our form elements so the first one is going to be not a text we're going to have them actually submit a file so click on file this is going to be required i only want them to be allowed to upload one file so I'm going to switch off multiple files and then for the field name we're just going to say product photo okay so now we're going to add another one which is going to be the product title so I'm just going to write product title this is going to be text for placeholder let's just put toothpaste since that was the example this will be a required field so the placeholder is just going to be the gray text that fills in the text box so people are kind of they know what to put in okay we're adding another one called product description we'll make this one required we'll just leave the placeholder blank cuz you don't need it and then finally what we need to get from them is an email but instead of doing text we can actually make it require a valid email address so I'm just going to call it email and we'll just say like namele.com so they know what a valid email looks like we'll make that required because we have to send them an email at the end with their materials and now we should be good to go so if I hit test step we'll see that it's going to open up a form submission and it has everything that we just configured and now let me put in some sample data real quick okay so I put a picture of a clone bottle the title's clone i said the clone smells very clean and fresh and it's a very sophisticated scent because we're going to have that description be used to sort of help create that text image prompt and then I just put my email so I'm going to submit this form we should see that we're going to get data back right here in our NIN which is the binary photo this is the product photo that I just submitted and then we have our actual table of information like the title the description and the email and so when I'm building stuff step by step what I like to do is I get the data in here and then I pretty much will just build node by node testing the data all the way through making sure that nothing's going to break when variables are being passed from left to right in this workflow okay so the next thing that we need to do is we have this binary data in here and binary data is tough to reference later so what I'm going to do is I'm just going to upload it straight to our Google Drive so we can pull that in later when we need it to actually edit that image okay so that's our form trigger that's what starts the workflow and now what we're going to do next is we want to upload that original image to Google Drive so we can pull it in later and then use it to edit the image so what I'm going to do is I'm going to click on the plus i'm going to type in Google Drive and we're going to grab a Google Drive operation that is going to be upload file so I'll click on upload file and at this point you need to connect your Google Drive so I'm not going to walk through that step by step but I have a video right up here where I do walk through it step by step but basically you're just going to go to Docs you have to open up a sort of Google Cloud profile or a console and then you just have to connect yourself and enable the right credentials and APIs um but like I said that video will walk through it anyways now what we're doing is we have to upload the binary field right here to our Google Drive so it's not called data we can see over here it's called product photo so I'm just going to copy and paste that right there so it's going to be looking for that product photo and then we have to give it a name so that's why we had the person submit a title so all I'm going to do is for the name I'm going to make this an expression instead of fixed because this name is going to change based on the actual product coming through i'm going to drag in the product title from the left right here so now the the photo in Google Drive is going to be called cologne and then I'm just going to in parenthesis say original so because this is an expression it basically means whenever someone submits a form whatever the title is it's going to be title and then it's going to say original and that's how we sort of control that to be dynamic anyways then I'm just choosing what folder to go in so in my drive I'm going to choose it to go to a folder that I just made called um product creatives so once we have that configured I'm going to hit test step we're going to wait for this to spin it means that it's trying to upload it right now and then once we get that success message we'll quickly go to our Google Drive and make sure that the image is actually there so there we go it just came back and now I'm going to click into Google Drive click out of the toothpaste and we can see we have cologne and that is the image that we just submitted in NAN all right now that we've done that what we want to do is we want to feed the data into an AI node so that it can create a text image prompt so I'm going to click on the plus i'm going to grab an AI agent and before we do anything in here I'm first of all going to give it its brain so I'm going to click on the plus under chat model i'm personally going to grab an open router chat model which basically lets you connect to a ton of different things um let me see open router.ai it basically lets you connect your agents to all the different models so if I click on models up here we can see that it just lets you connect to Gemini Anthropic OpenAI Deepseek it has all these models and all in one place so go to open router get an API key and then once you come back into here all you have to do is connect your API key and what I'm going to use here is going to be 4.1 and then I'm just going to name this so we know which one I'm using here and then we now have our agent accessing GPT4.1 okay so now you're going to go to that PDF that I have in the school community and you're just going to copy this product photography prompt grab that go back to the AI agent and then you're going to click on add option add a system message and then we're basically just going to I'm going to click on expression and expand this full screen so you guys can see it better but I'm just going to paste that prompt in here and this is going to tell the AI agent how to take what we're giving it and turn it into a text image optimized prompt for professional style you know studio photography so we're not done yet because we have to actually give it the dynamic information from our form submission every time so that's a user message that's basically what it's going to look at so the user message is what the agent's going to look at every time and the system message is basically like here are your instructions so for the user message we're not going to be using a connected chat trigger node we're going to define below and when we want to make sure that this changes every time we have to make sure it's an expression and then I'm just going to drill down over here to the form submission and I'm going to say okay here's what we're going to give this agent it's going to get the product which the person submitted to us in the form and we can drag in the product which was cologne as you can see on the right and then they also gave us a description so all I have to do now is drag in the product description and so now every time the agent will be looking at whatever product and description that the user submitted in order to create its prompt so I'm going to hit test step we'll see right now it's using its chat model GPT4.1 and it's already created that prompt for us so let's just give it a quick read hyperrealistic photo of sophisticated cologne bottle transparent glass sleek minimalistic design silver metal cap all this but what we have to do is we have to make sure that the image isn't being created just on this it has to look at this but it also has to look at the actual original image so that's why our next step is going to be to redownload this file and then we're going to push it over to the image generation model so at this point you may be wondering like why are we going to upload the file if we're just going to download it again and the reason why I had to do that is because when we get the file in the form of binary we want to send the binary data into the HTTP request right here that actually generates the image and we can't reference the binary way over here if it's only coming through over here so we upload it so that we can then download it and then send it right back in and so if that doesn't make sense yet it probably will once we get over to the stage but that's why anyways next step is we're going to download that file so I'm going to click on this plus we're going to be downloading it from Google Drive and we're going to be using the operation download file so we already should be connected because we've set up our Google credentials already the operation is going to be download the resources a file and instead of choosing from a list we're going to choose by ID and all we're going to do is download that file that we previously uploaded every time so I'm going to come over here the Google Drive upload photo node drag in the ID and now we can see that's all we have to do if we hit test step we'll get back that file that we originally uploaded and we can just make sure it's the cologne bottle okay but now it's time to basically use that downloaded file and the image prompt and send that over to an API that's going to create an image for us so we're going to be using OpenAI's image generator so here is the documentation we have the ability to create an image or we can create an image edit which is what we want to do because we wanted to look at the photo and our request so typically what you can do in this documentation is you can copy the curl command but this curl command is actually broken so we're not going to do that if you copied this one up here to actually just create an image that one would work fine but there's like a bug with this one right now so anyways I'm going to go into our n I'm going to hit the plus i'm going to grab an HTTP request and now we're going to configure this request so I'm going to walk through how I'm reading the API documentation right here to set this up i'm not going to go super super in-depth but if you get confused along the way then definitely check out my paid course the link for that down in the description i've got a full course on deep diving into APIs and HTTP requests anyways the first thing we see is we're going to be making a post request to this endpoint so the first thing I'm going to do is copy this endpoint we're going to paste that in and then we're also going to make sure the method is set to post so the next thing that we have to do is authorize ourselves somehow so over here I can see that we have a header and the name is going to be authorization and then the value is going to be bearer space R open AI key so that's why I set up a header authentication already so in authentication I went to generic and then I went to header and then you can see I have a bunch of different headers already set up but what I did here is I chose my OpenAI one where basically all I did was I typed in here authorization and then in the value I typed in bearer space and then I pasted my API key in there and now I have my OpenAI credential saved forever okay so the first thing we have to do in our body request over to OpenAI is we have to send over the image to edit so that's going to be in a field called image and then we're sending over the actual photo so what I'm going to do is I'm going to click on send body i'm going to use form data and now we can set up the different names and values to send over so the first thing is we're going to send over this image right here on the lefth hand side and this is in a field called data and it's binary so I'm going to choose instead of form data I'm going to send over an NAN binary file the name is going to be image because that's what it said in the documentation and the input data field name is data so I'm just going to copy that paste it in there and this basically means okay we're sending over this picture the next thing we need to send over is a prompt so the name of this field is going to be prompt i'm just going to copy that add a new parameter and call it prompt and then for the value we want to send over the prompt that we had our AI agent write so I'm going to click into schema and I'm just going to drag over the output from the AI agent right there and now that's an expression so the next thing we want to send over is what model do we want to use because if we don't put this in it's going to default to dolly 2 but we want to use gpt-image- one so I'm going to copy GPT- image- one we're going to come back into here and I'm going to paste that in as the value but then the name is model because as you can see in here right there it says model so hopefully you guys can see that when we're sending over an API call we just have all of these different options where we can sort of tweak different settings to change the way that we get the output back and then you have some other options of course like quality or size but right now we're just going to leave all that as default and just go with these three things to keep it simple and I'm going to hit test step and we'll see if this is working okay never mind i got an error and I was like okay I think I did everything right the reason I got the error is because I don't have any more credits so if you get this error go add some credits okay so added more credits i'm going to try this again and I'll check back in but before I do that I wanted to say me clearly I've been like spamming this thing with creating images cuz it's so cool it's so fun but everyone else in the world has also been doing that so if you're ever getting some sort of like errors where it's like a 500 type of error where it means like something's going on on the server side of things or you're seeing like some sort of rate limit stuff keep in mind that there's there's a limit on how many images you can send per minute i don't think that's been clearly defined on GPT- image-1 but also if the OpenAI server is receiving way too many requests that is also another reason why your request may be failing so just keep that in mind okay so now it worked we just got that back but what you'll notice is we don't see an image here or like an image URL so what we have to do is we have this base 64 string and we have to turn that into binary data so what I'm going to do is after this node I'm going to add one that says um convert to file so we're going to convert JSON data to binary data and we're going to do B 64 so all I have to do now is show this data on the lefth hand side grab the base 64 string and then when we hit test step we should get a binary file over here which if we click into it this should be our professional looking photo wow that looks great it even got the wording and like the same fonts right so that's awesome and by the way if we click into the results of the create image where we did the image edit we can see the tokens and with this model it is basically $10 for a million input tokens and $40 for a million output tokens so right here you can see the difference between our input and output tokens and this one was pretty cheap i think it was like 5 cents anyways now that we have that image right here as binary data we need to turn that into a video using an API called Runway and so if we go into Runway and we go first of all let's look at the price for a 5second video 25 cents for a 10-second video 50 cents so that's the one we're going to be doing today but if we go to the API reference to read how we can turn an image into a video what we need to look at is how we actually send over that image and what we have to do here is send over an HTTPS URL of the image so we somehow have to get this binary data in NADN to a public image that runway can access so the way I'm going to be doing that is with this API that's free called image BB and um it's a free image hosting service and what we can do is basically just use its API to send over the binary data and we'll get back a public URL so come here make a free account you'll grab your API key from up top and then we basically have here's how we set this up so what I'm going to do is I'm going to copy the endpoint right there we're going to go back into naden and I'm going to add an HTTP request and let me just configure this up we'll put it over here just to keep everything sort of square but now what I'm going to do in here is paste that endpoint in as our URL you can also see that it says this call can be done using post or git but since git requests are limited by the max amount of length you should probably do post so I'm just going to go back in here and change this to a post and then there are basically two things that are required the first one is our API key and then the second one is the actual image anyways this documentation is not super intuitive i can sort of tell that this is a query parameter because it's being attached at the end of the endpoint with a question mark and all this kind of stuff and that's just because I've looked at tons of API documentation so what I'm going to do is go into nit we're going to add a generic credential type it's going to be a query off where where was query there we go and then you can see I've already added my image BB but all you're going to do is you would add the name as a key and then you would just paste in your API key and that's it and now we've authenticated ourselves to the service and then what's next is we need to send over the image in a field called image so I'm going to go back in here i'm going to send over a body because this allows us to actually send over n binary fields and I'm not going to do n binary i'm going to do form data because then we can name the field we're sending over like I said not going to deep dive into how that all works but the name is going to be image and then the input data field name is going to be data because that's how it's seen over here and this should be it so real quick I'm just going to change this to get URL and then we're going to hit test step which is going to send over that binary data to image BB and it hopefully should be sending us back a URL and it sent back three of them i'm going to be using the middle one that's just called URL because it's like the best size and everything you can look at the other ones if you want on your end but this one is going to load up and we should see it's the image that we got generated for us it takes a while to load up on that first time but as you can see now it's a publicly accessible URL and then we can feed it into runway so that's exactly our next step we're going to add another request right here it's going to be an HTTP and this one we're going to configure to hit runway so here's a good example of we can actually use a curl command so I'm going to click on copy over here when I'm in the runway generate a video from image come back into Naden hit import curl and paste that in there and hit import and this is going to basically configure everything we need we just have to tweak a few things typically most API documentation nowadays will have a curl command the edit image one that we set up earlier was just a little broken imag is just a free service so sometimes they don't always but let's configure this node so the first thing I see is we have a header off right here and I don't want to send it like this i want to send it up as a generic type so I can save it otherwise you'd have to go get your API key every time you wanted to use Runway so as you can see I've already set up my Runway API key so I have it plugged in but what you would do is you'd go get your API key from Runway and then you'd see okay how do we actually send over authentication it comes through with the name authorization and then the header is bearer space API key so similar to the last one and then that's all you would do in here when you're setting up your runway credential authorization bearer space my API key and then because we have ourselves authenticated up here we can flick off that headers and all we have to do now is configure the actual body okay so first things first what image are we sending over to get turned into a video in that name prompt image we're going to get rid of that value and I'm just going to drag in the URL that we wanted that we got from earlier which was that picture I s I showed you guys so now runway sees that image next we have the seed which if you want to look at the documentation you can play with it but I'm just going to get rid of that then we have the model which we're going to be using Gen 4 Turbo we then have the prompt text so this is where we're going to get rid of this and you're going to go back to that PDF you downloaded from my free school and you're going to paste this prompt in there so this prompt basically gives us that like 3D spinning effect where it just kind of does a slow pan and a slow rotate and that's what I was looking for if you're wanting some other type of video then you can tweak that prompt of course for the duration if you look in the documentation it'll say the duration only basically allows five or 10 so I'm just going to change this one to 10 and then the last one was ratio and I'm just going to make the square so here are the accepted ratio values i'm going to copy 960 by 960 and we're just going to paste that in right there and actually before we hit test step I've realized that we're missing something here so back in the documentation we can see that there's one thing up here which is required which is a header x-runway- version and then we need to set the value to this so I'm going to copy the header and we have to enable headers i I deleted it earlier but we're going to enable that so we have the version and then I'm just going to go copy the value that it needs to be set to and we'll paste that in there as the value otherwise this would not have worked okay so that should be configured but before we test it out I want to show you guys how I set up the polling flow like this that you saw in the demo so what we're going to do here is we need to go see like okay once we send over our request right here to get a video from our image it's going to return an ID and that doesn't mean anything to us so what we have to do is get our task so that is the basically we send over the ID that it gives us and then it'll come back and say like the status equals pending or running or we'll say completed so what I'm going to do is copy this curl command for getting task details we're going to hook it up to this node as an HTTP request we're going to import that curl now that's pretty much set up we have our authorization which I'm going to delete that because as you know we just configured that earlier as a header off so I'm just going to come in here and grab my Runway API key there it is i couldn't find it for some reason um we have the version set up and now all we have to do is drag in the actual ID from the previous one so real quick I'm just going to make this an expression delete ID and now we're pretty much set up so first of all I'm going to test this one which is going to send off that request to runway and say "Hey here's our image here's the prompt make a video out of it." And as you can see we got back an ID now I'm going to use this next node and I'm going to drag in that ID from earlier and now it's saying okay we're going to check in on the status of this specific task and if I hit test step what we're going to see is that it's not yet finished so it's going to come back and say okay status of this run or status of this task is running so that's why what I'm going to do is add an if and this if is going to be saying okay does this status field right here does that equal running in all caps because that's what it equals right now if yes what we're going to do is we are going to basically wait for a certain amount of time so here's the true branch i'm going to wait and let's just say it's 5 seconds so I'll just call this five seconds i'm going to wait for 5 seconds and then I'm going to come back here and try again so as you saw in the demo it basically tried again like seven or eight times and this just ensures that it's never going to move on until we actually have a finished photo so what you could also do is basically say does status equal completed or whatever it means when it completes that's another way to do it you just have to be careful to make sure that whatever you're setting here as the check is always 100% going to work and then what you do is you would continue the rest of the logic down this path once that check has been complete and then of course you probably don't want to have this check like 10 times every single time so what you would do is you'd add a weight step here and once you know about how long it takes you'd add this here so last time I had it at 30 seconds and it waited like eight times so let's just say I'm going to wait 60 seconds here so then when this flow actually runs it'll wait for a minute check if it's still not done it'll continuously loop through here and wait 5 seconds every time until we're done okay there we go so now status is succeeded and what I'm going to do is just view this video real quick hopefully this one came out nicely let's take a look wow this is awesome super clean it's rotating really slowly it's a full 10-second video you can tell it's like a 3D image this is awesome okay cool so now if we test this if branch we'll see that it's going to go down the other one which is the false branch because it's actually completed and now we can with confidence shoot off the email with our materials so I'm going to grab a Gmail node i'm going to click send a message and we are going to have this configured hopefully because you've already set up your Google stuff and now who do we send this to we're going to go grab that email from the original form submission which is all the way down here we're going to make the subject which I'm just going to say marketing materials and then a colon and we'll just drag in the actual title of the product which in here was cologne i'm changing the email type to text just because I want to um we're going to make the body an expression and we're just going to say like hey here is your photo and obviously this can be customized however you want but for the photo what we have to do is grab that public URL that we generated earlier so right here there is the photo URL here is your video and for the video we're going to drag in the URL we just got from the output of that um runway get task check so there is the video URL and then I'm just going to say cheers last thing I want to do is down here append edit an attribution and turn that off this just ensures that the email doesn't say this email was sent by NAN and now if we hit test step right here this is pretty much the end of the process and we can go ahead and check uh-oh okay so not authorized let me fix that real quick okay so I just switched my credential because I was using one that had expired so now this should go through and we'll go take a look at the email okay so did something wrong i can already tell what happened is this is supposed to be an expression and dynamically come through as the title of the product but we accidentally somehow left off a curly brace so if I come back into here and and add one more curly brace right here to the description or sorry the subject now we should be good i'll hit test step again and now we'll go take a look at that email okay there we go now we have the cologne and we have our photo and our video so let's click into the video real quick i'm just so amazed this is this is just so much fun it look the the lighting and the the reflections it's it's all just perfect and then we'll click into the photo just in case we want to see the actual image and there it is this also looks awesome all right so that's going to do it for today's video i hope you guys enjoyed this style of walking step by step through some of the API calls and sort of my thought process as to how I set up this workflow okay at this point I think you guys probably have a really good understanding of how these AI workflows actually function and you're probably getting a little bit antsy and want to build an actual AI agent now so we're about to get into building your first AI agent step by step but before that just wanted to drive home the concept of AI workflows versus AI agents one more time and the benefits of using workflows but of course there are scenarios where you do need to use an agent so let's break it down real quick everyone is talking about AI agents right now but the truth is most people are using them completely wrong and admittedly myself included it's such a buzzword right now and it's really cool in n to visually see your agents think about which tools they have and which ones to call so a lot of people are just kind of forcing AI agents into processes where you don't really need it but in reality a simple AI workflow is not only going to be easier to build it's going to be more cost- effective and also more reliable in the long run if you guys don't know me my name's Nate and for a while now I've been running an agency where we deliver AI solutions to clients and I've also been teaching people from any background how to build out these things practically and apply them to their business through deep dive courses as well as live calls so if that sounds interesting to you definitely check out the community with the link in the description but let's get into the video so we're going to get into Naden and I'm going to show you guys some mistakes of when I've built agents when I should have been building AI workflows but before that I just wanted to lay out the foundations here so we all know what chatbt is at its core it's a large language model that we talk to with an input and then it basically just gives us an output so if we wanted to leverage chatbt to help us write a blog post we would ask it to write a blog post about a certain topic it would do that and then it would give us the output which we would then just copy and paste somewhere else and then came the birth of AI agents which is when we actually were able to give tools to our LLM so that they could not only just generate content for us but they could actually go post it or go do whatever we wanted to do with it ai agents are great and there's definitely a time and a place for them because they have different tools and basically the agent will use its brain to understand okay I have these three tools based on what the user is asking me do I call this one and then do I output or do I call this one then this one or do I need to call all three simultaneously it has that option and it has the variability there so this is going to be a non-deterministic workflow but the reality is most of the processes that we're trying to enhance for our clients are pretty deterministic workflows that we can build out with something more linear where we still have the same tools we're still using AI but we have everything going step one step two step three step four step five step six which is going to reduce the variability there it's going to be very deterministic and it's going to help us with a lot of things so stick with me because I'm going to show you guys an AI agent video that I made on YouTube a few months back and I started re-evaluating it like why would I ever build out the system like that it's so inefficient so I'll show you guys that in a sec but real quick let's talk about the pros of AI workflows over AI agents and I narrowed it down to four main points the first one is reliability and consistency one of the most important concepts of building an effective AI agent is the system prompt because it has to understand what its tools are when to use each one and what the end goal is and it's on its own to figure out which ones do I need to call in order to provide a good output but with a workflow we're basically keeping it on track and there's no way that the process can sort of deviate from the guardrails that we've set up because it has to happen in order and it can't really go anywhere else so this makes systems more reliable because there's never going to be a transfer of data between workflows where things may get messed up or incorrect mappings being sent across you know agent to a different agent or agent to tool we're just basically able to go through the process linearly so the next one is going to be cost efficiency when we're using an agent and it has different tools every time it hits a tool it's going to go back to its brain it's going to rerun through its system prompt and it's going to think about what is my next step here and every time you're accessing that AI agent's brain it costs you money so if we're able to eliminate that aspect of decision-m and just say okay you you finished step two now you have to go on to step three there's no decision to be made we don't have to make that extra API call to think about what comes next and we're saving money number three is easier debugging and maintenance when we have an AI workflow we can see exactly which node errors we can see exactly what mappings are incorrect and what happened here whereas with an AI agent workflow it's a little bit tougher because there's a lot of manipulating the system prompt and messing with different tool configurations and like I said there's data flowing between agent to tool or between agent to subworkflow and that's where a lot of things can happen that you don't really have full visibility into and then the final one is scalability kind of backpacks right off of number three but if you wanted to add more nodes and more functionality to a workflow it's as simple as you know plugging in a few more blocks here and there or adding on to the back but when you want to increase the functionality of an AI agent you're probably going to have to give it more tools and when you give it more tools you're going to have to refine and add more lines to the system prompt which could work great initially but then previous functionality the first couple tools you added those might stop working or those may become less consistent so basically the more control that we have over the entire workflow the better ai is great there are times when we need to make decisions and we need that little bit of flexibility but if a decision doesn't have to be made why would we leave that up to the AI to hallucinate 5 or 10% of the time when we could basically say "Hey this is going to be 100% consistent." Anyways I've made a video that talks a little bit more about this stuff as well as other things I've learned over the first 6 months of building agents if you want to watch that I'll link it up here but let's hop into n and take a look at some real examples okay so the first example I want to share with you guys is a typical sort of rag agent and for some reason it always seems like the element of rag has to be associated with an agent but it really doesn't so what we have is a workflow where we're putting a document from Google Drive into Pine Cone we have a customer support agent and then we have a customer support AI workflow and both of the blue box and the green box they do the exact same thing but this one's going to be more efficient and we also have more control so let's break this down also if you want to download this template to play around with you can get it for free if you go to my free school community the link for that's down in the description as well you'll come into here click on YouTube resources and click on the post associated with this video and then the workflow will be right here for you to download okay so anyways here is the document that we're going to be looking at it has policy and FAQ information we've already put it into Pine Cone as you can see it's created eight vectors and now what we're going to do is we're going to fire off an email to the customer support agent to see how it handles it okay so we just sent off do you offer price matching or bulk discounts we'll come back into the workflow hit run and we should see the customer support agent is hitting the vector database and it's also hitting its reply email tool but what you'll notice is that it hit its brain so Google Gemini 2.0 Flash in this case not a huge deal because it's free but if you were using something else it's going to have hit that API three different times which would be three separate costs so let's check and see if it did this correctly so in our email we got the reply "We do not offer price matching currently but we do run promotions and discounts regularly yes bulk orders may qualify for a discount please contact our sales team at salestechhaven.com for inquiries so let's go validate that that's correct so in the FAQ section of this doc we have that they don't offer price matching but they do run promotions and discounts regularly and then for bulk discounts um you have to hit up the sales team so it answered correctly okay so now we're going to run the customer support AI workflow down here it's going to grab the email it's going to search Pine Cone it's going to write the email i'll explain what's going on here in a sec and then it responds to the customer so there's four steps here it's going to be an email trigger it's going to search the knowledge base it's going to write the email and then respond to the customer in an email so why would we leave that up to the agent to decide what it needs to do if it's always going to happen in those four steps every time all right here's the email we just got in reply as you can see this is the one that the agent wrote and this one looks a lot better hello thank you for reaching out to us in response to your inquiry we currently do not offer price matching however we do regularly run promotions and discounts so be sure to keep an eye out for those that's accurate regarding bulk discounts yes they may indeed qualify for a discount so reach out to our sales team if you have any other questions please feel free to reach out best regards Mr helpful TechHaven and obviously I told it to sign off like that so now that we've seen that let's actually break down what's going on so it's the same trigger you know we're getting an email and as you can see we can find the text of the email right here which was "Do you guys offer price matching or bulk discounts?" We're feeding that into a pine cone node so if you guys didn't know you don't even need these to be only tools you can have them just be nodes where we're searching for the prompts that is do you guys offer price matching or bulk discounts and maybe you might want an AI step between the trigger and the search to maybe like formulate a query out of the email if the email is pretty long but in this case that's all we did and now we can see we got those four vectors back same way we would have with the agent but what's cool is we have a lot more control over it so as you can see we have a vector and then we have a score which basically ranks how relevant it the vector was to the query that we sent off and so we have some pretty low ones over here but what we can do is say okay we only want to keep if the score is greater than 04 so it's only going to be keeping these two as you can see and it's getting rid of these two that aren't super relevant and this is something that's a lot easier to control in this linear flow compared to having the agent try to filter through vector results up here anyways then we're just aggregating however many results it pulls back if it's four if it's three or if it's just one it's still just going to aggregate them together so that we can feed it into our OpenAI node that's going to write the email so basically in the user prompt we said "Okay here's the customer inquiry here's the original email and here's the relevant knowledge that we found all you have to do now is write an email." And so by giving this AI node just one specific goal it's going to be more quality and consistent with its outputs rather than we gave the agent multiple jobs it had to not only write the email but it also had to figure out how to search through information and figure out what the next step was so this node it only has to focus on one thing it has the knowledge handed to it on a silver platter to write the email with and basically we said you're Mr helpful a customer support rep for Tech Haven your job is to respond to incoming customer emails with accurate information from the knowledge base you must only answer using relevant knowledge provided to you don't make anything up we gave it the tone and then we said only output the body in a clean format it outputs that body and then all it had to do is map in the correct message ID and the correct message content simple as that so I hope this makes sense obviously it's a lot cooler to watch the agent do something like that up here but this is basically the exact same flow and I would argue that it's going to be a lot better more consistent and cheaper okay so now to show an example where I released this as a YouTube video and a couple weeks later I was like why did I do it like that so what we have here is a technical analyst and so basically we're talking to it through Telegram and it has one tool which is basically going to get a chart image and then it's going to analyze the chart image and then it sends it back to us in Telegram and this is the workflow that it's actually calling right here where we're making an HTTP request to chart- image we're getting the chart downloading it analyzing the image sending it back and then responding back to the agent so there's basically like two transfers of data here that we don't need because as you can see down here we have the exact same process as one simple AI workflow so there's going to be much much less room for error here but first of all let's demo how this works and then we'll demo the actual AI workflow okay so it should be listening to us now i'm going to ask it to analyze Microsoft and as you can see it's now hitting that tool we won't see this workflow actually in real time just because it's like calling a different execution but this is the workflow that it's calling down here i can actually just it's basically calling this right here um so what it's going to do is it's going to send us an image and then a second or two later it's going to send us an actual analysis so there is Microsoft's stock chart and now it's creating that analysis as you can see right up here and then it's going to send us that analysis we just got it so if you want to see the full video that I made on YouTube I'll I'll tag it right up here but not going to dive too much into what's actually happening i just want to prove that we can do the exact same thing down here with a simple workflow although right here I did evolve this workflow a little bit so it's it's not only looking at NASDAQ but it can also choose different exchanges and feed that into the API call but anyways let's make this trigger down here active and let's just show off that we can do the exact same thing with the workflow and it's going to be better so test workflow this should be listening to us now I'm just going to ask it to um we'll do a different one analyze uh Bank of America so now it's getting it it is going to be downloading the chart actually want to open up Telegram so we can see downloading the chart analyzing the image it's going to send us that image and then pretty much immediately after it should be able to send us that analysis so we don't have that awkward 2 to 5 second wait obviously we're waiting here but as soon as this is done we should get the both the image and the text simultaneously there you go and so you can see the results are basically the same but this one is just going to be more consistent there's no transfer of data between workflow there's no need to hit an AI model to decide what tool I need to use it is just going to be one seamless flow you can al also get this workflow in the free school community if you want to play around with it just wanted to throw that out there anyways that's going to wrap us up here i just wanted to close off with this isn't me bashing on AI agents well I guess a little bit it was ai agents are super powerful they're super cool it's really important to learn prompt engineering and giving them different tools but it's just about understanding am I forcing an agent into something that doesn't need it am I exposing myself to the risk of lower quality outputs less consistency more difficult time scaling this thing things along those lines and so that's why I think it's super important to get into something like Excal wireframe out the solution that you're looking to build understand what are all the steps here what are the different API calls or different people involved what could happen here is this deterministic or is there an aspect of decision-m and variability here essentially is every flow going to be the same or not the same cool so now that we have that whole concept out of the way I think it's really important to understand that so that when you're planning out what type of system you're going to build you're actually doing it the right way from the start but now that we understand that let's finally set up our first AI agent together let's move into that video all right so at this point you guys are familiar with Naden you've built a few AI workflows and now it's time to actually build an AI agent which gets even cooler so before we actually hop into there and do that just want to do a quick refresher on this little diagram we talked about at the beginning of this video which is the anatomy of an AI agent so we have our input we have our actual AI agent and then we have an output the AI agent is connected to different tools and that's how it actually takes action and in order to understand which tools do I need to use it will look at its brain and its instructions the brain comes in the form of a large language model which in this video we'll be using open router to connect to as many different ones as we want and you guys have already set up your open router credentials then we also have access to memory which I will show you guys how we're going to set up in nadn then finally it uses its instructions in order to understand what to do and that is in the form of a system prompt which we will also see in naden so all of these elements that we've talked about will directly translate to something in nen and I will show you guys and call out exactly where these are so there's no confusion so we're going to hop in nitn and you guys know that a new workflow always starts with a trigger so I'm going to hit tab and I'm going to type in a chat trigger because we want to just basically be able to talk to our AI agent right here in the native Nadm chat so there is our trigger and what I'm going to do is click the plus and add an AI agent right after this trigger so we can actually talk to it and so this is what it looks like you know we have our AI agent right here but I'm going to click into it so we can just talk about the difference between a user message up here and a system message that we can add down here so going back to the example with chatbt and with our diagram when we're talking to chat gbt in our browser every single time we type and say something to chatbt that is a user message because that message coming in is dynamic every time so you can see right here the source for the prompt that the AI agent will be listening for as if it was chatbt is the connected chat trigger node so we're set up right here and the agent will be reading that every time if we were feeding in information to this agent that wasn't coming from the chat message trigger we'd have to change that but right now we're good and if we go back to our diagram this is basically the input that we're feeding into the AI agent so as you can see input goes into the agent and that's exactly what we have right here input going into the agent and then we have the system prompt so I'm going to click back into the agent and we can see right here we have a system message which is just telling this AI agent you are a helpful assistant so right now we're just going to leave it as that and back in our diagram that is right here its instructions which is called a system prompt so the next thing we can see that we need is we need to give our AI agent a brain which will be a large language model and also memory so I'm going to flick back into N and you can see we have two options right here the first one is chat model so I'm first of all just going to click on the plus for chat model i'm going to choose open router and we've already connected to open router and now I just get to choose from all of these different chat models to use so I'm just going to go ahead and choose a GBT 4.1 Mini and I'm just going to rename this node GPT 4.1 mini just so we know which one we're using cool so now we have our input our AI agent and a brain but let's give it some memory real quick which is as simple as just clicking the plus under memory and I'm just going to for now choose simple memory which stores it in and it end there's no credentials required and as you can see the session ID is looking for the connected chat trigger node because we're using the connected chat trigger node we don't have to change anything we are good to go so this is basically the core part of the agent right so what I can do is I can actually talk to this thing so I can say "Hey," and we'll see what it says back it's going to use its memory it's going to um use its brain to actually answer us and it says "Hello how can I assist you?" I can say "My name is Nate i am 23 years old." And now what I'm going to basically test is that it's storing all of this as memory and it's going to know that so now it says "Nice to meet you Nate how can I help you?" Now I'm going to ask you you know what's my name and how old am I so we'll send that off and now it's going to be able to answer us your name is Nate and you are 23 years old how can I assist you further so first of all the reason it's being so helpful is because its system message says you're a helpful assistant the next piece would be it's using its brain to answer us and it's using its memory to make sure it's not forgetting stuff about our current conversation so those are the three parts right there input AI agent brain and instructions and now it's time to add the tools so in this example we're going to build a super simple personal assistant AI agent that can do three things it's going to be able to look in our contact database in order to grab contact information with that contact information it's going to be able to send an email and it's going to be able to create a calendar event so first thing we're going to do is we're going to set up our contact database and what I'm going to do for that is just I have this Google sheet really simple it just says name and email this could be maybe you have your contacts in Google contacts you could connect that or an Air Table base or whatever you want this is just the actual tool the actual integration that we want to make to our AI agent so what I'm going to do is throw in a few rows of example names and emails in here okay so we're just going to stick with these three we've got Michael Scott Ryan Reynolds and Oprah Winfrey and now what we're going to be able to do is have our AI agent look at this contact database whenever we ask it to send an email to someone or make a calendar event with someone if I go back and add it in the first thing we have to do is add a tool to actually access this Google sheet so I'm going to click on tool i'm going to type in Google sheet it's as simple as that and you can see we have a Google Sheets tool so I'm going to click on that and now we have to set up our credential you guys have already connected to Google Sheets in the previous workflow so it shouldn't be too difficult so choose your credential and then the first thing is a tool description what we're going to do is we are going to just set this automatically and this basically describes to the AI agent what does this tool do so we could set it manually and describe ourselves but if you just set it automatically the AI is going to be pretty good at understanding what it needs to do with this tool the next thing is a resource so what are we actually looking for we're looking for a sheet within a document not an entire document itself then the operation is we want to just get rows so I'm going to leave it all as that and then what we need to do is actually choose our document and then the sheet within that document that we want to look at so for document I'm going to choose contacts and for sheet there's only one i'm just going to choose sheet one and then the last thing I want to do is just give this actual tool a pretty intuitive name so I'm just going to call this contacts database there you go so now it should be super clear to this AI agent when to use this tool we may have to do some system prompting actually to say like hey here are the different tools you have but for now we're just going to test it out and see if it works so what I'm going to do is open up the chat and just ask it can you please get Oprah Winfreyy's contact information there we go we'll send that off and we will watch it basically think and then there we go boom it hit the Google Sheet tool that we wanted it to and if I open up the chat it says Oprah Winfreyy's contact information is email opra winfrey.com if we go into the base we can see that is exactly what we put for her contact information okay so we've confirmed that the agent knows how to use this tool and that it can properly access Google Sheets the next step now is to add another tool to be able to send emails so I'm going to move this thing over i'm going to add another tool and I'm just going to search for Gmail and click on Gmail tool once again we've already covered credentials so hopefully you guys are already logged in there and then what we need to do is just configure the rest of the tool so tool description set automatically resource message operation send and then we have to fill out the two the subject the email type and the message what we're able to do with our AI agents and tools is something super super cool we can let our AI agent decide how to fill out these three fields that will be dynamic and all I have to do is click on this button right here to the right that says let the model define this parameter so I'm going to click on that button and now we can see that it says defined automatically by the model so basically if I said hey can you send an email to Oprah Winfrey saying this um and this it would then interpret our message our user input and it would then fill out who's this going to who's the subject and who's the email so I'll show you guys an example of that it's super cool so I'm just going to click on this button for subject and also this button for message and now we can see the actual AI use its brain to fill out these three fields and then also I'm just going to change the email type to text because I like it how it comes through as text so real quick just want to change this name to send email and all we have to do now is we're going to chat with our agent and see if it's able to send that email all right so I'm sending off this message that asks to send an email to Oprah asking how she's doing and if she has plans this weekend and what happened is it went straight to the send email tool and the reason it did that is because in its memory it remembered that it already knows Oprah Winfreyy's contact information so if I open chat it says the email's been sent asking how she's doing and if she has plans this weekend is there anything else that you would like to do so real quick before we go see if the email actually did get sent I'm going to click into the tool and what we can see is on this left hand side we can see exactly how it chose to fill out these three fields so for the two it put oprafree.com which is correct for the subject it put checking in and for the message it put hi Oprah i hope this weekend finds you well how are you doing do you have any plans best regards Nate and another thing that's really cool is the only reason that it signed off right here as best regards Nate is because once again it used its memory and it remembers that our name is Nate that's how it filled out those fields let me go over to my email and we'll take a look so in our sent we have the checking in subject we have the message that we just read in and it in and then we have this little thing at the bottom that says this email was automatically sent by NADN we can easily turn that off if we go into NADN open up the tool we add an option at the bottom that says append naden attribution and then we just turn off the append naden attribution and as you can see if we click on add options there are other things that we can do as well like we can reply to the sender only we can add a sender name we can add attachments all this other stuff but at a high level and real quick setup that is the send email tool and keep in mind we still haven't given our agent any sort of system prompt besides saying you're a helpful assistant so super cool stuff all right cool and now for the last tool what we want to do is add a create calendar event so I'm going to search calendar and grab a Google calendar node we already should be set up or if you're not actually all you have to do is just create new credential and sign in real quick because you already went and created your whole Google Cloud thing we're going to leave the description as automatic the resource is an event the operation is create the calendar is going to be one that we choose from our account and now we have a few things that we want to fill out for this tool so basically it's asking what time is the event going to start and what time is the event going to end so real quick I'm just going to do the same thing i'm going to let the model decide based on the way that we interact with it with our input and then real quick I just want to add one more field which is going to be a summary and basically whatever gets filled in right here for summary is what's going to show up as the name of the event in Google calendar but once again we're going to let the model automatically define this field so let's call this node create event and actually one more thing I forgot to do is we want to add an attendee so we can actually let the agent add someone to an event as well so that is the new tool we're going to hit save and remember no system prompts let's see if we can create a calendar event with Michael Scott all right all right so we're asking for dinner with Michael at 6 p.m what's going to happen is it probably Okay so we're going to have to do some prompting because we don't know Michael Scott's contact information yet but it went ahead and tried to create that email so it said that it created the event and let's click into the tool and see what happened so it tried to send the event invite to michael.scottample.com so it completely made that up because in our contacts base Michael Scott's email is mikegreatcott.com so it got that wrong that's the first thing it got wrong the second thing it got wrong was the actual start and end date so yes it made the event for 6 p.m but it made it for 6 p.m on April 27th 2024 which was over a year ago so we can fix this by using the system prompt so what I'm going to do real quick is go into the system prompt and I'm just going to make it just an expression and open it up full screen real quick what I'm going to say next is you must always look in the contacts database before doing something like creating an event or sending an email you need the person's email address in order to do one of those actions okay so that's a really simple thing we can add and then also what I want to tell it is what is today's current date and time so that if I say create an event for tomorrow or create an event for today it actually gets the date right so I'm just going to say here is the current date slashtime and all I have to do to give it access to the current date and time is do two curly braces and then right here you can see dollar sign now which says a date time representing the current moment so if I click on that on the right hand side in the result panel you can see it's going to show the current date and time so we're happy with that our system prompt has been a little bit upgraded and now we're going to just try that exact same query again and we'll see what happens so I'm going to click on this little repost message button send it again and hopefully now there we go it hits the contact database to get Michael Scott's email and then it creates the calendar event with Michael Scott so down here it says I've created a calendar event for dinner with Michael Scott tonight at 6 if you need any more assistance feel free to ask so if I go to my calendar we can see we have a 2-hour long dinner with Michael Scott if I click onto it we can see that the guest that was invited was mikegreatscott.com which is exactly what we see in our contact database and so you may have noticed it made this event for 2 hours because we didn't specify if I said "Hey create a 15-minute event," it would have only made it 15 minutes so what I'm going to do real quick is a loaded prompt okay so fingers crossed we're saying "Please invite Ryan Reynolds to a party tonight that's only 30 minutes long at 8 p.m and send him an email to confirm." So what happened here it went to go create an event and send an email but it didn't get Ryan Reynolds email first so if we click into this we can see that it sent an email to ryan.rrensacample.com that's not right and it went to create an event at ryan.rerensacample.com and that's not right either but the good news is if we go to calendar we can see that it did get the party right as far as it's 8 p.m and only 15 minutes so because it didn't take the right action it's not that big of a deal we know now that we have to go and refine the system prompt so to do that I'm going to open up the agent i'm going to click into the system prompt and we are going to fix some stuff up okay so I added two sentences that say "Never make up someone's email address you must look in the contact database tool." So as you guys can see this is pretty natural language we're just instructing someone how to do something as if we were teaching an intern okay so what I'm going to do real quick is clear this memory so I'm just going to reset the session and now we're starting from a clean slate and I'm going to ask that exact same query to do that multi-step thing with Ryan Reynolds all right take two we're inviting Ryan Reynolds to a party at 9:00 p.m there we go it's hitting the contacts database and now it's going to hit the create event and the send email tool at the same time boom i've scheduled a 30-minute party tonight at 9:00 p.m and invited Ryan Reynolds so let's go to our calendar we have a 9 p.m party for 30 minutes long and it is ryanpool.com which is exactly what we see in our contacts database and then if we go to our email we can see now that we have a party invitation for tonight to ryanpool.com but what you'll notice is now it didn't sign off as Nate because I cleared that memory so this would be a super simple fix we would just want to go to the system prompt and say "Hey when you're sending emails make sure you sign off as Nate." So that's going to be it for your first AI agent build this one is very simple but also hopefully really opens your eyes to how easy it is to plug in these different tools and it's really just about your configurations and your system prompts because system prompting is a really important skill and it's something that you kind of have to just try out a lot you have to get a lot of reps and it's a very iterative process but anyways congratulations you just built your first AI agent in probably less than 20 minutes and now add on a few more tools play around with a few more parameters and just see how this kind of stuff works in this section what I'm going to talk about is dynamic memory for your AI agents so if you remember we had just set up this agent and we were using simple memory and this was basically helping us keep conversation history but what we didn't yet talk about was the session ID and what that exactly means so basically think of a session ID as some sort of unique identifier that identifies each separate conversation so if I'm talking to you person A and you ask me something I'm gonna go look at conversations from our conversation person A and Nate and then I can read that for context and then respond to you but if person B talks to me I'm going to go look at my conversation history with person B before I respond to them and that way I keep two people and two conversations completely separate so that's what a session ID is so if we were having some sort of AI agent that was being triggered by an email we would basically want to set the session ID as the email address coming in because then we know that the agent's going to be uniquely responding to whoever actually sent that email that triggered it so just to demonstrate how that works what I'm going to do is just manipulate the session ID a little bit so I'm going to come into here and I'm going to instead of using the chat trigger node for the session ID I'm going to just define it below and I'm just going to do that exact example that I just talked to you guys about with person A and person B so I'm just going to put a lowercase A in there as the session ID key so once I save that what I'm going to do is just say hi now it's going to respond to me it's going to update the conversation history and say hi i'm going to say my name is um Bruce i don't know why I thought of Bruce but my name's Bruce and now it says nice to meet you Bruce how can I assist you now what I'm going to do is I'm going to change the session ID to B we'll hit save and I'm just going to say what's my name what's my name and it's going to say I don't have access to your name directly if you'd like you can provide your name or any other details you want me to know how can I assist you today so person A is Bruce person B is no name and what I'm going to do is go back to putting the key as A hit save and now if I say "What is my name?" with a misspelled my it's going to say "Hey Bruce." There we go your name is Bruce how can I assist you further and so that's just a really quick demo of how you're able to sort of actually have dynamic um conversations with multiple users in one single agent flow because you can make this field dynamic so what I'm going to do to show you guys a practical use of this let's say you're wanting to connect your agent to Slack or to Telegram or to WhatsApp or to Gmail you want the memory to be dynamic and you want it to be unique for each person that's interacting with it so what I have here is a Gmail trigger i'm going to hit test workflow which should just pull in an email so when we open up this email we can see like the actual body of the email we can see you know like history we can see a thread ID all this kind of stuff but what I want to look at is who is the email from because then if I feed this into the AI agent and first of all we would have to change the actual um user message so we are no longer talking to our agent with the connected chat trigger node right we're connecting to it with Gmail so I'm going to click to find below the user message is basically going to be whatever you want the agent to look at so don't even think about end right now if you had an agent to help you with your emails what would you want it to read you'd want it to read maybe a combination of the subject and the body so that's exactly what I'm going to do i'm just going to type in subject okay here's the subject down here and I'm going to drag that right in there and then I'm just going to say body and then I would drag in the actual body snippet and it's a snippet right now because in the actual Gmail trigger we have this flicked on as simplified if we turn that off it would give us not a snippet it would give us a full email body but for right now for simplicity we'll leave it simplified but now you can see that's what the agent's going to be reading every time not the connected chat trigger node and before we hit test step what we want to do is we want to make the sender of this email also the session key for the simple memory so we're going to define below and what I'm going to do is find the from field which is right here and drag that in so now whenever we get a new email we're going to be looking at conversation history from whoever sent that email to trigger this whole workflow so I'll hit save and basically what I'm going to do is just run the agent and what it's going to do is update the memory it's going to be looking at the correct thing and it's taking some action for us so we'll take a look at what it does but basically it said the invitation email for the party tonight has been sent to Ryan if you need any further assistance please let me know and the reason why it did that is because the actual user message basically was saying we're inviting Ryan to a party so hopefully that clears up some stuff about dynamic um user messages and dynamic memory and now you're on your way to building some pretty cool Jetic workflows and something important to touch on real quick is with the memory within the actual node what you'll notice is that there is a context window length parameter and this says how many past interactions the model receives as context so this is definitely more of the short-term memory because it's only going to be looking at the past five interactions before it crafts its response and this is not just with a simple memory node what we have here is if I delete this connection and click on memory you can see there are other types of memory we can use for our AI agents let's say for example we're doing Postgress which later in this course you'll see how to set this up but in Postgress you can see that there's also a context window length so just to show you guys an example of like what that actually looks like what we're going to do is just connect back to here i'm going to drag in our chat message trigger which means I'm going to have to change the input of the AI agent so we're going to get rid of this whole um defined below with the subject and body we're going to drag in the connected chat trigger node go ahead and give this another save and now I'm just going to come into the chat and say "Hello Mr agent what is going on here we have the memory is messed up." So remember I just changed the session ID from our chat trigger to the Gmail trigger um the address the email address of whoever just sent us the email so I'm going to have to go change that again i'm just going to simply choose connected chat trigger node and now it's referencing the correct session ID our variable is green we're good to go we'll try this again hello Mr agent it's going to talk to us so just save that as memory my name is Nate okay nice to meet you Nate how can I assist you my favorite color is blue and I'm going to say you know tell me about myself okay so it's using all that memory right we basically saw a demo of this but it basically says other than your name and your favorite color is blue what else is there about you so if I go into the agent and I click over here into the agent logs we can see the basically the order of operations that the agent took in order to answer us so the first thing that it does is it uses its simple memory and that's where you can see down here these are basically the past interactions that we've had which was um hello Mr agent my name is Nate my favorite color is blue and this would basically cap out at five interactions so that's all we're basically saying in this context window length right here so just wanted to throw that out there real quick this is not going to be absolutely unlimited memory to remember everything that you've ever said to your agent we would have to set that up in a different way all right so you've got your agent up and running you have your simple memory set up but something that I alluded to in that video was setting up memory outside of NADN which could be something like Postgress so in this next one we're going to walk through the full setup of creating a superbase account connecting your Postgress and your Superbase so that you can have your short-term memory with Postgress and then you can also connect a vector database with Superbase so let's get started so today I'm going to be showing you guys how to connect Postgress SQL and Superbase to Nadin so what I'm going to be doing today is walking through signing up for an account creating a project and then connecting them both to NADN so you guys can follow every step of the way but real quick Postgress is an open- source relational database management system that you're able to use plugins like PG vector if you want vector similarity search in this case we're just going to be using Postgress as the memory for our agent and then Superbase is a backend as a service that's kind of built on top of Postgress and in today's example we're going to be using that as the vector database but don't want to waste any time here we are in Naden and what we know we're going to do here for our agent is give it memory with Postgress and access to a vector database in Superbase so for memory I'm going to click on this plus and click on Postgress chat memory and then we'll set up this credential and then over here we want to click on the plus for tool we'll grab a superbase vector store node and then this is where we'll hook up our superbase credential so whenever we need to connect to these thirdparty services what we have to do is come into the node go to our credential and then we want to create a new one and then we have all the stuff to configure like our host our username our password our port all this kind of stuff so we have to hop into superbase first create account create a new project and then we'll be able to access all this information to plug in so here we are in Superbase i'm going to be creating a new account like I said just so we can walk through all of this step by step for you guys so first thing you want to do is sign up for a new account so I just got my confirmation email so I'm going to go ahead and confirm once you do that it's going to have you create a new organization and then within that we create a new project so I'm just going to leave everything as is for now it's going to be personal it's going to be free and I'll hit create organization and then from here we are creating a new project so I'm going to leave everything once again as is this is the organization we're creating the project in here's the project name and then you need to create a password and you're going to have to remember this password to hook up to our Subabase node later so I've entered my password i'm going to copy this because like I said you want to save this so you can enter it later and then we'll click create new project this is going to be launching up our project and this may take a few minutes so um just have to be patient here as you can see we're in the screen it's going to say setting up project so we pretty much are just going to wait until our project's been set up so while this is happening we can see that there's already some stuff that may look a little confusing we've got project API keys with a service ro secret we have configuration with a different URL and some sort of JWT secret so I'm going to show you guys how you need to access what it is and plug it into the right places in Naden but as you can see we got launched to a different screen the project status is still being launched so just going to wait for it to be complete so everything just got set up we're now good to connect to NAN and what you want to do is typically you'd come down to project settings and you click on database and this is where everything would be to connect but it says connection string has moved so as you can see there's a little button up here called connect so we're going to click on this and now this is where we're grabbing the information that we need for Postgress so this is where it gets a little confusing because there's a lot of stuff that we need for Postgress we need to get a host a username our password from earlier when we set up the project and then a port so all we're looking for are those four things but we need to find them in here so what I'm going to do is change the type to Postgress SQL and then I'm going to go down to the transaction pooler and this is where we're going to find the things that we need the first thing that we're looking for is the host which if you set it up just like me it's going to be after the -h so it's going to be AWS and then we have our region.pool.subase.com so we're going to grab that copy it and then we're going to paste that into the host section right there so that's what it should look like for host now we have a database and a username to set up so if we go back into that superbase page we can see we have a D and a U so the D is going to stay as Postgress but for user we're going to grab everything after the U which is going to be postgress.com and then these um different characters so I'm going to paste that in here under the user and for the password this is where you're going to paste in the password that you use to set up your Subbase project and then finally at the bottom we're looking for a port which is by default 5342 but in this case we're going to grab the port from the transaction pooler right here which is following the lowercase P so we have 6543 i'm going to copy that paste that into here as the port and then we'll hit save and we'll see if we got connection tested successfully there we go we got green and then I'm just going to rename this so I can keep it organized so there we go we've connected to Postgress as our chat memory we can see that it is going to be using the connected chat trigger node that's how it's going to be using the key to store this information and it's going to be storing it in a table in Subabase called Naden chat histories so real quick I'm going to talk to the agent i'm just going to disconnect the subbase so we don't get any errors so now when I send off hello AI agent it's going to respond to us with something like hey how can I help you today hello how can I assist you and now you can see that there were two things stored in our Postgress chat memory so we'll switch over to superbase and now we're going to come up here in the left and go to table editor we can see we have a new table that we just created called NAN chat histories and then we have two messages in here so the first one as you can see was a human type and the content was hello AI agent which is what we said to the AI agent and then the second one was a type AI and this is the AI's response to us so it said hello how can I assist you today so this is where all of your chats are going to be stored based on the session ID and just once again this session ID is coming from the connected chat trigger node so it's just coming from this node right here as you can see there's the session ID that matches the one in our our chat memory table and that is how it's using it to store sort of like the unique chat conversations cool now that we have Postgress chat memory set up let's hook up our Superbase vector store so we're going to drag it in and then now we need to go up here and connect our credentials so I'm going to create new credential and we can see that we need two things a host and a service role secret and the host is not going to be the same one as the host that we used to set up our Postgress so let's hop into Superbase and grab this information so back in Superbase we're going to go down to the settings we're going to click on data API and then we have our project URL and then we have our service ro secret so this is all we're using for URL we're going to copy this go back to Subase and then we'll paste this in as our host as you can see it's supposed to be HTTPS um and then your Superbase account so we'll paste that in and you can see that's what we have.co also keep in mind this is because I launched up an organization and a project in Superbase's cloud if you were to self-host this it would be a little different because you'd have to access your local host and then of course we need our service ro secret so back in Superbase I'm going to reveal copy and then paste it into an end so let me do that real quick and as you can see I got that huge token just paste it in so what I'm going to do now is save it hopefully it goes green there we go we have connection tested successfully and then once again just going to rename this the next step from here would be to create our Superbase vector store within the platform that we can actually push documents into so you're going to click on docs right here you are going to go to the quick start for setting up your vector store and then all you have to do right here is copy this command so in the top right copy this script come back into Subabase you'll come on the lefth hand side to SQL editor you'll paste that command in here you don't change anything at all you'll just hit run and then you could should see down here success no rows returned and then in the table editor we'll have a new table over here called documents so this is where when we're actually vectorizing our data it's going to go into this table okay okay so I'm just going to do a real quick example of putting a Google doc into our Subbase vector database just to show you guys that everything's connected the way it should be and working as it should so I'm going to grab a Google Drive node right here i'm going to click download file i'm going to select a file to download which in this case I'm just going to grab body shop services terms and conditions and then hit test step and we'll see the binary data which is a doc file over here and now we have that information and what we want to do with it is add it to superbase superbase vector store so I'm going to type in superbase we'll see vector store the operation is going to be add documents to vector store and then we have to choose the right credential because we have to choose the table to put it in so this is in this case we already made a table as you can see in our superbase it's called documents so back in here I'm going to choose the credential I just made i'm going to choose insert documents and I'm going to choose the table to insert it to not the N chat histories we want to insert this to documents because this one is set up for vectorization from there I have to choose our document loader as well as our embeddings so I'm not really going to dive into exactly what this all means right now if you're kind of confused and you're wanting a deeper dive on rag and building agents definitely check out my paid community we've got different deep dive topics about all this kind of stuff but I'm just going to set this up real quick so we can see the actual example i'm just choosing the binary data to load in here i'm choosing the embedding and I'm choosing our text splitter which is going to be recursive and so now all I have to do here is hit run it's going to be taking that binary data of that body shop file it split it up and as you can see there's three items so if we go back into our Superbase vector store and we hit refresh we now see three items in our vector database and we have the different content and all this information here like the standard oil change the synthetic oil change is coming from our body shop document that I have right here that we put in there just to validate the rag and we know that this is a vector database store rather than a relational one because we can see we have our vector embedding over here which is all the dimensions and then we have our metadata so we have stuff like the source and um the blob type all this kind of stuff and this is where we could also go ahead and add more metadata if we wanted to anyways now that we have vectors in our documents table we can hook up the actual agent to the correct table so in here what I'm going to call this is um body shop for the description I'm going to say use this to get information about the body shop and then from the table name we have to choose the correct table of course so we know that we just put all this into something called documents so I'm going to choose documents and finally we just have to choose our embeddings of course so that it can embed the query and pull stuff back accurately and that's pretty much it we have our AI agent set up so let's go ahead and do a test and see what we get back so I'm going to go ahead and say what brake services are offered at the body shop it's going to update the Postgress memory so now we'll be able to see that query it hit the Superbase vector store in order to retrieve that information and then create an augmented generated answer for us and now we have the body shop offers the following brake services 120 per axle for replacement 150 per axle for rotor replacement and then full brake inspection is 30 bucks so if we click back into our document we can see that that's exactly what it just pulled and then if we go into our vector database within Subase we can find that information in here but then we can also click on NAN chat history and we can see we have two more chats so the first one was a human which is what we said what brake services are offered at the body shop and then the second one was a AI content which is the body shop offers the following brake services blah blah blah and this is exactly what it just responded to us with within NADN down here as you can see and so keep in mind this AI agent has zero prompting we didn't even open up the system message all that's in here is you are a helpful assistant but if you are setting this up what you want to do is you know explain its role and you want to tell it you know you have access to a vector database it is called X it has information about X Y and Z and you should use it when a client asks about X Y and Z anyways that's going to be it for this one subase and Postgress are super super powerful tools to use to connect up as a database for your agents whether it's going to be relational or vector databases and you've got lots of options with you know self-hosting and some good options for security and scalability there now that you guys have built an agent and you see the way that an agent is able to understand what tools it has and which ones it needs to use what's really really cool and powerful about NAND is that we can have a tool for an AI agent be a custom workflow that we built out in Nadn or we can build out a custom agent in Naden and then give our main agent access to call on that lower agent so what I'm about to share with you guys next is an architecture you can use when you're building multi- aent systems it's basically called having an orchestrator agent and sub agents or parent agents and child agents so let's dive into it i think you guys will think it's pretty cool so a multi- aent system is one where we have multiple autonomous AI agents working together in order to get the job done and they're able to talk to each other and they're able to use the tools that they have access to what we're going to be talking about today is a type of multi- aent system called the orchestrator architecture and basically what that means that we have one agent up here i call it the parent agent and then I call these child agents but we have an orchestrator agent that's able to call on different sub aents and the best way to think about it is this agent's only goal is to understand the intent of the user whether that's through Telegram or through email whatever it is understanding that intent and then understanding okay I have access to these four agents and here is what each one is good at which one or which ones do I need to call in order to actually achieve the end goal so in this case if I'm saying to the agent can you please write me a quick blog post about dogs and send that to Dexter Morgan and can you also create a dinner event for tonight at 6 p.m with Michael Scott and thank you cool so this is a pretty loaded task right and can you imagine if this one agent had access to all of these like 15 or however many tools and it had to do all of that itself it would be pretty overwhelmed and it wouldn't be able to do it very accurately so what you can see here is it is able to just understand okay I have these four agents they each have a different role which ones do I need to call and you can see what it's doing is it called the contact agent to get the contact information right now it's calling the content creator agent and now that that's finished up it's probably going to call the calendar agent to make that event and then it's going to call the email agent in order to actually send that blog that we had the content creator agent make and then you can see it also called this little tool down here called Think if you want to see a full video where I broke down what that does you can watch it right up here but we just got a response back from the orchestrator agent so let's see what it said all right so it said "The blog post about dogs has been sent to Dexter Morgan a dinner event for tonight at 6 p.m with Michael Scott has been created and if you need anything else let me know." And just to verify that that actually went through you can see we have a new event for dinner at 6 p.m with Michael Scott and then in our email and our scent we can see that we have a full blog post sent to Dexter Morgan and you can see that we also have a link right here that we can click into which means that the content creator agent was able to do some research find this URL create the blog post and send that back to the orchestrator agent and then the orchestrator agent remembered okay so I need to send a blog post to Dexter Morgan i've got his email from the contact agent i have the blog post from the content creator agent now all I have to do is pass it over to the email agent to take care of the rest so yes it's important to think about the tools because if this main agent had access to all those tools it would be pretty overwhelming but also think about the prompts so in this ultimate assistant prompt it's pretty short right all I had to say was "You're the ultimate assistant your job is to send the user's query to the correct tool you should never be writing emails or ever creating summaries or doing anything you just need to delegate the task." And then what we did is we said "Okay you have these six tools here's what they're called here's when you use them." And it's just super super clear and concise there's almost no room for ambiguity we gave it a few rules an example output and basically that's it and now it's able to interpret any query we might have even if it's a loaded query as you can see in this case it had to call all four agents but it still got it right and then when it sends over something to like the email agent for example we're able to give this specific agent a very very specific system prompt because we only have to tell it about you only have access to these email tools and this is just going back to the whole thing about specialization it's not confusing it knows exactly what it needs to do same thing with these other agents you know the calendar agent of course has its own prompts with its own set of calendar tools the contact agent has its own prompt with its own set of contact tools and then of course we have the content creator agent which has to know how to not only do research using its tavly tool but it also has to format the blog post with you know proper HTML as you can see here there was like a title there were headings there were you know inline links all that kind of stuff and so because we have all of this specialized can you imagine if we had all of that system prompt thrown into this one agent and gave it access to all the tools just wouldn't be good and if you're still not convinced think about the fact that for each of these different tasks because we know what each agent is doing we're able to give it a very specific chat model because you know like for something like content creation I like to use cloud 3.7 but I wouldn't want to use something as expensive as cloud 3.7 just to get contacts or to add contacts to my contact database so that's why I went with Flash here and then for these ones I'm using 4.1 Mini so you're able to have a lot more control over exactly how you want your agents to run and so I pretty much think I hit on a lot of that but you know benefits of multi-agent system more reusable components so now that we have built out you know an email agent whenever I'm building another agent ever and I realize okay maybe it would be nice for this agent to have a couple email functions boom I just give it access to the email agent because we've already built it and this email agent can be called on by as many different workflows as we want and when we're talking about reusable components that doesn't have to just mean these agents are reusable it could also be workflows that are reusable so for example if I go to this AI marketing team video if you haven't watched it I'll leave a link right up here these tools down here none of these are agents they're all just workflows so for example if I click into the video workflow you can see that it's sending data over to this workflow and even though it's not an agent it still is going to do everything it needs to do and then send data back to that main agent similarly with this create image tool if I was to click into it real quick you can see that this is not an agent but what it's going to do is it's going to take information from that orchestrator agent and do a very specific function that way this main agent up here all it has to do is understand I have these different tools which one do I need to use so reusable components and also we're going to have model flexibility different models for different agents we're going to have easier debugging and maintenance because like I said with the whole prompting thing if you tried to give that main agent access to 25 tools and in the prompt you have to say here's when you use all 25 tools and it wasn't working you wouldn't know where to start you would feel really overwhelmed as to like how do I even fix this prompt so by splitting things up into small small tasks and specialized areas it's going to make it so much easier exactly like I just covered point number four clear prompts logic and better testability and finally it's a foundation for multi-turn agents or agent memory just because we're sending data from main agent to sub agent doesn't mean we're losing that context of like we're talking to Nate right now or we're talking to Dave right now we can still have that memory pass between workflows so things get really really powerful and it's just pretty cool okay so we've seen a demo i think you guys understand the benefits here just one thing I wanted to throw out before we get into like a live build of a multi- aent system is just because this is cool and there's benefits doesn't mean it's always the right thing to do so if you're forcing a multi-agent orchestrator framework into a process that could be a simple single agent or a simple AI workflow all you're going to be doing is you're going to be increasing the latency you're going to be increasing the cost because you're making more API calls and you're probably going to be increasing the amount of error just because kind of the golden rule is you want to eliminate as much data transfer between workflows as you can because that's where you can run into like some issues but of course there are times when you do need dedicated agents for certain functions so let's get into a new workflow and build a really simple example of an orchestrator agent that's able to call on a sub agent all right so what we're going to be doing here is we're going to build an orchestrator agent so I'm going to hit tab i'm going to type in AI agent and we're going to pull this guy in and we're just going to be talking to this guy using that little chat window down here for now so first thing we need to do as always is connect a brain i'm going to go ahead and grab an open router and we're just going to throw in a 4.1 mini and I'll just change this name real quick so we can see what we're using and from here we're basically just going to connect to a subworkflow and then we'll go build out that actual subworkflow agent so the way we do it is we click on this plus under tool and what we want to do is call nen workflow tool because you can see it says uses another nen workflow as a tool allows packaging any naden node as a tool so it's super cool that's how we can send data to these like custom things that we built out as you saw earlier when I showed that little example of the marketing team agent that's how we can do it so I'm going to click on this and basically when you click on this there's a few things to configure the first one is a description of when do you use this tool you'll kind of tell the agent that here and you'll also be able to tell a little bit in a system prompt but you have to tell it when to use this tool and then the next thing is actually linking the tool so you can see we can choose from a list of our different workflows in NAN you can see I have a ton of different workflows here but all you have to do is you have to choose the one that you want this orchestrator agent to send data to and one thing I want to call attention to here is this text box which says the tool will call the workflow you defined below and it will look in the last node for the response the workflow needs to start with an execute workflow trigger so what does this mean let's just go build another workflow and we will see exactly what it means so I'm going to open up a new workflow which is going to be our sub agent so I'm going to hit tab to open up the nodes and it's obviously prompting us to choose a trigger and we're going to choose this one down here that says when executed by another workflow runs the flow when called by the execute workflow node from a different tool so basically the only thing that can access this node and send data to this node is one of these bad boys right here so these two things are basically just connected and data is going to be sending between them and what's interesting about this node is you can have a couple ways that you accept data so by default I usually just put it on accept all data and this will put things into a field right here called query but if you wanted to you could also have it send over specific fields so if you wanted to only get like you know a phone number and you wanted to get a name and you wanted to get an email and you wanted those all to already be in three separate fields that's how you could do that and a practical example of that would be in my marketing team right here in the create image you can see that I'm sending over an image title an image prompt and a chat ID and that's another good example of being able to send you know like memory over because I have a chat ID coming from here which is memory to the agent right here but then I can also send that chat ID to the next workflow if we need memory to be accessed down here as well so in this case just to start off we're not going to be sending over specified fields we're just going to do accept all data and let us connect an AI agent to this guy so I'm going to type in AI agent we'll pull this in the first thing we need to do is we need to change this because we're not going to be talking through the connected chat trigger node as we know because we have this trigger right here so what we're going to do is save this workflow so now it should actually register an end that we have this workflow i'm going to go back in here and we're just going to connect it so we know that it's called subwork sub aent so grab that right there and now you can see it says the sub workflow is set up to receive all input data without specific inputs the agent will not be able to pass data to this tool you can define the specific inputs in the trigger so that's exactly what I just showed you guys with changing that right there so what I want to do is show how data gets here so we can actually map it so the agent can read it so what we need to do before we can actually test it out is we need to make sure that this orchestrator agent understands what this tool will do and when to use it so let's just say that this one's going to be an email agent first thing I'm going to do is just intuitively name this thing email agent i'm then going to type in the description call this tool to take any email actions so now it should basically you know signal to this guy whenever I see any sort of query come in that has to do with email i'm just going to pass that query right off to this tool so as you can see I'm not even going to add a system message to this AI agent yet we're just going to see if we can understand and I'm going to come in here and say "Please send an email to Nate asking him how he's doing." So we fire that off and hopefully it's going to call this tool and then we'll be able to go in there and see the query that we got the reason that this errored is because we haven't mapped anything so what I'm going to do is click on the tool i'm going to click on view subexecution so we can pop open like the exact error that just happened and we can see exactly what happened is that this came through in a field called query but the main agent is not looking for a field called query it's looking for a field called chat input so I'm just going to click on debug and editor so we can actually pull this in now all I have to do is come in here change this to define below and then just drag in the actual query and now we know that this sub agent is always going to receive the orchestrator agents message but what you'll notice here is that the orchestrator agent sent over a message that says "Hi Nate just wanted to check in and see how you're doing hope all is well." So there's a mistake here because this main agent ended up basically like creating an email and sending it over all we wanted to do is basically just pass the message along so what I would do here is come into the system prompt and I'm just going to say overview you are an orchestrator agent your only job is to delegate the task to the correct tool no need to write emails or create summaries there we go so just with a very simple line that's all we're going to do and before we shoot that off I'm just going to go back into the sub workflow and we have to give this thing an actual brain so that it can process messages we're just going to go with a 4.1 mini once again save that so it actually reflects on this main agent and now let's try to send off this exact same query and we'll see what it does this time so it's calling the email agent tool it shouldn't error because we we we fixed it but as you can see now it just called that tool twice so we have to understand why did it just call the sub agent twice first thing I'm going to do is click into the main agent and I'm going to click on logs and we can see exactly what it did so when it called the email agent once again it sent over a subject which is checking in and an actual email body so we have to fix the prompting there right but then the output which is basically what that sub workflow sent back said here's a slightly polished version of your message for a warm and clear tone blah blah blah and then for some reason it went and called that email agent again so now it says please send the following email and it sends it over again and then the sub agent says I can't send emails directly but here's the email you can send so they're both in this weird loop of thinking they are creating them an email but not actually being able to send them so let's take a look and see how we can fix that all right so back in the sub workflow what we want to do now is actually let this agent have the ability to send emails otherwise they're just going to keep doing that endless loop so I'm going to add a tool and type in Gmail we're going to change this to a send message operation i'm just going to rename this send email and we're just going to have the two be defined by the model we're going to have the subject be defined by the model and we're going to have the message be defined by the model and all this means is that ideally you know this query is going to say hey send an email to nateample.com asking what's up the agent would then interpret that and it would fill out okay who is it going to what's the subject and what's the message it would basically just create it all itself using AI and the last thing I'm going to do is just turn off the Nent attribution right there and now let's give it another shot and keep in mind there's no system prompt in this actual agent and I actually want to show you guys a cool tip so when you're building these multi- aent systems and you're doing things like sending data between flows if you don't want to always go back to the main agent to test out like how this one's working what you can do is come into here and we can just edit this query and just like set some mock data as if the main agent was sending over some stuff so I'm going to say like we're pretending the orchestrator agent sent over to the sub workflow send an email to nate@example.com asking what's up and we'll just get rid of that R and then now you can see that's the query that's exactly what this agent's going to be looking at right here and if we hit play above this AI agent we'll see that hopefully it's going to call that send email tool and we'll see what it did so it just finished up we'll click into the tool to see what it did and as you can see it sent it to Nate example it made the subject checking in and then the message was "Hey Nate just wanted to check in and see what's up best your name so my thought process right now is like let's get everything working the way we want it with this agent before we go back to that orchestrator agent and fix the prompting there so one thing I don't like is that it's signing off with best your name so we have a few options here we could do that in the system prompt but same thing with like um specialization if this tool is specialized in sending emails we might as well instruct it how to send emails in this tool so for the message I'm going to add a description and I'm going to say always sign off emails as Bob and that really should do it so because we have this mock data right here I don't have to go and you know send another message i can just test it out again and see what it's going to do so it's going to call the send email tool it's going to make that message and now we will go ahead and look and see if it's signed off in a better way right here we can see now it's signing off best Bob so let's just say right now we're happy with the way that our sub agent's working we can go ahead and come back into the main agent and test it out again all right so I'm just going to shoot off that same message again that says "Send an email to Nate asking him how he's doing." And this will be interesting we'll see what it sends over it was one run and it says "Could you please provide Nate's email address so I can send the message?" So what happened here was the subexecution realized we don't have Nate's email address and that's why it basically responded back to this main agent and said "I need that if I need to send the message." So if I click on subexecution we will see exactly what it did and why it did that and it probably didn't even call that send email tool yeah so it actually failed and it failed because it tried to fill out the two as Nate and it realized that's not like a valid email address so then because this sub agent responds with could you please provide Nate's email address so I can send the message that's exactly what the main agent saw right here in the response from this agent tool so that's how they're able to talk to each other go back and forth and then you can see that the orchestrator agent prompted us to actually provide Nate's email address so now we're going to try please send an email to nativeample.com asking him how the project is coming along we'll shoot that off and everything should go through this time and it should basically say oh which project are you referring to this will help me provide you with the most accurate and relevant update so once again the sub agent is like okay I don't have enough information to send off that message so I'm going to respond back to that orchestrator agent and just because we actually need one to get through let me shoot off one more example okay hopefully this one's specific enough we have an email address we have a specified name of a project and we should see that hopefully it's going to send this email this time okay there we go the email asking Nate how Project Pan is coming along it's been sent anything else you need so at this point it would be okay which other agents could I add to the system to make it a bit easier on myself the first thing naturally to do would be I need to add some sort of contact agent or maybe I realize that I don't need a full agent for that maybe that needs to just be one tool so basically what I would do then is I'd add a tool right here i would grab an air table because that's where my contact information lives and all I want to do is go to contacts and choose contacts and now I just need to change this to search so now this tool's only job is to return all of the contacts in my contact database i'm just going to come in here and call this contacts and now keep in mind once again there's still nothing in the system prompt about here are the tools you have and here's what you do i just want to show you guys how intelligent these models can be before you even prompt them and then once you get in there and say "Okay now you have access to these seven agents here's what each of them are good at it gets even cooler." So let's try one more thing and see if it can use the combination of contact database and email agent okay so I'm going to fire this off send an email to Dexter Morgan asking him if he wants to get lunch you can see that right away it used the contacts database pulled back Dexter Morgan's email address and now we can see that it sent that email address over to the email agent and now we have all of these different data transfers talking to each other and hopefully it sent the email all right so here's that email hi Dexter would you like to get lunch sometime soon best Bob the formatting is a little off we can fix that within the the tool for the email agent but let's see if we sent that to the right email which is dextermiami.com if we go into our contacts database we can see right here we have dextermorggan dextermiami.com and like I showed you guys earlier what you want to do is get pretty good at reading these agent logs so you can see how your agents are thinking and what data they're sending between workflows and if we go to the logs here we can see first of all it used its GPT4.1 mini model brain to understand what to do it understood okay I need to go to the contacts table so I got my contact information then I need to call the email agent and what I sent over to the email agent was send an email to dextermiami.com asking him if he wants to get lunch and that was perfect all right all right so that's going to do it for this one hopefully this opened your eyes to the possibilities of these multi- aent systems in N&N and also hopefully it taught you some stuff because I know all of this stuff is like really buzzwordy sometimes with all these agents agents agents but there are use cases where it really is the best path but it's all about like understanding what is the end goal and how do I want to evolve this workflow and then deciding like what's the best architecture or system to use so that was one type of architecture for a multi-agent system called the orchestrator architecture but that's not the only way to have multiple agents within a workflow or within a system so in this next section I'm going to break down a few other architectures that you can use so that you can understand what's possible and which one fits your use case best so let's dive right in so in my ultimate assistant video we utilize an agentic framework called parent agent so as you can see we have a parent agent right here which is the ultimate assistant that's able to send tasks to its four child agents down here which are different workflows that we built out within NAND if you haven't seen that video I'll tag it right up here but how it works is that the ultimate assistant could get a query from the human and decide that it needs to send that query to the email agent which looks like this and then the email agent will be able to use its tools in Gmail and actually take action from there it responds to the parent agent and then the parent agent is able to take that response back from this child agent and then respond to us in Telegram so it's a super cool system it allows us to delegate tasks and also these agents can be activated in any specific order it doesn't always have to be the same but is this framework always the most effective no so today I'm going to be going over four different agentic frameworks that you can use in your end workflows the first one we're going to be talking about is prompt chaining the second one is routing the third one is parallelization and the fourth one is evaluator optimizer so we're going to break down how they all work what they're good at but make sure you stick around to the end because this one the evaluator optimizer is the one that's got me most excited so before we get into this first framework if you want to download these four templates for free so you can follow along you can do so by joining my free school community you'll come in here click on YouTube resources click on the post associated with this video and then you'll have the workflow right here to download so the link for that's down in the description there's also going to be a link for my paid community which is if you're looking for a more hands-on approach to learning NAND we've got a great community of members who are also dedicated to learning NAN sharing resources sharing challenges sharing projects stuff like that we've got a classroom section where we're going over different deep dive topics like building agents vector databases APIs and HTTP requests and I also just launched a new course where I'm doing the step-by-step tutorials of all the videos that I've shown on YouTube and finally we've got five live calls per week to make sure that you're getting questions answered never getting stuck and also networking with individuals in the space we've also got guest speakers coming in in February which is super exciting so I'd love to see you guys in these calls anyways back to the video here the first one we're going to be talking about is prompt chaining so as you can see the way this works we have three agents here and what we're doing is we're passing the output of an agent directly as the input into the next agent and so on so forth so here are the main benefits of this type of workflow it's going to lead to improved accuracy and quality because each step focuses on a specific task which will help reduce errors and hallucinations greater control over each step we can refine the system prompt of the outline writer and then we can refine the prompt of the evaluator so we can really tweak what's going on and how data is being transferred specialization is going to lead to more effective agents so as you can see in this example we're having one agent write the outline one of them evaluates the outline and makes suggestions and then finally we pass that revised outline to the blog writer who's in charge of actually writing the blog so this is going to lead to a much more cohesive thought through actual blog in the end compared to if we would just fed in all of this system prompt into one agent and then finally with this type of framework we've got easier debugging and optimization because it's linear we can see where things are going wrong finally it's going to be more scalable and reusable as we're able to plug in different agents wherever we need them okay so what we have to do here is we're just going to enter in a keyword a topic for this um blog so I'm just going to enter in coffee and we'll see that the agents start going to work so the first one is an outline writer um one thing that's also really cool about this framework and some of the other ones we're going to cover is that because we're splitting up the different tasks we're able to utilize different large language models so as you can see the outline writer we gave 20 Flash because it's it's free um it's it's powerful but not super powerful and we just need a brief outline to be written here and then we can pass this on to the next one that uses 40 Mini it's a little more powerful a little more expensive but still not too bad and we want this more powerful chat model to be doing the evaluating and refining of the outline and then finally for the actual blog writing content we want to use something like Claw 3.5 or even Deepseek R1 because it's going to be more powerful and it's going to take that revised outline and then structure a really nice blog post for us so that's just part of the specialization not only can we split up the tasks but we can plug and play different chat models where we need to rather than feeding everything through one you know one Deep Seeker one blog writer at the very beginning so this one's finishing up here it's about to get pushed into a Google doc where we'll be able to go over there and take a look at the blog that it got for us about coffee so looks like it just finished up here we go detailed blog post based on option one a comprehensive guide to coffee here's our title um we have a rich history of coffee from bean to cup we have um different methods we have different coffee varieties we have all this kind of stuff health benefits and risks um and as you can see this pretty much was a four-page blog we've got a conclusion at the end anyways let's dive into what's going on here so the concept is passing the output into the input and then taking that output and passing it into the next input so here we have here's the topic to write a blog about which all it got here was the word coffee that's what we typed in the system message is that you are an expert outline writer your job is to generate a structured outline for a blog post with section titles and key points so here's the first draft at the outline using 20 flash then we pass that into an outline evaluator that's using for Mini we said here's the outline we gave it the outline of course and then the system message is you're an expert blog evaluator your job is to revise this outline and make sure it hits these four criteria which are engaging introduction clear section breakdown logical flow and then a conclusion so we told it to only output the revised outline so now we have a new outline over here and finally we're sending that into a Claude 3.5 blog writer where we gave it the revised outline and just said "You're an expert blog writer generate a detailed blog post using this outline with well ststructured paragraphs and engaging content." So that's how this works you can see it will be even more powerful once we hook up you know like some internet search functionality and if we added like an editor at the end before it actually pushed it into the the Google doc or whatever it is but that's how this framework works but let's move into aic framework number two now we're going to talk about the routing framework in this case we have an initial LLM call right here to classify incoming emails and based on that classification it's going to route it up as high priority customer support promotion their finance and billing and as you can see there's different actions that are going to take place we have different agents depending on what type of message comes through so the first agent which is the text classifier here basically just has to decide okay which agent do I need to send this email off to anyways why would you want to use routing because you're going to have an optimized response handling so as we can see in this case we're able to set up different personas for each of our agents here rather than having one general AI response agent then this can be more scalable and modular it's going to be faster and more efficient and then you can also introduce human escalation for critical issues like we do up here with our high priority agent and finally it's just going to be a better user experience for for your team and also your customers so I hit test step what we're getting here is an email that I just sent to myself that says "Hey I need help logging into my account can you help me?" So this email classifier is going to label this as customer support as soon as we hit play it's going to send it down the customer support branch right here as you can see we got one new item what's going on in this step is that we're just labeling it in our Gmail as a customer support email and then finally we're going to fire it off to the customer support agent in this case this one is trained on customer support activities um this is where you could hook up a customer support database if you needed and then what it's going to do is it's going to create an email draft for us in reply to the email that we got so let's go take a look at that so here's the email we got hey I need help logging into my account as you can see our agent was able to label it as customer support and then finally it created this email which was "Hey Nate thanks for reaching out i'd be happy to assist you with logging into your account please provide me with some more details um about the issue you're experiencing blah blah blah." And then this one signs off "Best regards Kelly because she's the customer support rep." Okay let's take a look at a different example um we'll pull in the trigger again and this time we're going to be getting a different email so as you can see this one says "Nate this is urgent we need your outline tomorrow or you're fired." So hopefully this one gets labeled as high priority it's going to go up here to the high priority branch once again we're going to label that email as high priority but instead of activating an email draft reply tool this one has access to a Telegram tool so what it's going to do is text us immediately and say "Hey this is the email you got you need to take care of this right away." Um and obviously the logic you can choose of what you want to happen based on what route it is but let's see we just got telegram message urgent email from Nate Hkelman stating that an outline is needed by tomorrow or there will be serious consequences potential termination so that way it notifies us right away we're able to get into our email manually you know get get caught up on the thread and then respond how we need to and so pretty much the same thing for the other two promotional email will get labeled as promotion we come in here and see that we are able to set a different persona for the pro promotion agent which is you're in charge of promotional opportunities your job is to respond to inquiries in a friendly professional manner and use this email to send reply to customer always sign off as Meredith from ABC Corp so each agent has a different sort of persona that it's able to respond to in finance agent we have we have this agent signing off as a as Angela from ABC Corp um anyways what I did here was I hooked them all up to the same chat model and I hooked them all up to the same tool because they're all going to be sending an email draft here as you can see we're using from AAI to determine the subject the message and the thread ID which it's going to pull in from the actual Gmail trigger or sorry the Gmail trigger is not using from AAI we're we're mapping in the Gmail trigger because every time an email comes through it can just look at that um email in order to determine the thread ID for sending out an email but you don't have to connect them up to the same tool i just did it this way because then I only had to create one tool same thing with the different chat models based on the you know importance of what's going through each route you could switch out the chat models we could have even used a cheaper easier one for the classification if we wanted to but in this case I just hooked them all up to a 40 mini chat model anyways this was just a really simple example of routing you could have 10 different routes you could have just two different routes but the idea is that you're using one agent up front to determine which way to send off the data moving on to the third framework we've got parallelization what we're going to do here is be using three different agents and then we're going to merge their outputs aggregate them together and then feed them all into a final agent to sort of you know throw it all into one response so what this is going to do is give us faster analysis rather than processing everything linearly so in this case we're going to be sending in some input and then we're going to have one agent analyze the emotion behind it one agent do the intent behind it and then one agent analyze any bias rather than doing it one by one they're all going to be working simultaneously and then throwing their outputs together so it can decrease the latency there they're going to be specialized which means we could have specialized system prompts like we do here we also could do specialized um large language models again where we could plug in different different models if we wanted to maybe feed through the same prompt use cloud up here OpenAI down here and then you know DeepSeek down here and then combine them together to make sure we're getting the best thoughtout answer um comprehensive review and then more scalability as well but how this one's going to work is we're putting in an initial message which is I don't trust the mainstream media anymore they always push a specific agenda and ignore real issues people need to wake up and stop believing everything they see on the news so we're having an emotion agent first of all analyze the emotional emotional tone categorize it as positive neutral negative or mixed with a brief explanation the intent agent is going to analyze the intent behind this text and then finally the bias agent is going to analyze this text for any potential bias so we'll hit this off um we're going to get those three separate analysises um or analysis and then we're going to be sending that into a final agent that's going to basically combine all those outputs and then write a little bit of report based on our input so as you can see right now it's waiting here for um the input from the bias agent once that happens it's going to get aggregated and now it's being sent into the final agent and then we'll take a look at um the report that we got in our Google doc okay just finished up let's hop over to Docs we'll see we got an emotional tone intent and bias analysis report overview is that um the incoming text has strong negative sentiment towards mainstream media yep emotional tone is negative sentiment intent is persuasive goal um the bias analysis has political bias generalization emotional language lack of evidence um it's got recommendations for how we can make this text more neutral revised message and then let's just read off the conclusion the analysis highlights a significant level of negativity and bias in the original message directed towards mainstream media by implementing the suggested recommendations the author can promote a more balanced and credible perspective that encourages critical assessment of media consumption blah blah blah so as you can see that's going to be a much better you know comprehensive analysis than if we would have just fed the initial input into an agent and said "Hey can you analyze this text for emotion intent and bias?" But now we got that split up merged together put into the final one for you know a comprehensive review and an output and it's going to turn the the you know data in into data out process it's going to be a lot more efficient finally the one that gets me the most excited um the evaluator optimizer framework where we're going to have an evaluator agent decide if what's passing through is good or not if it's good we're fine but if it's not it's going to get optimized and then sent back to the evaluator for more evaluation and this is going to be an endless loop until the evaluator agent says "Okay finally it's good enough we'll send it off." So if you watch my human in the loop video it's going to be just like that where we were providing feedback and we were the ones basically deciding if it was good to go or not but in this case we have an agent that does that so it's going to be optimizing all your workflows on the back end without you being in the loop so obviously the benefits here are that it's going to ensure high quality outputs it's going to reduce errors and manual review it's going to be flexible and scalable and then it's going to optimize the AI's performance because it's sort of an iterative approach that um you know focuses on continuous improvement from these AI generated responses so what we're doing here is we have a biography agent what we told this agent to do is um basically write a biography you're an expert biography writer you'll receive information about a person your job is to create an entire profile using the information they give you and I told it you're allowed to be creative from there we're setting the bio and we're just doing this here so that we can continue to feed this back over and over that way if we have five revisions it'll still get passed every time the most recent version to the agent and also the most recent version when it's approved will get pushed up here to the Google doc then we have the evaluator agent what we told this agent to do is um evaluate the biography your job is to provide feedback we gave a criteria so make sure that it includes a quote from the person make sure it's light and humorous and make sure it has no emojis only need to output the feedback if the biography is finished and all criteria are met then all you need to output is finished so then we have a check to say okay does the output from the evaluator agent say finished or is it feedback if it's feedback it's going to go to the optimizer agent and continue on this loop until it says finished once it finally says finished as you can see we set JSON.output output which is the output from the evaluator agent equals finished when that happens it'll go up here and then we'll see it in our Google doc but then what we have in the actual optimizer agent is we're giving it the biography and this is where we're referencing the set field where we earlier right here where we set the bio this way the optimizer agent's always getting the most updated version of the bio and then we're also going to get the feedback so this is going to be the output from the evaluator agent because if it does go down this path the evaluator agent it means that it output feedback rather than saying finished so it's getting feedback it's getting the biography and then we're saying you're an expert reviser your job is to take the biography and optimize it based on the feedback so it gets all it needs in the user message and then it outputs us a better optimized version of that biography okay so let's do an example real quick um if you remember in the biography agent well all we have to do is give it a you know some information about a person to write a biography on so I'm going to come in here and I'm just going to say Jim 42 um lives by the ocean okay so that's all we're going to put in we'll see that it's writing a brief biography right now and then we're going to see it get evaluated we're going to see if it you know met those criteria if it doesn't it's going to get sent to the optimizer agent the optimizer agent is going to get um basically the criteria it needs to hit as well as the original biography so here's the evaluator agent look at that it decides that it wasn't good enough now it's being sent to the optimizer agent who is going to optimize the bio send it back and then hopefully on the second run it'll go up and get published in the docs if it's not good enough yet then it will come back to the agent and it will optimize it once again but I think that this agent will do a good job there we go we can see it just got pushed up into the doc so let's take a look at our Google doc here's a biography for Jim Thompson he lives in California he's 43 um ocean enthusiast passion adventure a profound respect for nature it talks about his early life and obviously he's making all this up talks about his education talks about his career talks about his personal life here we have a quote from Jim which is "I swear the fish are just as curious about me as I am about them." We've even got another quote um a few dad jokes along the way why did the fish blush because it saw the ocean's bottom so not sure I completely get that one oh no i get that one um anyways then hobbies philosophy legacy and a conclusion so this is you know a pretty optimized blog post it meets all the criteria that we had put into our agents as far as you know this is what you need to evaluate for it's very light there's no emojis threw some jokes in there and then it has some quotes from Jim as well so as you can see all we put in was Jim 43 lives by the ocean and we got a whole basically a story written about this guy and once again just like all of these frameworks pretty much you have the flexibility here to change out your model wherever you want so let's say we don't really mind up front we could use something really cheap and quick and then maybe for the actual optimizer agent we want to plug in something a little more um you know with reasoning aspect like deepse R1 potentially anyways that's all I've got for you guys today hope this one was helpful hope this one you know sparked some ideas for next time you're going into edit end to build an agentic workflow maybe looking at I could actually have structured my workflow in this framework and it would have been a little more efficient than the current way I'm doing it like I said these four templates will be in the free school community if you want to download them and just play around with them to understand what's going on understand you know when to use each framework stuff like that all right so we understand a lot of the components that actually go into building an effective agent or an effective agent system but we haven't really yet spent a lot of time on prompting which is like 80% of an agent it's so so important so in this next section we're going to talk about my methodology when it comes to prompting a tools agent and we're going to do a quick little live prompting session near the end so if that sounds good to you let's get started building AI agents and hooking up different tools is fun and all but the quality and consistency of the performance of your agents directly ties back to the quality of the system prompt that you put in there anyways today what we're going to be talking about is what actually goes into creating an effective prompt so that your agents perform as you want them to i'm going to be going over the most important thing that I've learned while building out agents and prompting them that I don't think a lot of people are doing so let's not waste any time and get straight into this one all right so I've got a document here if you want to download this one to follow along or just have it for later you can do so by joining my free school community the link for that's down in the description you'll just click on YouTube resources and find the post associated with this video and you'll be able to download the PDF right there anyways what we're looking at today is how we can master reactive prompting for AI agents in NAD and the objective of this document here is to understand what prompting is why it matters develop a structured approach to reactive prompting when building out AI agents and then learn about the essential prompt components so let's get straight into it and start off with just a brief introduction what is prompting make sure you stick around for this one because once we get through this doc we're going to hop into NN and do some live prompting examples so within our agents we're giving them a system prompt and this is basically just coding them on how to act but don't be scared of the word code because we're just using natural language instead of something like Python or JavaScript a good system prompt is going to ensure that your agent is behaving in a very clear very specific and a very repeatable way so instead of us programming some sort of Python agent what we're doing is we're just typing in "You're an email agent your job is to assist the user by using your tools to take the correct action." Exactly as if we were instructing an intern and why does prompting matter i'm sure by now you guys already have a good reason in your head of why prompting matters and it's pretty intuitive but let's think about it like this as well agents are meant to be running autonomously and they don't allow that back and forth interaction like chatbt now yes there can be some human in the loop within your sort of agentic workflows but ideally you put in an input it triggers the automation triggers the agent to do something and then we're getting an output unlike chatbt where you ask it to help you write an email and you can say "Hey make that shorter," or you can say "Make it more professional." We don't have that um luxury here we just need to trust that it's going to work consistently and high quality so our goal as prompters is to get the prompts right the first time so that the agent functions correctly every single time it's triggered so the key rule here is to keep the prompts clear simple and actionable you don't want to leave any room for misinterpretation um and also less is more sometimes I'll see people just throw in a novel and that's just obviously going to be more expensive for you and also just more room to confuse the agent so less is more so now let's get into the biggest lesson that I've learned while prompting AI agents which is prompting needs to be done reactively i see way too many people doing this proactively throwing in a huge system message and then just testing things out this is just not the way to go so let's dive into what that actually means to be prompting reactively first of all what is proactive prompting this is just writing a long detailed prompt up front after you have all your tools configured and all of the sort of you know standard operating procedures configured and then you start testing it out the problem here is that you don't know all the possible edge cases and errors in advance and debugging is going to be a lot more difficult because if something breaks you don't know which part of the prompt is causing the issue you may try to fix something in there and then the issue originally you were having is fixed but now you cause a new issue and it's just going to be really messy as you continue to add more and more and you end up just confusing both yourself and the agent now reactive prompting on the other hand is just starting with absolutely nothing and adding a tool testing it out and then slowly adding sentence by sentence and as you've seen in some of my demos we're able to get like six tools hooked up have no prompt in there and the agent's still working pretty well at that point we're able to start adding more lines to make the system more robust but the benefits here of reactive prompting are pretty clear the first one is easier debugging you know exactly what broke the agent whether that's I added this sentence and then the automation broke all I have to do is take out that sentence or I added this tool and I didn't prompt the tool yet so that's what caused the automation to break so I'm just going to add a sentence in right here about the tool this is also going to lead to more efficient testing because you can see exactly what happens before you hard prompt in fixes and essentially you know I'll talk about hard prompting more later but essentially what it is is um you're basically seeing an error and then you're hard prompting in the error within the system prompt and saying "Hey like you just did this that was wrong don't do that again." And we can only do that reactively because we don't know how the agent's going to react before we test it out finally we have the benefit that it prevents over complicated prompts that are hard to modify later if you have a whole novel in there and you're getting errors you're not going to know where to start you're going to be overwhelmed so taking it step by step starting with nothing and adding on things slowly is the way to go and so if it still isn't clicking yet let's look at a real world example let's say you're teaching a kid to ride a bike if you took a proactive approach you'd be trying to correct the child's behavior before you know what he or she is going to do so if you're telling the kid to keep your back straight lean forward you know don't tilt a certain way that's going to be confusing because now the kid is trying to adjust to all these things you've said and it doesn't even know what it was going to do what he or she was going to do in the in the beginning but if you're taking a reactive approach and obviously maybe this wasn't the best example cuz you don't want your kid to fall but you let them ride you see what they're doing you know if they're leaning too much to the left you're going to say "Okay well maybe you need to lean a little more to the right to center yourself up." um and only correct what they actually need to have corrected this is going to be more effective fewer unnecessary instructions and just more simple and less overwhelming so the moral of the story here is to start small observe errors and fix one problem at a time so let's take a look at some examples of reactive prompting that I've done in my ultimate assistant workflow as you can see right here I'm sure you guys have seen that video by now if you haven't I'll link it right up here but I did a ton of reactive prompting in here because I have one main agent calling four different agents and then within those sub agents they all have different tools that they need to call so this was very very reactive when I was prompting this workflow or this system of agents i started with no persistent prompt at all i just connected a tool and I tested it out to see what happened so an an example would be I hooked up an email agent but I didn't give it in any instructions and I running the AI to see if it will call the tool automatically a lot of times it will and then it only comes to when you add another different agent that you need to prompt in hey these are the two agents you have here's when to use each one so anyways adding prompts based on errors here I have my system prompts so if you guys want to pause it and read through you can take a look but you can see it's very very simple i've got one example i've got basically one brief rule and then I just have all the tools it has and when to use them and it's very very concise and not overwhelming and so what I want you guys to pay attention to real quick is in the overview right here i said you know you're the ultimate personal assistant your job is to send the user's query to the correct tool that's all I had at first and then I was getting this error where I was saying "Hey write an email to Bob." And what was happening is it wasn't sending that query to the email tool which is supposed to do it itself was trying to write an email even though it has no tool to write an email so then I reactively came in here and said "You should never be writing emails or creating event summaries you just need to call the correct tool." And that's not something I could have proactively put in there because I didn't really expect the agent to be doing that so I saw the error and then I basically hardcoded in what it should not be doing and what it should be doing so another cool example of hard coding stuff in is using examples you know we all understand that examples are going to help the agent understand what it needs to do based on certain inputs and how to use different tools and so right here you can see I added this example but we'll also look at it down here because I basically copied it in what happened was the AI failed in a very specific scenario so I added a concrete example where I gave it an input I showed the actions it should take and then I gave it the output so in this case what happened was I asked it to write an email to Bob and it tried to send an email or try it tried to hit the send email agent but it didn't actually have Bob's email address so the email didn't get sent so what I did here was I put in the input which was send an email to Bob asking him what time he wants to leave i then showed the two actions it needs to take the first one was use the contact agent to get Bob's email send this email address to the email agent tool and then the second action is use the email agent to send the email and then finally the output that we want the personal assistant to say back to the human is "The email has been sent to Bob anything else I can help you with?" The idea here is you don't need to put examples in there that are pretty intuitive and that the agent's going to get right already you only want to put in examples where you're noticing common themes of the agents failing to do this every time i may as well hardcode in this example input and output and tool calls so step four is to debug one error at a time always change one thing and one thing only at a time so you know exactly what you changed that broke the automation too too often I'll see people just get rid of an entire section and then start running things and now it's like okay well we're back at square one because we don't know exactly what happened so you want to get to the point where you're adding one sentence you're hitting run and it's either fixing it or it's not fixing it and then you know exactly what to do you know exactly what broke or fixed your automation and so one thing honestly I want to admit here is I created that system prompt generator on my free school community um and really the idea there was just to help you with the formatting because I don't really use that thing anymore because the fact that doing that is very proactive in the sense that we're dropping in a sort of a query into chat GBT the custom GPT I built it's giving us a system prompt and then we're putting that whole thing in the agent and then just running it and testing it and in that case you don't know exactly what you should change to fix little issues so just wanted to throw that out there i don't really use that system prompt generator anymore i now always like handcraft my prompts anyways from there what you want to do is scale up slowly so once you confirm that the agent is consistently working with its first tool and its first rule in its prompt then you can slowly add more tools and more prompt rules so here's an example you'll add a tool you'll add a sentence in the prompt about the tool test out a few scenarios if it's working well you can then add another tool and keep testing out and slowly adding pieces but if it's not then obviously you'll just hard prompt in the changes of what it's doing wrong and how to fix that from there you'll just test out a few more scenarios um and then you can just kind of rinse and repeat until you have all the functionality that you're looking for all right now let's look at the core components of an effective prompt each agent you design should follow a structured prompt to ensure clarity consistency and efficiency now there's a ton of different types of prompting you can do based on the role of agent ultimately they're going to fall under one of these three buckets which is toolbased prompting conversational prompting or like content creation type prompting and then categorization/ealuation prompting and the reason I wanted to highlight that is because obviously if we're creating like a content creation agent we're not going to say what tools it has if it has no tools but um yeah I just wanted to throw that out there and another thing to keep in mind is I really like using markdown formatting for my prompts as you can see these examples we've got like different headers with pound signs and we're able to specify like different sections we can use bolded lists we can use numbered lists i've seen some people talk about using XML for prompting i'm not a huge fan of it because um as far as human readability I think markdown just makes a lot more sense so that's what I do anyways now let's talk about the main sections that I include in my prompts the first one is always a background so whether this is a role or a purpose or a context I typically call it something like an overview but anyways just giving it some sort of background that defines who the agent is what its overall goal is and this really sets the foundation of you know sort of identifying their persona their behavior and if you don't have the section the agent is kind of going to lack direction and it's going to generate really generic or unfocused outputs so set its role and this could be really simple you can kind of follow this template of you are a blank agent designed to do blank your goal is blank so you are a travel planning AI assistant that helps users plan their vacations your goal is to pro provide detailed personalized travel itineraries based on the user's input then we have tools this is obviously super super important when we're doing sort of non-deterministic agent workflows where they're going to have a bunch of different tools and they have to use their brain their chat model to understand which tool does what and when to use each one so this section tells the agent what tools it has access to and when to use them it ensures the AI selects the right tool for the right task and a well structured tools section prevents confusion and obviously makes AI more efficient so here's an example of what it could look like we have like the markdown header of tools and then we have like a numbered list we're also showing that the tools are in bold this doesn't have to be the way you do it but sometimes I like to show them in bold um and it's you can see it's really simple it's it's not too much it's not overwhelming it's not too um you know it's just very clear google search use this tool when the user asks for real-time information email sender use this tool when the user wants to send a message super simple and what else you can do is you can define when to use each tool so right here we say we have a contact database use this tool to get contact information you must use this before using the email generator tool because otherwise it won't know who to send the email to so you can actually define these little rules keep it very clear within the actual tool layer of the prompt and then we have instructions i usually call them rules as you can see um you could maybe even call it like a standard operating procedure but what this does it outlines specific rules for the agent to follow it dictates the order of operations at a high level just keep in mind you don't want to say do this in this order every time because then it's like why are you even using an agent the whole point of an agent is that it's you know it's taking an input and something happens in this black box where it's calling different tools it may call this one twice it may call this one three times it may call them none at all um the idea is that it's variable it's not deterministic so if you're saying do it and this every time then you should just be using a sequential workflow it shouldn't even be an agent but obviously the rules section helps prevent misunderstandings so here's like a high level instruction right you're greeting the user politely if the user provides incomplete information you ask follow-up questions use the available tools only when necessary structure your response in clear concise sentences so this isn't saying like you do this in this order every time it's just saying when this happens do this if this happens do that so here's an example for AI task manager when a task is added you confirm with the user if a deadline is missing ask the user to specify one if a task priority is high send a notification store all tasks in the task management system so it's very clear too um we don't need all these extra filler words because remember the AI can understand what you're saying as long as it has like the actual context words that have meaning you don't need all these little fillers um you don't need these long sentences so moving on to examples which you know sample inputs and outputs and also actions within those between the inputs and outputs but this helps the AI understand expectations by showing real examples and these are the things that I love to hard code in there hard prompt in there because like I said there's no point in showing an example if the AI was already going to get that input and output right every time you just want to see what it's messing up on and then put an example in and show it how to fix itself so more clear guidance and it's going to give you more accurate and consistent outputs here's an example where we get the input that says can you generate a trip plan for Paris for 5 days the action you're going to take is first call the trip planner tool to get X Y and Z then you're going to take another action which is calling the email tool to send the itinerary and then finally the output should look something like this here's a 5-day Paris itinerary day 1 day 2 day 3 day 4 day 5 and then I typically end my prompts with like a final notes or important reminders section which just has like some miscellaneous but important reminders it could be current date and time it could be rate limits it could be um something as simple as like don't put any emojis in the output um and sometimes why I do this is because something can get lost within your prompt and sometimes like I I've thrown the today's date up top but then it only actually realizes it when it's in the bottom so playing around with the actual like location of your things can be sometimes help it out um and so having a final notes section at the bottom not with too many notes but just some quick things to remember like always format responses as markdown here's today's date if unsure about an answer say I don't have that information so just little miscellaneous things like that now I wanted to quickly talk about some honorable mentions because like I said earlier the prompt sections and components varies based on the actual type of agent you're building so in the case of like a content creator agent that has no tools um you wouldn't give it a tool section but you may want to give it an output section so here's an output section that I had recently done for my voice travel agent um which if you want to see that video I'll drop a link right here but what I did was I just basically included rules for the output because the output was very specific with HTML format and it had to be very structured and I wanted horizontal lines so I created a whole section dedicated towards output format as you can see and because I used three pound signs for these subsections the agent was able to understand that all this rolled up into the format of the output section right here so anyways I said the email should be structured as HTML that will be sent through email use headers to separate each section add a horizontal line to each section um I said what it what should be in the subject i said what should be in the introduction section i said how you should list these departure dates return dates flights for the flight section um here's something where I basically gave it like the HTML image tag and I showed how to put the image in there i showed to make I said like make a inline image rather than um an attachment i said to have each resort with a clickable link i also was able to adjust the actual width percentage of the image by specifying that here in the prompt um so yeah this was just getting really detailed about the way we want the actual format to be structured you can see here we have activities that I actually misspelled in my agent but it didn't matter um and then finally just a sign off and then just some final additional honorable mentions something like memory and context management um some reasoning some error handling but typically I think that these can be just kind of one or two sentences that can usually go in like the rules or instructions section but it depends on the use case like I said so if it needs to be pretty robust then creating an individual section at the bottom called memory or error handling could be worth it it just depends on like I said the actual use case and the goal of the agent okay cool so now that we've got through that document let's hop into Nitn and we'll just do some really quick examples of some reactive live prompting okay so I'm going to hit tab i'm going to type in AI agent we're going to grab one and we're going to be communicating with it through this connected chat trigger node now I'm going to add a chat model real quick just so we can get set up up and running we have our 40 Mini we're good to go and just a reminder there is zero assistant prompt in here all it is is that you are a helpful assistant so what's the first thing to do is we want to add a tool test it out so I'm going to add a um Google calendar tool i'm just going to obviously select my calendar to pull from i'm going to you know fill in those parameters using the model by clicking that button and I'm just going to say this one's called create event so we have create event and so now we're going to do our test and see if the tool is working properly i'm going to say create an event for tonight at 700 p.m so send this off we should see the agents able to understand to use this create event tool because it's using an automatic description but now we see an issue it created the start time for October 12th 2023 and the end time for also October 12th 2023 so this is our first instance of reactive prompting it's calling the tool correctly so we don't really need to prompt in like the actual tool name yet um it's probably best practice just to just to do so but first I'm just going to give an overview and say you are a calendar actually no i'm just going to say you are a helpful assistant because that's all it is right now and we don't know what else we're adding into this guy but now we'll just say tools is create event just so it's aware use this to create an event and then we want to say final notes um here is the current date and time because that's where it messed up is because it didn't know the current date and time even though it was able to call the correct tool so now we'll just send this same thing off again and that should have fixed it we reactively fixed the error and um we're just making sure that it is working as it should now okay there we go it just hit the tool and it says the event has been created for tonight at 7 p.m and if I click into my calendar you can see right there we have the event that was just created so cool now that's working what we're going to do now is add another tool so we'll drag this one over here and let's say we want to do a send email tool we're going to send a message we're going to change the name to send email and just so you guys are aware like how it's able to know right here tool description we're setting automatically if we set manually we would just say you know use this tool to send an email but we can just keep it simple leave it as set automatic i'm going to turn on to subject and message as defined by the model and that's going to be it so now we just want to test this thing again before we add any prompts we'll say send an email to bobacample.com asking what's up we'll send this off hopefully it's hitting the right tool so we should see there we go it hit the send email tool and the email got sent we can come in here and check everything was sent correctly although what we noticed is it's signing off as best placeholder your name and we don't want to do that so let's come in here and let's add a tool section for this tool and we'll tell it how to how to act so send email that's another tool it has and we're going to say use this to send an email then we're going to say sign off emails as Frank okay so that's reactively fixing an error we saw i'm just now going to send off that same query we already know that it knows how to call the tool so it's going to do that once again there we go we see the email was sent and now we have a sign off as Frank so that's two problems we've seen and then we've added one super short line into the system prompt and fixed those problems now let's do something else let's say in Gmail we want to be able to label an email and in order to label an email as you can see add label to a message we need a message ID and we need a label name or an ID for that label and this is we could choose from a list but more realistically we want the label ID to be pulled in dynamically so if we need to get these two things what we have to do is first get emails and also get labels so first I'm going to do get many i'm going to say this is using you know we're we're calling this tool get get emails and then we don't want to return all we want to do a limit and we also want to choose from a sender so we'll have this also be dynamically chosen so cool we don't have a system prompt in here about this tool but we're just going to say get my last email from Nate Herkman so we'll send that off it should be hitting the get emails tool filling in Nate Herkman as the sender and now we can see that we just got this email with a subject hello we have the message ID right here so that's perfect and now what we need to do is we need to create a tool to get the label ID so I'm going to come in here and I'm going to say um get many and we're going to go to label we're going to do um actually we'll just return all that works there's not too many labels in there um and we have to name this tool of course so we're going to call this get labels so once again there's no tools in or no prompt in here about these two tools at all and we're gonna say get my email labels we'll see if it hits the right tool there we go it did and it is going to basically just tell us you know here they are so here are our different labels um and here are the ones that we created so promotion customer support high priority finance and billing cool so now we can try to actually label an email so that email that we just got from um from Nate Hkelman that said hello let's try to label that one so I'm going to add another Gmail tool and this one's going to be add a label to a message and we need the message ID and the label ID so I'm just going to fill these in with the model parameter and I'm going to call this tool add label so there's no prompting for these three tools right here but we're going to try it out anyway and see what happens so add a promotion label to my last email from Nate Herklman send that off see what happens it's getting emails it tried to add a label before so now we're kind of We got in that weird loop as you can see it tried to add a label before it got labels so it didn't know what to do right um we'll click into here we'll see that I don't really exactly know what happened category promotions looking in my inbox anything sent from Nate Hkelman we have the email right here but it wasn't accurately labeled so let's go back into our agent and prompt this thing a little bit better to understand how to use these tools so I'm going to basically go into the tools section here and I'm going to tell it about some more tools that it has so get emails right this one was it was already working properly and we're just saying use this to get emails now we have to add get labels we're just saying use this to get labels um and we know that we want it to use this before actually trying to add a label but we're not going to add that yet we're going to see if it can work with a more minimalistic prompt and then finally I'm going to say add labels and this one is use this tool to add a label to an email okay so now that we just have very basic tool descriptions in here we don't actually say like when to use it or how so I'm going to try this exact same thing again add a promotion label to my last email from Nate HKman once again it tried to use ad label before and it tried to just call it twice as you can see so not working so back in email I just refreshed and you can see the email is still not labeled correctly so let's do some more reactive prompting what we're going to do now is just say in order to add labels so in the description of the ad label tool I'm going to say you must first use get emails to get the message ID and actually I want to make sure that it knows that this is a tool so what I'm going to do is I'm going to put it in in a quote and I'm going to make it the exact same capitalization as we defined over here so you must first use get emails to get the message ID of the email to label then you must use get labels to get the label ID of the email to label okay so we added in this one line so if it's still not working we know that this line wasn't enough i'm going to hit save and I'm going to try the exact same thing again add a promotion label to my last email so it's getting now it's getting labels and now it still had an error with adding labels so we'll take a look in here um it said that it did it successfully but obviously didn't it filled in label 127 blah blah blah so I think the message ID is correct but the label ID is not so what I'm going to try now is reactively prompting in here i'm going to say the label ID of the email to label we'll try that we'll see if that fixes it it may not we'll have to keep going so now we'll see it's going to at least it fixed the order right so it's getting emails and getting labels first and now look at that we successfully got a labeled email as you can see we have our um maybe we didn't we'll have to go into Gmail and actually check okay never mind we did as you can see we got the promotion email for this one from Nate Hookman that says hello and um yeah that's just going to be a really cool simple example of how we sort of take on the process of running into errors adding lines and being able to know exactly what caused what so I know the video was kind of simple and I went through it pretty fast but I think that it's going to be a good lesson to look back on as far as the mindset you have and approaching reactively prompting and adding different tools and testing things because at the end of the day building agents is a super super testheavy iterative you know refining process of build test change build test change all that kind of stuff all right so these next sections are a little bit more miscellaneous but cool little tips that you can play around with with your AI agents we're going to be talking about output parsing human in the loop error workflows and having an agent have a dynamic brain so let's get into it all right so output parsing let's talk about what it actually means and why you need to use it so just to show you guys what we're working with I'm just going to come in here real quick and ask our agent to create an email for us and when it does this the idea is that it's going to create a subject and a body so that we could drag this into a Gmail node so actually before I ask it to do that let's just say we're we're dragging in a Gmail node and we want to have this guy send an email we're if I can find this node which is right up here okay send a message now what you can see is that we have different fields that we need to configure the two the subject and the message so ideally when we're asking the agent to create an email it will be able to output those three different things so let me just show an example of that please send an email to nateample.com asking what's up we need the to the subject and the email okay so ideally we wouldn't say that every time because um we would have that in the system prompt the issue is this workflow doesn't let you run if the node is errored and it's errored because we didn't fill out stuff so I'm just going to resend this message but let me show you guys exactly why we need to use an output parser so it outputs the two to the subject and the message and if we actually click into it though the issue is that it comes through all in one single you know item called output and so you can see we have the two the subject and the message and now if I went into here to actually map these variables I couldn't have them separated or I would need to separate them in another step because I want to drag in the dynamic variable but I can only reference all of it at once so that's not good that's not what we want that's why we need to connect an output parser so I'm going to click into here and right here there's an option that says require specific output format and I'm going to turn that on what that does is it just gave us another option to our AI agent so typically we basically right here have chat model memory and tool but now we have another one called output parser so this is awesome i'm going to click onto the output parser and you can see that we have basically three options 99.9% of the time you are just going to be using a structured output parser which means you're able to give your agent basically a defined JSON schema and it will always output stuff in that schema if you need to have it kind of be a little bit automatically fixed with AI like I said I almost never have to use this but that's what you would use the autofixing output parser for so if I click on the structured output parser what happens is right now we see a JSON example so if we were to talk to our agent and say hey can you um you know tell me some information about California it would output the state in one string item called state and then would also output an array of cities LA San Francisco San Diego so what we want to do is we want to quickly define to our AI agent how to output information and we know that we wanted to output based on this node we need a two we need a subject and we need a message so don't worry you're not going to have to write any JSON yourself i'm going to go to chatgbt and say "Help me write a JSON example for a structured output parser in NADN i need the AI agent to output a two field a subject field and a body field." We'll just go ahead and send this off and as you guys know all LLMs are trained really well on JSON it's going to know exactly what I'm asking for here and all I'm going to have to do is copy this and paste that in so once this finishes up it's very simple two subject body and it's being a little extra right now and giving me a whole example body but I just have to copy that i have to go into here and just replace that JSON example super simple and now hopefully I don't even have to prompt this guy at all and we'll give it a try but if it's not working what we would do is we would prompt in here and say "Hey here is basically how we want you to output stuff here's your job." All that kind of stuff right but let me just resend this message we'll take a look we'll see that it called its output parser because this is green and now let's activate the Gmail node and click in perfect so what we see on this left hand side now is we have a two we have a subject and we have a body which makes this so much easier to actually map out over here and drag in so in different agents in this course you're going to see me using different structured output parsers whether that is to get to subject and body whether that is to create different stories stuff like that let me just show one more quick example of like a different way you could use this i'm going to delete this if I can actually delete it and we are going to just change up the structure output parser so let's say we want an AI agent to create a story for us so I'm going to just talk to this guy again help me write a different JSON example where I want to have the agent output a title of the story an array of characters and then three different scenes okay so we'll send that off and see what it does and just keep in mind it's creating this JSON basically a template that's telling your agent how to output information so we would basically say "Hey create me a story about um a forest." And it would output a title three characters and three different scenes as you can see here so we'll copy this we'll paste this into here and once again I'm not even going to prompt the agent and let's see how it does please create me a story about an airplane okay we'll go ahead and take a look at what this is going to do this one's going to spin a little bit longer oh wow didn't even take too long so it called the structured output parser and now let's click into the agent and see how it output perfect so we have the title is the adventure of Skyward the airplane we have four characters Skyward Captain Jane Navigator Max and ground engineer Leo and then you can see we have four different scenes that each come with a scene number and a description so if we wanted to we could have this be like you know maybe we want an image prompt for each of these scenes so we can feed that into an image generation model and we would just have to go into that chatbt and say "Hey for each scene add another field called image prompt." And it would just basically take care of it so just wanted to show you how this works how easy it is to set up these different JSON structured output parsers and why it's actually valuable to do within so hopefully that opened your eyes a little bit appreciate your time okay our workflow is actively listening for us in Telegram and I'm going to ask it to make an expost about coffee at night so as you can see this first agent is going to search the internet using Tavi and create that initial X post for us now we just got a message back in our Telegram that says "Hey is this post good to go?" Drinking coffee at night can disrupt your sleep since caffeine stays in your system for hours often leading to poorer sleep quality so what I'm going to do is click on respond and this gives us the ability to give our agent feedback on the post that it initially created so here is that response window and I'm going to provide some feedback so I'm telling the agent to add at the end of the tweet unless it's decaf and as soon as I hit submit we're going to see this go down the path it's going to get classified as a denial message and now the revision agent just made those changes and we have another message in our telegram with a new X post so now as you can see we have a new post i'm going to click on respond and open up that window and what we can see here is now we have the changes made that we requested at the end it says unless it's decaf so now all we have to do is respond good to go and as soon as we submit this it's going to go up down the approval route and it's going to get submitted and posted to X so here we go let's see that in action i'll hit submit and then we're going to watch it get posted onto X and let's go check and make sure it's there so here's my beautiful X profile and as you can see I was playing around with some tweets earlier but right here we can see drinking coffee at night can disrupt your sleep we have the most recent version because it says unless it's decaf and then we can also click into the actual blog that Tavi found to pull this information from so now that we've seen this workflow in action let's break it down so the secret that we're going to be talking about today is the aspect of human in the loop which basically just means somewhere along the process of the workflow in this case it's happening right here the workflow is going to pause and wait for some sort of feedback from us that way we know before anything is sent out to a client or posted on social media we've basically said that we 100% agree that this is good to go and if the initial message is not good to go we have the ability to have this unlimited revision loop where it's going to revise the output over and over until we finally agree that it's good to go so we have everything color coded and we're going to break it down as simple as possible but before we do that here I just wanted to do a real quick walkthrough of a more simple human in the loop because what's going on up here is it's just going to say "Do you like this?" Yes or no compared to down here where we actually give textbased feedback so we'll break them both down but let's start up here real quick and by the way if you want to download the template for free and play around with either of these flows you can get that in my free school community the link for that will be down in the description and when it comes to human in the loop in Naden if you click on the plus you can see down here human in the loop wait for approval or human input before continuing you click on it you can see there's a few options and they all just use the operation called send and wait for response so obviously there's all these different integrations and I'm sure more will even start to roll out but in this example we're just using Telegram okay so taking a look at this more simple workflow we're going to send off the message make an expost about AI voice agents what's happening is the exact same thing as the demo where this agent is going to search the web and then it's going to create that initial content for us and now we've hit that human in the loop step as you can see it's spinning here purple because it's waiting for our approval so in our Telegram we see the post it asks us if this is good to go and let's just say that we don't like this one and we're going to hit decline so when I hit decline it goes down this decision point where it basically says you know did the human approve yes or no if yes we'll post it to X if no it's going to send us a denial message which basically just says post was denied please submit another request and so that's really cool because it gives us the ability to say okay do we like this yes and it will get posted otherwise just do nothing with it but what if we actually want to give it feedback so that it can take this post we can give it a little bit of criticism and then it will make another one for us and it just stays in that loop rather than having to start from square one so that's exactly what I did down here with the human and loop 2.0 know where we're able to give textbased feedback instead of just saying yes or no so now we're going to break down what's going on within every single step here so what I'm going to do is I'm going to click on executions i'm going to go to the one that we did in the live demo and bring that into the workflow so we can look at it so what we're going to do is just do another live run and walk through step by step the actual process of this workflow so I'm going to hit test workflow i'm going to pull up Telegram and then I'm going to ask it to make us an expost okay so I'm about to fire off make me an expost about crocodiles so sent that off this expost agent is using its GPT41 model as well as Tavly search to do research create that post and now we have the human in the loop waiting for us so before we go look at that let's break down what's going on up front so the first phase is the initial content this means that we have a telegram trigger and that's how we're communicating with this workflow and then it gets fed into the first agent here which is the expost agent let's click into the expost agent and just kind of break down what's going on here here so the first thing to notice is that we're looking for some sort of prompt the agent needs some sort of user message that it's going to look at in this case we're not doing the connected chat trigger node we're looking within our Telegram node because that's where the text is actually coming through so on this lefth hand side we can see all I basically did was right here is the text that we typed in make me an expost about crocodiles and all I did was I dragged this right into here as the user message and that is what the agent is actually looking at in order to take action and then the other thing we did was gave the agent a system message which basically defines its behavior and so here's what we have the overview is you are an AI agent responsible for creating expost based on a user's request your instructions are to always use the Tavly search tool to find accurate information write an informative engaging tweet include a brief reference to the source directly in the tweet and only output the tweet we listed its tool which it only has one called tavly search and we told it to use this for real-time web search and then just gave it an example basically saying okay here's an input you may get here's the action you will take and then here's the output that we want you to output and then we just gave them final notes and I know I may be read through this pretty quick but keep in mind you can download the template for free and the prompt will be in there and then what you could do is you can click on the logs for an agent and you can basically look at its behavior so we can see that it used its chat model GBT4.1 read through the system prompt decided said "Okay I need to go use tably search." So here's how it searched for crocodile information and then it used its model again to actually create that short tweet right here and then we'll just take a quick look at what's going on within the actual Tavi search tool here so if you download this template all you'll have to do is plug in your own credential everything else should be set up for you but let me just break it down real quick so if you go to tavly.com and create an account you can get a,000 free searches per month so that's the kind of plan I'm on but anyways here is the documentation you can see right here we have the Tavi search endpoint which is right here all we have to do is authorize ourselves so we'll have an authorization as a header parameter and then we'll do bearer space our API token so that's how you'll set up your own credential and then all I did was I copied this data field into the HTTP request and this is where you can do some configuration you can look through the docs to see how you want to make this request but all I wanted to do here was just change the search query so back in end you can see in my body request I I changed the query by using a placeholder right here it says use a placeholder for any data to be filled in by the model so I changed the query to a placeholder called search term and then down here I defined the search term placeholder as what the user is searching for so what this means is the agent is going to interpret our query that we sent in telegram it's then going to use this tavly tool and basically use its brain to figure out what should I search for and in this case on the lefth hand side you can see that it filled out the search term with latest news or facts about crocodiles and then we get back our response with information and a URL and then it uses all of this in order to actually create that post okay so here's where it may seem like it's going to get a little tricky but it's not too bad just bear with me and I wanted to do some color coding here so we could all sort of stay on the same page so what we're doing now is we're setting the post and this is super important because we need to be able to reference the post later in the workflow whether that's when we're actually sending it over to X or when we're making a revision and we need the revision agent to look at the original post as well as the feedback from the human so in the set node all we're doing is we're basically setting a field called post and we're dragging in a variable called JSON.output and this just means that it's going to be grabbing the output from this agent or the revision agent no matter what as you can see it's looped back into this set because if we're defining a variable using dollar sign JSON it means that we're going to be looking for whatever node immediately finished right before this one and so that's why we have to keep this one kind of flexible because we want to make sure that at the end of the day if we made five or six or seven revisions that only the most recent version will actually be posted on X so then we move into the human in the loop phase of this workflow and as you can see it's still spinning it's been spinning this whole time while we've been talking but it's waiting for our response so anyways it's a send and wait for a response operation as you can see right here the chat ID is coming from our Telegram trigger so if I scroll down in the Telegram trigger on the lefth hand side you can see that I have a chat ID right here and all I did was I dragged this in right here basically just meaning okay whoever communicates with this workflow we need to send and get feedback from that person so that's how we can make this dynamic and then I just made my message basically say hey is this good to go and then I'm dragging in the post that we set earlier so this is another reason why it's important is because we want to request feedback on the most recent version as well not the first one we made and then like I mentioned within all of these human in the loop nodes you have a few options so you can do free text which is what we're doing here earlier what we did was approval which is basically you can say hey is there an approve button is there an approve and a denial button how do you want to set that up but this is why we're doing free text because it allows for us to actually give feedback not just say yes or no cool so what we're going to do now is actually give our feedback so I'm going to come into here we have our post about crocodiles so I'm going to hit respond and it's going to open up this new page and so yes it's a little annoying that this form has to pop up in the browser rather than natively in Telegram or whatever you know Slack Gmail wherever you're doing the human in the loop but I'm sure that'll be a fix that'll come soon but it's just right now I think it's coming through a web hook so they just kind of have to do it like this anyways let's say that we want to provide some feedback and say make this shorter so I'm going to say make this shorter and as I submit it you're going to see it go to this decision point and then it's going to move either up or down and this is pretty clearly a denial message so we'll watch it get denied and go down to the revision agent as you can see and just like that that quickly we already have another one to look at so before we look at it and give feedback let's just look at what's actually going on within this decision point so in any automation you get to a point where you have to make a decision and what's really cool about AI automation is now we can use AI to make a decision that typically a computer couldn't because a typical decision would be like is this number greater than 10 or less than 10 but now it can read this text that we submitted make this shorter and it can say okay is this approved or declined and basically I just gave it some short definitions of like what an approval message might look like and what a denial message might look like and you can look through that if you download the template but as you can see here it pushed this message down the declined branch because we asked it to make a revision and so it goes down the denial branch which leads into the revision agent and this one's really really simple all we did here was we gave it two things as the user message we said here's the post to revise so as you can see it's this is the initial post that the first agent made for us and then here is the human feedback so it's going to look at this it's going to look at this and then it's going to make those changes because all we said in the system prompt was you're an expert Twitter writer your job is to take an incoming post and revise it based on the feedback that the human submitted and as you can see here is the output it made the tweet a lot shorter and that's the beauty of using the set node is because now we loop that back in the most recent version has been submitted to us for feedback so let's open that up real quick in our Telegram and now you can see that the shorter tweet has been submitted to us and it's asking for a response so at this point let's say we're good to go with this tweet i'm going to click respond open up this tab recent crocodile attacks in Indonesia highlight the need for caution in their habitats stay safe we've got a few emojis and I'm just going to say let's just say send it off because it can interpret multiple ways of saying like yes it's good to go so as soon as I hit submit we're going to watch it go through the decision point and then post on our X so you see that right here text classifier and now it has been posted to X and I just gave our X account a refresh you can see that we have that short tweet about recent crocodile attacks okay so now that we've seen another example of a live run through a little more detailed let me talk about why I made the color coding like this so the set note here its job is basically just I'm going to be grabbing the most recent version of the post because then I can feed it into the human in the loop i can then feed that into the revision if we need to make another revision because you want to be able to make revisions on top of revisions you don't want to be only making revisions on the first one otherwise you're going to be like what's the point and then also of course you want to post the most recent version not the original one because again what's the point so in here you can see there's two runs the first one was the first initial content creation and then the second one was the revised one similarly if we click into the next node which was request feedback the first time we said make this shorter and then the second time we said send it off and then if we go into the next node which was the text classifier we can see the first time it got denied because we said make this shorter and the second time it said send it off and it got approved and that's basically the flow of you know initial creation we're setting the most recent version we're getting feedback we're making a decision using AI and as you can tell for the text classifier I'm using 2.0 Flash rather than GPT 4.1 and then of course if it's approved it gets posted if it's not it makes revisions and like I said this is unlimited revisions and it's revisions on top of revisions so when it comes to Human in the Loop you can do it in more than just Telegram too so if you click on the plus you can see right here Human in the Loop wait for approval or human input before continuing we've got Discord Gmail Chat Outlook Telegram Slack we have a lot of stuff you can do however so far with my experience it's been limited to one workflow and what do I mean by that it's kind of tough to do this when you're actually giving an agent a tool that's supposed to be waiting for human approval so let me show you what I mean by that okay so here's an agent where I tried to do a human in the loop tool because we have the send and wait message operation as a tool for an agent so let me show you what goes on here we'll hit test workflow okay so I'm going to send off get approval for this message hey John just wanted to see if you had the meeting minutes and you're going to watch that it's going to call the get approval tool but here's the issue so it's waiting for a response right and we have the ability to respond but the waiting is happening at the agent level it really should be waiting down here for the tool because as you saw in the previous example the response from this should be the actual feedback from the human and we haven't submitted that yet and right now the response from this tool is literally just the message so what you'll see here is if I go back into Telegram and I click on respond and we open up this tab it basically just says no action required and if I go back into the workflow you can see it's still spinning here and there's no way for this to give another output so it just doesn't really work and so what I was thinking was okay why don't I just make another workflow where I just use the actual node like we saw on the previous one that should work fine because then it should just spin down here on the tool level until it's ready and so let me show you what happens if we do that okay so like I said I built a custom tool down here which is called get approval it would be sending the data to this workflow it would send off an approval message using the send and wait and it doesn't really work i even tried adding a wait here but what happens typically is when you use a workflow to call another one it's going to be waiting and looking in the last node of that workflow for the response but it doesn't yet work yet with these operations and I'll show you guys why and I'm sure NNN will fix this soon but it's just not there yet so I'm just going to send off the exact same query get approval for this message we'll see it call the tool and basically as you can see it finished up instantly and now it's waiting here and we already did get a message back in telegram which basically said ready to go hey John just wanted to see if you had the meeting minutes and it gives us the option to approve or deny and if we click into the subworkflow this one that it actually sent data to we can see that the execution is waiting so this workflow is properly working because it's waiting here for human approval but if we go back into the main flow it's waiting here at the agent level rather than waiting here so there's no way for the agent to actually get our live feedback and use that to take action how it needs to so I just wanted to show you guys that I had been experimenting with this as a tool it's not there yet but I'm sure it will be here soon and when it is you can bet that I'll have a video out about it today I'm going to be showing you guys how you can set up an error workflow in NAN so that you can log all of your errors as well as get notified every time one of your active workflows fails the cool part is all we have to do is set up one error workflow and then we can link that one to all of our different active workflows so I think you'll be pretty shocked how quick and easy this is to get set up so let's get into the video all right so here's the workflow that we're going to be using today as our test workflow that we're going to purposely make error and then we're going to capture those errors in a different one and feed that into a Google sheet template as well as some sort of Slack or email notification and if you haven't seen my recent video on using this new think tool in edit then I'll tag it right up here anyways in order for a workflow to trigger an error workflow it has to be active so first things first I'm going to make this workflow active there we go this one has been activated and now what I'm going to do is go back out to my NAD we're going to create a new workflow and this is going to be our error logger workflow okay so you guys are going to be pretty surprised by how simple this workflow is going to be i'm going to add a first step and I'm going to type an error and as you can see there's an error trigger which says triggers the workflow when another workflow has an error so we're going to bring this into the workflow we don't have to do anything to configure it you can see that what we could do is we could fetch a test event just to see what information could come back but what we're going to do is just trigger a live one because we're going to get a lot more information than what we're seeing right here so quickly pay attention to the fact that I named this workflow error logger i'm going to go back into my ultimate assistant active workflow up in the top right I'm going to click on these three dots go down to settings and then right here there's a setting called error workflow which as you can see a second workflow to run if the current one fails the second workflow should always start with an error trigger and as you saw we just set that up so all I have to do is choose a workflow i'm going to type an error and we called it error logger so I'm going to choose that one hit save and now these two workflows are basically linked so that if this workflow ever has an error that stops the workflow it's going to be captured in our second one over here with the information so let's see a quick example of that okay so this workflow is active it has a telegram trigger as you can see so I'm going to drag in my telegram and I'm just going to say "Hey." And what's going to happen is obviously we're going to get a response back because this workflow is active and it says "How can I assist you today?" Now what I'm going to do is I'm just going to get rid of the chat model so this agent essentially has no brain i'm going to hit save we're going to open up Telegram again and we're going to say "Hey." And now we should see that we're not going to get any response back in Telegram if we go into the executions of this ultimate assistant you can see that we just got an error right now and that was when we just sent off the query that said "Hey," and it errored because the chat model wasn't connected so if we hop into our error logger workflow and click on the executions we should see that we just had a new execution and if we click into it we'll see all the information that came through so what it's going to tell us is the ID of the execution the URL of the workflow the name of the workflow and then we'll also see what node errored and the error message so here under the object node we can see different parameters we can see what's kind of how the node's configured we can see the prompt even but what we're interested in is down here we have the name which is ultimate assistant and then we have the message which was a chat model sub node must be connected and enabled so anyways we have our sample data i'm going to hit copy to editor which just brings in that execution into here so we can play with it and now what I want to do is map up the logic of first of all logging it in a Google sheet so here's the Google sheet template I'm going to be using we're going to be putting in a timestamp a workflow name the URL of the workflow the node that errored and the error message if you guys want to get this template you can do so by joining my free school community the link for that's down in the description once you join the community all you have to do is search for the title of the video up top or you can click on YouTube resources and you'll find the post and then in the post is where you'll see the link to the Google sheet template anyways now that we have this set up all we have to do is go back into our error logger we're going to add a new node after the trigger and I'm going to grab a sheets node what we want to do is append a row in sheets um I'm just going to call this log error make sure I choose the right credential and then I'm going to choose the sheet which is called error logs and so now we can see we have the values we need to send over to these different columns so for time stamp all I'm going to do is I'm actually going to make an expression and I'm just going to do dollar sign now and this is basically just going to send over to Google Sheets the current time whenever this workflow gets triggered and if you don't like the way this is coming through you can play around with format after dollar sign now and then you'll be able to configure it a little bit more and you can also ask chat to help you out with this JavaScript function and feel free to copy this if you want i'm pulling in the full year month day and then the time okay cool then we're just pretty much going to drag and drop the other information we need so the first thing is the workflow name and to get to that I'm going to close out of the execution and then we'll see the workflow and we can pull in the name right there which is ultimate personal assistant for the URL I'm going to open back up execution and grab the URL from here for node all I have to do is look within the node object we're going to scroll down until we see the name of the node which is right here the ultimate assistant and then finally the error message which should be right under that name right here drag that in which says a chat model sub node must be connected and enabled so now that we're good to go here I'm going to test step and then we'll check our Google sheet and make sure that that stuff comes through correctly and as you can see it just got populated and we have the URL right here which if we clicked into it would take us to that main ultimate personal assistant workflow as you can see when this loads up and it takes us to the execution that actually failed as well so we could sort of debug so now we have an error trigger that will update a Google sheet and log the information but maybe we also want to get notified when there's an error so I'm just going to drag this off right below and I'm going to grab the Slack node and I'm going to choose to send a message right here and then we'll just configure what we want to send over okay so we're going to be sending a message to a channel i'm going to choose the channel all awesome AI stuff and then we just need to configure what the actual message is going to say so I'm going to change this to an expression make this full screen and let's fill this out so pretty much just customize this however you want let's say I want to start off with workflow error and we will put the name of the workflow so I'll just close out of here throw that in there so now it's going to come through saying workflow error ultimate personal assistant and then I'm going to say like what node errored at what time and what the error message was so first let's grab the name of the node um if I just have to scroll down to name right here so ultimate assistant errored at and I'm going to do that same dollar sign now function so it says ultimate assistant errored at 2025417 and then I'm just going to go down and say the error message was and we're just going to drag in the error message there we go and then finally we'll just provide a link to the workflow so see this execution here and then we'll drag in the link which is all the way up top and we should be good to go and then if you want to make sure you're not sending over a little message at the bottom that says this was sent from Nad you're going to add an option you're going to click on include link to workflow and then you're going to turn that off and now we hit test up and we hop into Slack and we can see we got workflow error ultimate personal assistant we have all this information we can click into this link and we don't have this little message here that says automated with this NN workflow so maybe you could just set up a channel dedicated towards error logging whatever it is okay so let's save this real quick and um let's just do another sort of like example um one thing to keep in mind is there's a difference between the workflow actually erroring out and going red and just something not working correctly and I'll show you exactly what I meant by that so this example actually triggered the error workflow because the execution on this side is red and it shows an error but what happens is for example with our Tavly tool right here I have no authentication pulled up so this tool is not going to work but if I come into Telegram and say search the web for Apples it's going to work this this workflow is going to go green even though this tool is not going to work and we'll see exactly why so as you can see it says I'm currently unable to search the web due to a connection error so if we go into the execution we can see that this thing went green even though it didn't work the way we wanted to but what happened is the tool came back and it was green and it basically just didn't work because our authentication wasn't correct and then you can even see in the think node it basically said the web search function is encountering an authentication error i need to let the user know the search isn't currently available and offer alternative ways to help blah blah blah but all of these nodes actually went green and we're fine so this example did not trigger the error logger as you can see if we check here there's nothing we check in Slack there's nothing so what we can do is we'll actually make something error so I'll go into this memory and it's going to be looking for a session ID within the telegram trigger and I'm just going to add an extra d so this variable is not going to work it's probably going to error out and now we'll actually see something happen with our error workflow so I'm just going to say hey and we will watch basically nothing will come back here okay that confused me but I realized I didn't save the workflow so now that we've saved it this is not going to work so let's once again say hey and we should see that nothing's going to come back over here um I believe if we go into our error logger we should see something pop through we just got that row and you can see the node changed the error message changed all that kind of stuff and then in Slack we got another workflow error at a new time and it was a different node and finally we can just come into our error logger workflow and click on executions and we'll see the newest run was the one that we just saw in our logs and in our Slack which was the memory node that aired as you can see right here simple memory and so really the question then becomes okay well what happens if this workflow in itself errors too i really don't foresee that happening unless you're doing some sort of crazy AI logic over here but it really needs to just be as simple as you're mapping variables from here somewhere else so you really shouldn't see any issues maybe an authentication issue but I don't know maybe if this if this workflow is erring for you a ton you probably are just doing something wrong anyways that's going to do it for this one i know it was a quicker one but hopefully if you didn't know about this it's something that you'll implement and it will be helpful if you've ever wondered which AI model to use for your agents and you're tired of wasting credits or overpaying for basic tasks then this video is for you because today I'm going to be showing you a system where the AI agent picks its brain dynamically based on the task this is not only going to save you money but it's going to boost performance and we're also getting full visibility into the models that it's choosing based on the input and we'll see the output that way all we have to do is come back over here update the prompt and continue to optimize the workflow over time as you can see we're talking to this agent in Slack so what I'm going to do is say "Hey tell me a joke." You can see my failed attempts over there and it's going to get this message as you can see it's picking a model and then it's going to answer us in Slack as well as log the output so we can see we just got the response why don't scientists trust Adams because they make up everything and if I go to our model log we can see we just got the input we got the output and then we got the model which was chosen which in this case was Google Gemini's 2.0 Flash and the reason it chose Flash is because this was a simple input with a very simple output and it wanted to choose a free model so we're not wasting credits for no reason all right let's try something else i'm going to ask it to create a calendar event at 1 p.m today for lunch once this workflow fires off it's going to choose the model as you can see it's sending that over to the dynamic agent to create that calendar event it's going to log that output and then send us a message in Slack so there we go i just have created the calendar event for lunch at 1 p.m today if you need anything else just let me know we click into the calendar real quick there is our launch event at one and if we go to our log we can see that this time it used OpenAI's GBT 4.1 mini all right we'll just do one more and then we'll break it down so I'm going to ask it to do some research on AI voice agents and create a blog post here we go it chose a model it's going to hit Tavi to do some web research it's going to create us a blog post log the output and send it to us in Slack so I'll check in when that's done all right so it just finished up and as you can see it called the Tavly tool four times so it did some in-depth research it logged the output and we just got our blog back in Slack as you can see wow it is pretty thorough it talks about AI voice agents the rise of voice agents um there's key trends like emotionally intelligent interactions advanced NLP real-time multilingual support all this kind of stuff um that's the whole blog right it ends with a conclusion and if you're wondering what model it used for this task let's go look at our log we can see that it ended up using Claude 3.7 sonnet and like I said it knew it had to do research so it hit the tabletly tool four different times the first time it searched for AI voice agents trends then it searched for case studies then it searched for growth statistics and then it searched for ethical considerations so it made us a pretty like holistic blog anyways now that you've seen a quick demo of how this works let's break down how I set this up so the first things first we're talking to it in Slack and we're getting a response back in Slack and as you can see if I scroll up here I had a a few fails at the beginning when I was setting up this trigger so if you're trying to get it set up in Slack um it can be a little bit frustrating but I have a video right up here where I walk through exactly how to do that anyways the key here is that we're using Open Router as the chat model so if you've never used Open Router it's basically a chat model that you can connect to and it basically will let you route to any model that you want so as you can see there's 300 plus models that you can access through Open Router so the idea here is that we have the first agent which is using a free model like Gemini 2.0 Flash we have this one choosing which model to use based on the input and then whatever this model chooses we're using down here dynamically for the second agent to actually use in order to use its tools or produce some sort of output for us and just so you can see what that looks like if I come in here you can see we're using a variable but if I got rid of that and we change this to fixed you can see that we have all of these models within our open router dynamic brain to choose from but what we do is instead of just choosing from one of these models we're basically just pulling the output from the model selector agent right into here and that's the one that it uses to process the next steps cool so let's first take a look at the model selector what happens in here is we're feeding in the actual text that we sent over in Slack so that's pretty simple we're just sending over the message and then in the system message here this is where we actually can configure the different models that the AI agent has access to so I said "You're an agent responsible for selecting the most suitable large language model to handle a given user request choose only one model from the list below based strictly on each model's strengths." So we told it to analyze the request and then return only the name of the model we gave it four models obviously you could give it more if you wanted to and down here available models and strengths we gave it four models and we basically defined what each one's good at you could give it more than four if you wanted to but just for this sake of the demo I only gave it four and then we basically said return only one of the following strings and as you can see in this example it returned anthropic claude 3.7 sonnet and so one quick thing to note here is when you use Gemini 2.0 flash for some reason it likes to output a new line after a lot of these strings so all I had to do later is I clean up this new line and I'll show you exactly what I mean by that but now we have the output of our model and then we move on to the actual Smartyp Pants agent so in this one we're giving it the same user message as the previous agent where we're just basically coming to our Slack trigger and we're dragging in the text from Slack and what I wanted to show you guys is that here we have a system message and all I gave it was the current date and time so I didn't tell it anything about using Tavi for web search i didn't tell it how to use its calendar tools this is just going to show you that it's choosing a model intelligent enough to understand the tools that it has and how to use them and then of course the actual dynamic brain part we looked at this a little bit but basically all I did is I pulled in the output of the previous agent the model selector agent and then like I said we had to just trim up the end because if you just dragged this in and Open Router was trying to reference a model that had a new line character after it it would basically just fail and say this model isn't available so I trimmed up the end and that's why and you can see in my Open Router account if I go to my activity we can see which models we've used and how much they've costed so anyways Gemini 2.0 Flash is a free model but if we use it through open router they have to take a little bit of a you know they got to get some kickback there so it's not exactly free but it's really really cheap but the idea here is you know Claude 3.7 sonnet is more expensive and we don't need to use it all the time but if we want our agent to have the capability of using Claude at some point then we probably would just have to plug in Claude but now if you use this method if you want to talk to the agent just about some general things or looking up something on your calendar or sending an email you don't have to use Claude and waste these credits you could go ahead and use a free model like 2.0 Flash or still a very powerful cheap model like GPT 4.1 Mini and that's not to say that 2.0 Flash isn't super powerful it's just more of a lightweight model it's very cheap anyways that's just another cool thing about Open Router that's why I've gotten in the habit of using it because we can see the tokens the cost and the breakdown of different models we've used from there we're feeding the output into a Google sheet template which by the way you can download this workflow as well as these other ones down here that we'll look at in a sec you can download all this for free by joining my Free School community all you have to do is go to YouTube resources or search for the title of this video and when you click on the post associated with this video you'll have the JSON which is the end workflow to download as well as you'll see this Google sheet template somewhere in that post so that you can just basically copy it over and then you can plug everything into your environment anyways just logging the output of course and we're sending over a timestamp so I just said you know whatever time this actually runs you're going to send that over the input so the Slack message that triggered this workflow the output I'm basically just bringing the output from the Smartyp Pants agent right here and then the model is the output from the model selector agent and then all that's left to do is send the response back to the human in Slack where we connected to that same channel and we're just sending the output from the agent so hopefully this is just going to open your eyes to how you can set up a system so that your actual main agent is dynamically picking a brain to optimize your cost and performance and in a space like AI where new models are coming out all the time it's important to be able to test out different ones for their outputs and see like what's going on here but also to be able to compare them so two quick tools I'll show you guys this first one is Vellum which is an LLM leaderboard you can look at like reasoning math coding tool use you have all this stuff you can compare models right here where you can select them and look at their differences and then also down here is model comparison with um all these different statistics you can look at you can look at context window cost and speed so this is a good website to look at but just keep in mind it may not always be completely up to date right here it was updated on April 17th and today is the 30th so doesn't have like the 4.1 models anyways another one you could look at is this LM Arena so I'll leave the link for this one also down in the description you can basically compare different models by chatting with them like side by side or direct people give ratings and then you can look at the leaderboard for like an overview or for text or for vision or for whatever it is just another good tool to sort of compare some models anyways we'll just do one more quick before we go on to the example down below um because we haven't used the reasoning model yet and those are obviously more expensive so I'm asking you a riddle i said you have three boxes one has apples one has only oranges and one has a mix of both they're all incorrectly labeled and you can pick one fruit from the box without looking how can you label all boxes correctly so let's see what it does hopefully it's using the reasoning model okay so it responded with a succinct way to see it is to pick one piece of fruit from the box labeled apples and oranges since that label is wrong the box must actually contain only apples or only oranges whatever fruit you draw tells you which single fruit box that really is once you know which box is purely apples or purely oranges you can use the fact that all labels are incorrect to deduce the proper labels for the remaining two boxes and obviously I had chatbt sort of give me that riddle and that's basically the answer it gave back so real quick let's go into our log and we'll see which model it used and it used OpenAI's 01 reasoning model and of course we can just verify that by looking right here and we can see it is OpenAI 01 so one thing I wanted to throw out there real quick is that Open Router does have sort of like an auto option you can see right here Open Router/auto but it's not going to give you as much control over which models you can choose from and it may not be as costefficient as being able to define here are the four models you have and here's when to use each one so just to show you guys like what that would do if I said "Hey," it's going to use its model and it's going to pick one based on the input and here you can see that it used GPT4 mini and then if I go ahead and send in that same riddle that I sent in earlier remember earlier it chose the reasoning model but now it's going to choose probably not the reasoning model so anyways looks like it got the riddle right and we can see that the model that it chose here was just GPT40 so I guess the argument is yes this is cheaper than using 01 so if you want to just test out your workflows by using the auto function go for it but if you do want more control over which models to use when to use each one and you want to get some higher outputs in certain scenarios then you want to take probably the more custom route anyways just thought I'd drop that in there but let's get back to the video all right so now that you've seen how this agent can choose between all those four models let's look at like a different type of example here okay so down here we have a rag agent and this is a really good use case in my mind because sometimes you're going to be chatting with a knowledge base and it could be a really simple query like can you just remind me what our shipping policy is or something like that but if you wanted to have like a comparison and like a deep lookup for something in the knowledge base you'd probably want more of a you know a more intelligent model so we're doing a very similar thing here right this agent is choosing the model with a free model and then it's going to feed in that selection to the dynamic brain for the rag agent to do its lookup and um what I did down here is I just put a very simple flow if you wanted to download a file into Superbase just so you can test out this Superbase rag agent up here but let's chat with this thing real quick okay so here is my policy and FAQ document right and then I have my Subbase table where I have these four vectors in the documents table so what we're going to do is query this agent for stuff that's in that policy and FAQ document and we're going to see which model it uses based on how complex the query is so if I go ahead and fire off what is our shipping policy we'll see that the model selector is going to choose a model send it over and now the agent is querying Superbase and it's going to respond with here's Tech Haven's shipping policy orders are processed within 1 to two days standard shipping takes 3 to seven business days blah blah blah and if we compare that with the actual documentation you can see that that is exactly what it should have responded with and you'll also notice that in this example we we're not logging the outputs just because I wanted to show a simple setup but we can see the model that it chose right here was GPT 4.1 mini and if we look in this actual agent you can see that we only gave it two options which was GPT 4.1 mini and anthropic cloud 3.5 sonnet just because of course I just wanted to show a simple example but you could up this to multiple models if you'd like and just to show that this is working dynamically I'm going to say what's the difference between our privacy policy and our payment policy and what happens if someone wants to cancel their order or return an item so we'll see hopefully it's choosing the cloud model because this is a little bit more complex um it just searched the vector database we'll see if it has to go back again or if it's writing an answer it looks like it's writing an answer right now and we'll see if this is accurate so privacy versus payment we have privacy focuses on data protection payment covers accepted payment methods um what happens if someone wants to cancel the order we have order cancellation can be cancelled within 12 hours and we have a refund policy as well and if we go in here we could validate that all this information is on here and we can see this is how you cancel and then this is how you refund oh yeah right here visit our returns and refund page and we'll see what it says is that here is our return and refund policy and all this information matches exactly what it says down here okay so those are the two flows I wanted to share with you guys today really I just hope that this is going to open your eyes to the fact that you can have models be dynamic based on the input which really in the long run will save you a lot of tokens for your different chat models all right so now we're going to move on to web hooks which I remember seemed really intimidating as well just like APIs and HTTP requests but they're really even simpler so we're going to dive into what exactly they are and show an example of how that works in NN and then I'm going to show you guys two workflows that are triggered by NAN web hooks and then we send data back to that web hook so don't worry you guys will see exactly what I'm talking about let's get into it okay web hooks so I remember when I first learned about APIs and HTTP requests and then I was like what in the world is a web hook they're pretty much the same thing except for think about it like this the web hook rather than us sending off data somewhere or like sending off an API call we are the one that's waiting for an API call we're just waiting and listening for data so let me show you an example of what that actually looks like so here you can see we have a web hook trigger and a web hook is always going to come in the form of a trigger because essentially our end workflow is waiting for data to be sent to it whether that's like a form is submitted and now the web hook gets it or whatever that is we are waiting for the data here so when I click into the web hook what we see is we have a URL and this is basically the URL that wherever we're sending data from is going to send data to so later in this course I'm going to show you an example where I do like an 11labs voice agent and so our end web hook URL right here that's where 11 Labs is sending data to or I'll show you an example with lovable where I build a little app and then our app is sending data to this URL so that's how it works right important things to remember is you still have to set up your method so if you are setting up some sort of request on a different service and you're sending data to this web hook it's probably going to be a post so you'll want to change that and make sure that these actually align anyways what we're going to do is we're going to change this to a post because I I just know it's going to be post and this is our web hook URL which is a test URL so I'm going to click on the button to copy it and what I'm going to do is take this and I'm going to go into Postman which is just kind of like an API platform that I use to show some demos of how we can send these requests so I'm going to click on send an API request in here this basically just lets us test out and see if our web hook's working so what I'm going to do is I'm going to change the request to post i'm going to enter the web hook URL from my NAND web hook okay and now basically what we have is the ability to send over certain information so I'm just going to go to body i'm going to send over form data and now you can see just like JSON it's key value pairs so I'm just going to send over a field called text and the actual value is going to be hello okay so that's it i'm going to click on send but what happens is we're going to get a request back which is a 404 error it says the web hook is not registered and basically there's a hint that says click the test workflow button so because this workflow I'm sorry because the web hook is supposed to be listening right now it's not listening and the reason it's not listening is because we are in an act inactive workflow like we've talked about before and we haven't clicked listen for test event so if I click listen now you can see it is listening for this URL okay so I go back into Postman i hit send and now it's going to say workflow was started i come back into here we can see that the node has executed and what we have is our text that we entered right there in the body which was text equals hello we also get all this other random stuff that we don't really need um I don't even know what this stuff really stands for we can see our host was our our nit cloud account all this kind of stuff um but that's not super important for us right now right i just wanted to show that that's how it works so they're both configured as post our postman is sending data to this address and we saw that it worked right so what comes next is the fact that we can respond to this web hook so right now we're set to respond immediately which would be sending data back right away but let's say later you'll see an example in 11 labs and my end workflow we where we want to grab data do something with it and send something back and how that would work is we would change this method to using respond to web hook node and then we basically like add like maybe an AI agent right here and then after the AI agent we would basically just go respond to web hook and as you can see it just returns data to that same web hook address so that would just be sending data back to lovable 11s postman wherever we actually got the initial request from we would do something with that data and send it back to that web hook so really it's the exact same way that we think about APIs except for we are now the API server rather than the person who's sending the request so if you think about the example with um being at a restaurant you know like we would look at the menu we would send off a request through the waiter to the kitchen and then the kitchen would get that request via a web hook they would create the food and then they would send it back to the actual person via responding to web hook so that's all it is is we are just on the other side of the table now and then one last important thing to know about web hooks in NN is ideally you have to make it active so we would click on active but what it's going to tell us is that you can now make calls to your production web hook URL no longer the test URL so if you remember in here we have test and production and what I copied into Postman was the test so if I go back into Postman and I hit send nothing happens right but if I now go to production URL copy the production go into Postman and paste in the production URL hit send there we go workflow was started because that's the actual active workflow production URL so I can click on executions and we can see this is the newest one we just got when we made our workflow active and it did in fact start and just to prove to you that that's how it works let me change the body which now instead of saying hello it's going to say active run oops and we'll send that off go into edit end and we'll basically just watch a new execution will pop up because it's actively listening i'm not doing anything there you go you see it pop up and if we click into the actual web hook data we will see right here the text says active run cool so that's web hooks hopefully that clears up any confusion that you may have had regarding web hooks but let's dive into some examples in NAND where we have a web hook trigger and then we're also configuring that other third party app that's going to send data to our web hook and trigger the workflow hey there I'm Archer what can I do for you hey Archer can you help me send an email of course I'd be delighted to help who's the email for and what's it about just give me the details and I'll get it sent out awesome yeah I just wanted to send one to Phil i wanted to ask about an update for the project that we discussed last week got it so you want to send an email to Phil asking about a project update no problem i'll handle that just hang tight while I send this off all done it's been sent to Phil he'll be getting that email any minute anything else I can help you with yeah could you actually go ahead and help me send another one of course i'm always happy to lend a hand or rather an email address who is this email for and what's it about just give me the details and I'll whip it up just another one to Phil i forgot to mention that I wanted to see if he wants to get lunch tomorrow all right another email to Phil this time to ask about lunch tomorrow i'm on it just a sec gotcha the email is on its way to Phil he'll be sure to see your invitation for lunch tomorrow let me know if you need anything else no that's going to be it thanks Archer you're very welcome always happy to help especially when it comes to emails happy to handle any other messages you need to send in the future have a great day okay so that was a quick demo of the super cool conversational voice agent that we built using 11 Labs and Nad his name's Archer and he helps us send emails as you can tell he was very enthusiastic about sending emails so here's that first email that we asked Archer to send to Phil hi Phil i hope this message finds you well i'm writing to inquire about the project update we discussed last week could you please share the latest developments at your earliest convenience looking forward to your response best Nate and then we asked Archer to send another email just asking if he wants to get lunch tomorrow to Phil so hi Phil i was wondering if you're available for lunch tomorrow let me know what works for you best Nate so now that we've seen a quick demo we heard the voice we've seen the emails actually come through we're going to hop back into Nad and we're going to explain what's going on here so that you guys can get this sort of system up and running for yourselves okay so there are a few things that I want to break down here first of all just within NAN whenever you're building an AI agent as you guys should know there's going to be an input and then that input is going to be fed into the agent the agent's going to use its system prompt and its brain to understand what tools it needs to hit it's going to use those tools to take action and then there's going to be some sort of output so in the past when we've done tutorials on personal assistants email agents whatever it was rag agents usually that the input that we've been using has been something like Telegram or Gmail or even just the NAN chat trigger pretty much all we're switching out here for the input and the output is 11 Labs so we're going to be getting a post request from 11 Labs which is going to send over the body parameters like who the email is going to um what the message is going to say stuff like that and then the agent once it actually does that it's going to respond using this respond to web hook node so we'll get into 11 Labs and I'll show you guys how I prompted the agent and everything like that in 11 Labs but first let's take a quick look at what's going on in the super simple agent setup here in NN so these are tools that I've used multiple times on videos on my channel the first one is contact data so it's just a simple Google sheet this is what it looks like here's Phil's information with the correct Gmail that we were having information sent to and then I just put other ones in here just to sort of dummy data but all we're doing is we're hooking up the tool um Google Sheets it's going to be reading get rows sheet within the document we link the document that's pretty much all we had to do um and then we just called it contact data so that when we're prompting the agent it knows when to use this tool what it has and then the actual tool that sends emails is the send email tool so in here we're connecting a Gmail tool um this one is you know we're using all the from AI functions which makes it really really easy um we're sending a message of course and so the from AI function basically takes the query coming in from the agent and understands um dynamically the AI is looking for okay what's the email address based on the user's message okay we grab the email address we're going to put it in the two parameter how can we make a subject out of this message we'll put it here and then how can we actually construct an email body and we put it there so that's all that's going on here here we've got our tools we've obviously got a chat model in this case we're just using um GPT40 and then we have the actual what's taking place within the agent so obviously there's an input coming in so that's where we define this information input agent output and then the actual system message for the agent so the system message is a little bit different than the user agent the system message is defining the role this is your job as an agent this is what you should be doing these are the tools you have and then the user message is like each execution each each run each time that we interact with the agent through 11 Labs it's going to be a different user message coming in but the system message is always going to remain the same as it's the prompt for the AI agents behavior anyways let's take a look at the prompt that we have here first the overview is that you are an AI agent responsible for drafting and sending professional emails based on the user's instructions you have access to two tools contact data to find email addresses and send email to compose and send emails your objective is to identify the recipient's contact information draft a professional email and sign off as Nate before sending the tools you have obviously uh contact data it retrieves email addresses based on the name so we have an example input John Doe example output an email address and then send email sends an email with a subject and a body the example input here is an email address um subject and a body with example email subject body um so that's what we have for the system message and then for the um user message as you can see we're basically just saying um okay so the email is going to be for this person and the email content is going to be this so in this case this execution it was the email's for Phil and the email content is asking about lunch tomorrow so that's all that we're being fed in from 11 Labs and then the agent takes that information to grab the contact information and then it uses its AI brain to make the email message finally it basically just responds to the web hook with um the email to Phil regarding lunch tomorrow has been successfully sent and then 11 Labs captures that response back and then it can respond to us with gotcha we were able to send that off for you is there anything else you need so that's pretty much all that's going on here um if you see in the actual web hook what we're getting here is you know there's different things coming back we have different little technical parameters all this kind of stuff all that we want to configure and I'll show you guys how we configure this in 11 Labs is the the JSON body request that's being sent over so we're in table format if we went to JSON we could see down here we're looking at body in the body we set up two fields to send over from 11 Labs to Nidend using that post request web hook the first field that we set up was two and as you can see that's when the 11 Labs model based on what we say figures out who the email is going to and puts that there and then figures out what's the email content what do you want me to say in this email and then throws that in here so um that's how that's going to work as far as setting up the actual web hook node right here um we have a we wanted to switch this to a post method because 11 Labs is sending us information um we have a test URL and a production URL the test one we use for now and we have to manually have naden listen for a test event um I will show an example of what happens if we don't actually do this later in the video but when you push the app into production you make the workflow active you would want to put this web hook in 11 Labs as the production URL rather than the test URL so that you can make sure that the stuff's actually coming over we put our path as end just to clean up this URL all that it does is changes the URL um and then authentication we put none and then finally for response instead of doing immediately or wait when last node finishes we want to do using respond to web hook node that way we get the information the agent takes place and then responds and then all we have here is respond to web hook so it's very simple as you can see it's only you know really four nodes you know the email the brain um and then the two tools and the web hooks so um hopefully that all made sense we are going to hop into 11 labs and start playing around with this stuff also quick side note if you want to hop into this workflow check out the prompts play around with how I configured things um you'll be able to download this workflow for free in the free school community link for that will be down in the description you'll just come into here you'll click on YouTube resources you will click on the post associated with this video and then you're able to download the workflow right here once you download the workflow you can import it from file and then you will have this exact canvas pop up on your screen then if you're looking to take your skills with Naden a little bit farther feel free to check out my paid community the link for that will also be down in the description great community in here a lot of people obviously are learning NAN and um asking questions sharing builds sharing resources got a great classroom section going over you know client builds and some deep dive topics as well as five live calls per week so you can always make sure you're getting your questions answered okay anyways back to the video so in 11 Labs this is the email agent this is just the test environment where we're going to be talking to it to try things out so we'll go back and we'll see how we actually configured this agent and if you're wondering why I named him Marcher it's just because his actual voice is Archer so um that wasn't my creativity there anyways once we are in the configuration section of the actual agent we need to set up a few things so first is the first message um we pretty much just when we click on call the agent it's going to say "Hey there I'm Marcher what can I do for you?" Otherwise um if we leave this blank then we will be the ones to start the conversation but from there you will set up a system prompt so in here this is a prompt I have is you are a friendly and funny personal assistant who loves helping the user with tasks in an upbeat and approachable way your role is to assist the user with sending emails when the user provides details like who the email is for and what's it about you will pass that information to the NAN tool and wait for its response i'll show you guys in a sec how we configure the NAN tool and how all that works but anyways once you get confirmation from NAN that the email was sent cheerfully let the user know it's done and ask if there's anything else you can help with keep your tone light friendly and witty while remaining efficient and clear in your responses so as you can see in the system prompt I didn't even really put in anything about the way it should be conversating as far as like sounding natural and using filler words and um and sometimes I do that to make it sound more natural but this voice I found just sounded pretty good just as is then we're setting up the large language model um right now we're using Gemini 1.5 Flash just because it says it's the fastest you have other things you can use here but I'm just sticking with this one and so this is what it uses to extract information pretty much out of the conversation to pass it to NAND or figure out how it's going to respond to you that's what's going on here and then with temperature um I talked about I like to put a little bit higher especially for some fun use cases like this um basically this is just the randomness and creativity of the responses generated so that it's always going to be a little different and it's going to be a little fun um the higher you put it but if you wanted it to be more consistent and you had like you know you were trying to get some sort of information back um right the way you want it then you would probably want to lower this a little bit um and then you have stuff like knowledge base so if this was maybe like um a customer support you'd be able to put some knowledge base in there or if you watch my previous voice video about um sort of doing voice rag you could still do the sending it to NADN hitting a vector database from Naden and then getting the response back but anyways um in this case this is where we set up the tool that we were able to call up here as you saw in the system prompt so the tool NAN this is where you're putting the web hook from your the web hook URL from NAN that's where you're putting that right here as you can see um web hook- test NAN the method is going to be a post so we can send information from 11 Labs to NAN and we just named it Naden to make the system prompt make more sense for um just just for me when I was creating this it makes sense to send something to the tool called Naden anyways as you can see the description is use this tool to take action upon the user's request and so we can pretty much just leave it as that we don't have any headers or authorization going in here but we do need to send over body parameters um otherwise if we didn't have this nothing would be sent over to Naden at all so the description of the body parameters is in a friendly way ask the user to provide the name of the recipient and what the email is about unless they already provided that information so the LLM is understanding when it's conversating with the human it needs to extract the name of this person to send an an email to and then actually what is the email going to have as you can see we didn't have to put in like oh what's the subject of the email because our AI agent in N8N can use its brain to figure out a subject so we have two parameters that we're setting over if you remember when we were in here we got the two parameters from the body right here which was two and email content and so that's as you can see what we set up here so the first one was a string it was called two and this is who the email is going to and then the second one was also a string it's called email content and this is what is the email about so we hit save changes now we have a tool that gets called whenever um the voice agent realizes it has information to send over to N to send an email and it has the right parameters to do so so now we have this voice agent pretty much set up here with its tools and its system prompt we're going to test the agent and remember earlier I talked about the fact that right now we're testing so we have to have the web hook actively listening once this is in production it's going to be listening all the time but right now we have to manually hit test event before we call it otherwise it's not going to work so I'm going to talk to Archer ask him to send an email it's going to go through and then we're going to ask him to send another email where we don't hit this web hook test event and then we'll see what he says you're probably just going to say he couldn't access the database or he couldn't find the contact information something like that hey there I'm Archer what can I do for you hey Archer can you help me send an email of course i'd love to help who's the email for and what's it about tell me the details and I'll whip it up in a jiffy sweet um it's going to be for Phil okay so the email is for Phil what's it about i'm ready to get this email sent out yeah just let him know that I'm caught in traffic and I'm going to be late to the meeting got it so you want to let Phil know you're running late because of traffic i'll get that email sent out right away all done i just sent the email to Phil letting him know you're running late anything else I can help you with yeah I'm actually going to need to send another one no problem who's this one for and what's it about i'm ready to send email number two yeah can you let Phil know that um I actually just drove my car off a bridge oh my goodness i can't send an email like that maybe you should call Phil instead is there someone else you want to send an email to um no can you send an email to Phil i'm so sorry but I can't send an email like that it sounds like you're in a difficult situation is there someone else you can reach out to for help okay didn't expect that so I guess the model doesn't want to say something like that we'll try again um workflow is not active so let's see hey there I'm Archer what can I do for you hey Archer can you send an email of course I'd be happy to help you with that who is the email for and what is it about i'll get it sent out in a jify just wanted to touch base with Phil about um the meeting later today okay so you want to send an email to Phil about the meeting later today got it i'll get this done right away anything else I can help with today oops looks like there was an error sending that email it's possible there's a typo in the email address or something is wrong on my end let me try again can you please double check the email address okay anyway so that's how that works as you can see the second time the web hook wasn't active so wasn't able to send that um that email for us because it pretty much endnot passed through so that's going to be it for this one i hope that everything made sense um it's just really cool how easy it basically is to switch out an input and you can have the agent function the same obviously a few things would change as you start to add more tools your user message would have to be tweaked a little bit you'd have to tweak the actual system prompts a little bit but as you can see in this one kept it very very simple basically just told it its role gave it the the two tools and how to use them and as you can see um it was pretty seamless as far as being able to have the agent fill in things make the messages and then send them off pretty easily today we're going to be talking about how you can build anything with Lovable and NAN so we're going to be doing a live build of spinning up a web page with lovable and then also building the backend on nit but first of all I wanted to go over high level what this architecture looks like so right here is lovable this is what we're starting off with and this is where we're going to be creating the interface that the user is interacting with what we do here is we type in a prompt in natural language and Lovable basically spins up that app in seconds and then we're able to talk back and forth and have it make minor fixes for us so what we can do is when the user inputs information into our lovable website it can send that data to nadn the nadn workflow that we're going to set up can you know use an agent to take action in something like gmail or slack air tableable or quickbooks and then naden can send the data back to lovable and display it to the user and this is really just the tip of the iceberg there's also some really cool integrations with lovable and superbase or stripe or resend so there's a lot of ways you can really use lovable to develop a full web app and so while we're talking high We just wanted to show you an example flow of what this naden could look like where we're capturing the information the user is sending from lovable via web hook we're feeding that to a large language model to create some sort of content for us and then we're sending that back and it will be displayed in the Lovable web app so let's head over to Lovable and get started so if you've never used Lovable before don't worry i'm going to show you guys how simple it is you can also sign up using the link in the description for double the credits okay so this is all I'm going to start with just to show you guys how simple this is i said "Help me create a web app called Get Me Out of This where a user can submit a problem they're having." Then I said to use this image as design inspiration so I Googled landing page design inspiration and I'm just going to take a quick screenshot of this landing page copy that and then paste it into Lovable and then we'll fire this off cool so I just sent that off and on the right hand side we're seeing it's going to spin up a preview so this is where we'll see the actual web app that it's created and get to interact with it right now it's going to come through and start creating some code and then on the lefth hand side is where we're going to have that back and forth chat window to talk to lovable in order to make changes for us so right now as you can see it's going to be creating some of this code we don't need to worry about this let's go into nit real quick and get this workflow ready to send data to okay so here we are in Nen if you also haven't used this app before there'll be a link for it down in the description it's basically just going to be a workflow builder and you can get a free trial just to get started so you can see I have different workflows here we're going to come in and create a new one and what I'm going to do is we're gonna add a first step that's basically saying okay what actually triggers this workflow so I'm gonna grab a web hook and so all a web hook is is you know it looks like this and this is basically just a trigger that's going to be actively listening for something to send data to it and and data is received at this URL and so right now there's a test URL and there's a production URL don't worry about that we're going to click on this URL to copy it to our clipboard and basically we can give this to Lovable and say "Okay whenever a user puts in a problem they're having you're going to send the data to this web hook." Cool so hopping over to Lovable as you can see it's still coding away and looks like it's finishing up right now and it's saying "I've created a modern problem-solving web app with a hero section submission form and feature section in blue color." Um looks like there's an error so all we have to do is click on try to fix and it should go back in there and continue to spin up some more code okay so now it looks like it finished that up and as you can see we have the website filled up and so it created all of this with just uh an image as inspiration as well as just me telling it one sentence help me create a web app called get me out of this where a user can submit a problem they're having so hopefully this should already open your eyes to how powerful this is but let's say for the sake of this demo we don't want all this we just kind of want one simple landing page where they send a problem in so all I'd have to do is on this lefth hand side scroll down here and say make this page more simple we only need one field which is what problem can we help with so we'll just send that off very simple query as if we were just kind of talking to a developer who was building this website for us and we'll see it modify the code and then we'll see what happens so down here you can see it's modifying the code and now we'll see what happens it's just one interface right here so it's created like a title it has these different buttons and we could easily say like okay when someone clicks on the home button take them here or when someone clicks on the contact button take them here and so there's all this different stuff we can do but for the sake of this video we're just going to be worrying about this interface right here and just to give it some more personality what we could do is add in a logo so I can go to Google and search for a thumbs up logo PNG and then I can say add this logo in the top left so I'll just paste in that image we'll fire this off to lovable and it should put that either right up here or right up here we'll see what it does but either way if it's not where we like it we can just tell it where to put it cool so as you can see now we have that logo right up there and let's say we didn't like this all we'd have to do is come up to a previous version hit on these three dots and hit restore and then it would just basically remove those changes it just made okay so let's test out the functionality over here let's say a problem is we want to get out of Oh looks like the font is coming through white so we need to make sure this is changed and boom we just told it to change the text to black and now it's black and we can see it so anyways I want to say get me out of a boring meeting so we'll hit get me out of this and we'll see what happens it says submitting and nothing really happens even though it told us you know we'll get back to you soon nothing really happened so what we want to do is we want to make sure that it knows when we hit this button it's going to send that data to our Naden web hook so we've already copied that web hook to our clipboard but I'm just going to go back into Naden we have the web hook we'll click on this right here back into lovable basically just saying when I click get me out of this so this button right here send the data to this web hook and also what we want to do is say as a post request because it's going to be sending data so we're going to send that off and while it's making that change to the code real quick we want to go into edit end and make sure that our method for this web hook is indeed post so I don't want to dive into too much what that means really but Lovable is going to be sending a post request to our web hook meaning there's going to be stuff within this web hook like body parameters and different things and so if this wasn't configured as a post request it might not work so you'll see once we actually get the data and we catch it in any of them but anyways now when the users click on get me out of this the form will send the problem description to your web hook via a post request so let's test it out so we're going to say I forgot to prepare a brief for my meeting we're going to go back and end it in real quick and make sure we hit listen for test event so now our web hook is actively listening back in lovable we'll click get me out of this and we will see what happens we can come and end it in and we can now see we got this information so here's the body I was talking about where we're capturing a problem which is I forgot to prepare a brief for my meeting so we now know that Lovable is able to send data to NAND and now it's on us to configure what we want to happen in NAND so we can send the data back to Lovable cool so what I'm going to do is I'm going to click on the plus that's coming off of the web hook and I'm going to grab an AI agent what this is going to do is allow us to connect to a different chat model and then the agent's going to be able to take this problem and produce a response and I'm going to walk through the step by step but if you don't really want to worry about this and you just want to worry about the lovable side of things you can download the finished template from my free school community i'll link that down in the description that way you can just plug in this workflow and just give lovable your noden web hook and you'll be set up but anyways if you join the free school community you'll click on YouTube resources click on the post associated with this video and you'll be able to download the JSON right here and then when you have that JSON you can come into Nadn open up a new workflow click these three dots on the top and then click import from file and when you open that up it'll just have the finished workflow for you right here but anyways what I'm going to do is click into the AI agent and the first thing is we have to configure what information the agent is going to actually read so first of all we're going to set up that as a user prompt we're going to change this from connected chat trigger node to define below because we don't have a connected chat trigger node we're using a web hook as we all know so we're going to click on define below and we are basically just going to scroll down within the web hook node where the actual data we want to look at is which is just the problem that was submitted by the user so down here in the body we have a problem and we can just drag that right in there and that's basically all we have to do and maybe we just want to define to the agent what it's looking at so we'll just say like the problem and then we'll put a colon so now you can see in the result panel this is what the agent will be looking at and next we need to give it a system message to understand what it's doing so I'm going to click on add option open up a system message and I am going to basically tell it what to do so here's a system message that I came up with just for a demo you're an AI excuse generator your job is to create clever creative and context appropriate excuses that someone could use to avoid or get out of a situation and then we told it to only return the excuse and also to add a touch of humor to the excuses so now before we can actually run this to see how it's working we need to connect its brain which is going to be an AI chat model so what I'm going to do is I'm going to click on this plus under chat model for this demo we'll do an OpenAI chat model and you have to connect a credential if you haven't done so already so you would basically come into here click create new credential and you would just have to insert your API key so you can just Google OpenAI API you'll click on API platform you can log in and once you're logged in you just have to go to your dashboard and then on the left you'll have an API key section all you'll have to do is create a new key we can call this one um test lovable and then when you create that you just copy this value go back into Nitn paste that right here and then when you hit save you are now connected to OpenAI's API and we can finally run this agent real quick if I come in here and hit test step we will see that it's going to create an excuse for I forgot to prepare a brief for my meeting which is sorry I was too busy trying to bond with my coffee machine turns out it doesn't have a prepare briefs setting so basically what we have is we're capturing the problem that a user had we're using an AI agent to create a excuse and then we need to send the data back to Lovable so all we have to do here is add the plus coming off of the agent we're going to call this a respond to web hook node and we're just going to respond with the first incoming item which is going to be the actual response from the agent but all we have to do also to configure this is back in the web hook node there's a section right here that says respond instead of responding immediately we want to respond using the respond to web hook node so now it will be looking over here and that's how it's going to send data back to lovable so this is pretty much configured the way we need it but we have to configure Lovable now to wait for this response okay so what I'm telling Lovable is when the data gets sent to the web hook we wait for the response from the web hook then output that in a field that says here is your excuse so we'll send this off to Lovable and see what it comes up with okay so now it said that I've added a new section that displays here is your excuse along with the response message from the web hook when it's received so let's test it out first I'm going to go back and edit in and we're going to hit test workflow so the web hook is now listening for us so we'll come into our lovable web app and say I want to skip a boring meeting we'll hit get me out of this so now that data should be captured in Naden it's running and now the output is I just realized my pet goldfish has a lifealtering decision to make regarding his tank decorations and I simply cannot miss this important family meeting so it doesn't look great but it worked and if we go into edit end we can see that this run did indeed finish up and the output over here was I just realized my pet goldfish has a lifealtering decision blah blah blah so basically what what's happening is the web hook is returning JSON which is coming through in a field called output and then we have our actual response which is exactly what lovable sent through so it's not very pretty and we can basically just tell it to clean that up so what I just did is I said only return the output fields value from the web hook response not the raw JSON so we wanted to just output this right here which is the actual excuse and so some of you guys may not even have had this problem pop up i did a demo of this earlier just for testing and I basically walked through these same steps and this wasn't happening but you know sometimes it happens anyways now it says the form only displays the value from the output field so let's give it another try so back in we're going to hit test workflow so it's listening for us in lovable we're going to give it a problem so I'm saying I overslept and I'm running late i'm going to click get me out of this and we'll see the workflow just finished up and now we have the response in a clean format which is I accidentally hit the snooze button until it filed for a restraining order against me for harassment okay so now that we know that the functionality within N is working it's sending data back we want to customize our actual interface a little bit so the first thing I want to do just for fun is create a level system so every time someone submits a problem they're going to get a point and if they get five points they'll level up if they get 20 total points they'll level up again okay so I just sent off create a dynamic level system every time a user submits a problem they get a point everyone starts at level one and after five points they reach level two then after 50 more points they reach level three and obviously we'd have to bake in the rest of the the levels and how many points you need but this is just to show you that this is going to increase every time that we submit a problem and also you'd want to have some sort of element where people actually log in and get authenticated and you can store that data in Superbase or in um you know Firebase whatever it is so that everyone's levels are being saved and it's specific to that person okay so looks like it just created a level system it's reloading up our preview so we can see what that looks like now um looks like there may have been an error but now as you can see right here we have a level system so let's give it another try i'm going to go into Nitn we're going to hit test workflow so it's listening once again and we're going to describe a problem so I'm saying my boss is mean i don't want to talk to him we're going to hit submit the NN workflow is running right now on the back end and we just got a message back which is I'd love to chat but I've got a hot date with my couch and binge watching the entire season of Awkward Bosses and you can see that we got a point so four more points to unlock level two but before we continue to throw more prompts so that we get up to level two let's add in one more cool functionality okay so I'm just firing off this message that says add a drop down after what problem can we help with that gives the user the option to pick a tone for the response so the options can be realistic funny ridiculous or outrageous and this data of course should be passed along in that web hook to NADN because then we can tell the agent to say okay here's the problem and here's the tone of an excuse the user is requesting and now it can make a request or a response for us so looks like it's creating that change right now so now we can see our dropown menu that has realistic funny ridiculous and outrageous as you can see before you click on it it's maybe not super clear that this is actually a drop down so let's make that more clear and what I'm going to do is I'm going to take a screenshot of this section right here i'm going to copy this and I'm just going to paste it in here and say make this more clear that it is a drop-own selection and we'll see what it does here okay perfect so it just added a little arrow as well as a placeholder text so that's way more clear and now what we want to do is test this out okay so now to test this out we're going to hit test workflow but just keep in mind that this agent isn't yet configured to also look at the tone so this tone won't be accounted for yet but what we're going to do is we have I overslept and the response is going to be funny we'll hit generate me a or sorry get me out of this so we have a response and our level went up we got another point but if we go into Nit we can see that it didn't actually account for the tone yet so all we have to do is in the actual user message we're basically just going to open this up and also add a tone and we can scroll all the way down here and we can grab the tone from the body request and now it's getting the problem as well as the tone and now in the system prompt which is basically just defining to the agent its role we have to tell it how to account for different tones okay so here's what I came up with i gave it some more instructions and I said "You're going to receive a problem as well as a tone and here are the possible tones which are realistic funny ridiculous and outrageous." And I kind of said what that means and then I said "Your excuse should be one to three sentences long and match the selected tone." So that's all we're going to do we're going to hit save okay so now that it's looking at everything we're going to hit test workflow the web hook's listening we'll come back into here and we're going to submit i broke my friend's iPhone and the response tone should be outrageous so we're going to send that off and it's loading because our end workflow is triggering and now we just got it we also got a message that says we earned a point so right here we now only need two more for level two but the excuse is I was trying to summon a unicorn with my telekinetic powers and accidentally transformed your iPhone into a rogue toaster that launched itself off the counter i swear it was just trying to toast a bagel okay so obviously that's pretty outrageous and that's how we know it's working so I'm sure you guys are wondering what would you want to do if you didn't want to come in here and every single time make this thing you know test workflow what you would do is you'd switch this to an active workflow now basically we're not going to see the executions live anymore with all these green outlines but what's happening now is it's using the production URL so we're going to have to copy the production URL come back into Lovable and just basically say I switched the URL or sorry let's call I switched the web hook to this and we'll paste that in there and it should just change the data the logic should be all the exact same because we've already built that into this app but we're just going to switch the web hook so now we don't have to go click test workflow every time in NAN and super excited we have two more problems to submit and then we'll be level two so now it says the web hook URL has been updated so let's test it out as you can see in here we have an active workflow we're not hitting test workflow we're going to come in here and submit a new problem so we are going to say um I want to take four weeks off work but my boss won't let me we are going to make the response tone let's just do a realistic one and we'll click get me out of this it's now calling that workflow that's active and it's listening so we got a point we got our response which is I've been dealing with some unforeseen family matters that need my attention i believe taking 4 weeks off will help me address them properly i plan this time to use this time to ensure everything is in order so I can return more focused and productive i would definitely say that that's realistic what we can do is come into NAN we can click up here on our executions and we can see what just happened so this is our most recent execution and if we click into here it should have been getting the problem which was I want to take four weeks off work and the tone which was realistic cool cool so now that we know that our active new web hook is working let's just do one more query and let's earn our level two status i'm also curious to see you know we haven't worked in any logic of what happens when you hit level two maybe there's some confetti maybe it's just a little notification we're about to find out okay so I said I got invited on a camping trip but I hate nature we're going to go with ridiculous and we're going to send this off see what we get and see what level two looks like okay so nothing crazy we could have worked in like hey you know make some confetti pop up all we do is we get promoted to level two up here but you know as you can see the bar was dynamic it moved and it did promote us to level two but the excuse is I'd love to join but unfortunately I just installed a new home system that detects the presence of grass trees and anything remotely outdoorsy if I go camping my house might launch an automated rescue mission to drag me back indoors so that's pretty ridiculous and also by the way up in the preview you can make it mobile so we can see what this would look like on mobile obviously it's not completely optimized yet so we'd have to work on that but that's the ability to do both desktop and mobile and then when you're finally good with your app up in the top right we can hit publish which is just going to show us that we can connect it to a custom domain or we can publish it at this domain that is made for us right here anyways that is going to be it for today's video this is really just the tip of the iceberg with you know nodn already has basically unlimited capabilities but when you connect that to a custom front end when you don't have to have any sort of coding knowledge as you can see all of these prompts that I use in here was just me talking to it as if I was talking to a developer and it's really really cool how quick we spun this up all right hopefully you guys thought that was cool i think that 11 Labs is awesome and it's cool to integrate agents with that as well as lovable or bolt or these other vibe coding apps that let you build things that would have taken so much longer and you would have kind of had to know how to code so really cool so we're nearing the end of the course but it would be pretty shameful if I didn't at least cover what MCP servers are because they're only going to get more commonly used as we evolve through the space so we're going to talk about MCP servers we're going to break it down as simple as possible and then I'm going to do a live setup where I'm self-hosting NADN in front of you guys step by step and then I'm going to connect to a community node in NN that lets us access some MCP servers so let's get into it okay so model context protocol i swear the past week it's been the only thing I've seen in YouTube comments YouTube videos Twitter LinkedIn it's just all over and I don't know about you guys but when I first started reading about this kind of stuff I was kind of intimidated by it i didn't completely understand what was going on it was very techy and you know kind of abstract i also felt like I was getting different information based on every source so we're going to break it down as simple as possible how it makes AI agents more intelligent okay so we're going to start with the basics here let's just pretend we're going back to Chad GBT which is you know a large language model what we have is an input on the left we're able to ask it a question you know help me write this email tell me a joke whatever it is we feed in an input the LM thinks about it and provides some sort of answer to us as an output and that's really all that happens the next evolution was when we started to give LLM tools and that's when we got AI agents because now we could ask it to do something like write an email but rather than just writing the email and giving it back to us it could call a tool to actually write that email and then it would tell us there you go the job's done and so this really started to expand the capabilities of these LLM because they could actually take action on our behalf rather than just sort of assisting us and getting us 70% of the way there and so before we start talking about MCP servers and how that enhances our agents abilities we need to talk about how these tools work and sort of the limitations of them okay so sticking with that email example let's pretend that this is an email agent that's helping us take action in email what it's going to do is each tool has a very specific function so this first tool over here you can see this one is going to label emails the second tool in the middle is going to get emails and then this third one on the right is going to send emails so if you watched my ultimate assistant video if you haven't I'll tag it right up here what happened was we had a main agent and then it was calling on a separate agent that was an email agent and as you can see here was all of its different tools and each one had one very specific function that it could do and it was basically just up to the email agent right here to decide which one to use based on the incoming query and so the reason that these tools aren't super flexible is because within each of these configurations we basically have to hardcode in what is the operation I'm doing here and what's the resource and then we can feed in some dynamic things like different message ids or label ids over here you know the operation is get the resources message so that won't change and then over here the operation is that we're sending a message and so this was really cool because agents were able to use their brains whatever large language model we had plugged into them to understand which tool do I need to use and it still works pretty well but when it comes to being able to scale this up and you want to interact with multiple different things not just Gmail and Google Calendar you also want to interact with a CRM and different databases that's where it starts to get a little confusing so now we start to interact with something called an MCP server and it's basically just going to be a layer between your agent and between the tools that you want to hit which would be right here and so when the agent sends a request to the specific MCP server in this case let's pretend it's notion it's going to get more information back than hey what tools do I have and what's the functionality here it's also going to get information about like what are the resources there what are the schemas there what are the prompts there and it uses all of that to understand how to actually take the action that we asked back here in the whole input that triggered the workflow when it comes to different services talking to each other so in this case Nadn and notion there's been you know a standard in the way that we send data across and we get data back which has been the rest APIs and these standards are really important because we have to understand how can we actually format our data and send it over and know that it's going to be received in the way that we intend it to be and so that's exactly what was going on back up here where every time that we wanted to interact with a specific tool we were hitting a specific endpoint so the endpoint for labeling emails was different for the endpoint for sending emails and besides just those endpoints or functions being different there was also different things that we had to configure within each tool call so over here you can see what we had to do was in order to send an email we have to give it who it's going to what the subject is the email type and the message which is different from the information we need to send to this tool which is what's the message ID you want to label and what is the label name or ID to give to that message by going through the MCP server it's basically going to be a universal translator that takes the information from the LLM and it enriches that with all of the information that we need in order to hit the right tool with the right schema fill in the right parameters access the right resources all that kind of stuff the reason I put notion here for an example of an MCP server is because within your notion you'll have multiple different databases and within those databases you're going to have tons of different columns and then all of those you know are going to have different pages so being able to have the MCP server translate back to your agent here are all of the databases you have here is the schema or the different fields or columns that are in each of your databases um and also here are the actions you can take now using that information what do you want to do real quick hopping back to the example of the ultimate assistant what we have up here is the main agent and then it had four child workflows child agents that it could hit that had specializations in certain areas so the Gmail agent which we talked about right down here the Google calendar agent the contact agent which was Air Table and then the content creator agent so all that this agent had to do was understand okay based on what's coming in based on the request from the human which of these different tools do I actually access and we can honestly kind of think of these as MCP servers because once the query gets passed off to the Gmail agent the Gmail agent down here is the one that understands here are the tools I have here are the different like you know parameters I need to fill out i'm going to take care of it and then we're going to respond back to the main agent this system made things a little more dynamic and flexible because then we didn't have to have the ultimate assistant hooked up to like 40 different tools you know all the combinations of all of these and it made its job a little more easier by just delegating the work to different MCP servers and obviously these aren't MCP servers but it's kind of the same concept the difference here is that let's say all of a sudden Gmail adds more functionality we would have to come in here and add more tools in this case but what's going on with the MCP servers is whatever MCP server that you're accessing it's on them to continuously keep that server updated so that people can always access it and do what they need to do by this point it should be starting to click but maybe it's not 100% clear so we're going to look at an actual example of like what this really looks like in action but before we do just want to cover one thing which is you know the agent sending over a request to a server the server translates it in order to get all this information and get the tool calls all that kind of stuff um and what's going on here is called MCP protocol so we have the client which is just the interface that we're using in this case it's NN it could be your claude or your you know coding window whatever it is and then we're sending over something to the MCP server and that's called MCP protocol also one thing to keep in mind here that I'm not going to dive into but if you were to create your own MCP server and it had access to all of your own resources your schemas your tools all that kind of stuff you just got to be careful there there's some security concerns because if anyone was getting into that server they could basically ask for anything back so that's something that was brought up in my paid community we were having a great discussion about MCP and stuff like that so just keep it in mind so let's look more at an example in Naden once again so coming down here let's pretend that we have this beautiful air table agent that we built out in NAN as you can see it has these um seven different tools which is get record update record get bases create record search record delete record and get bases schema the reason we needed all of these different tools is because as you know they each have different operations inside of them and then they each have different parameters to be filled out so the agent takes care of all of that but this could be a lot more lean of a system if we were able to access Air Table's MCP server as you see what we're doing right here because this is able to list all the tools that we have available in Air Table so here you can see I asked the Air Table agent what actions do I have it then listed these 13 different actions that we have which are actually more than the seven we had built out here and we can see we have list records search records and then 11 more and this is actually just the agent telling us the human what we have access to but what the actual agent would look at in order to use the tool is a list of the tools where it would be here's the name here's the description of when you use this tool and then here's the schema of what you need to send over to this tool because when we're listing records we have to send over different information like the base ID the table ID max records how we want to filter which is different than if we want to list tables because we need a base ID and a detail label so all of this information coming back from the MCP server tells the agent how it needs to fill out all of these parameters that we were talking about earlier where it's like send email you have different things than you need to fill out for labeling emails so once the agent gets this information back from the MCP server it's going to say okay well I know that I need to use the search records tool because the user asked me to search for records with the name Bob in it so I have this schema that I need to use and I'm going to use my air tableable execute tool in order to do so and basically what it's going to do is going to choose which tool it needs based on the information it was fed previously so in this case the air table execute tool would search records and it would do it by filling in this schema of information that we need to pass over to air tableable so now I hope you can see how basically what's going on in this tool is all 13 tools wrapped up into one and then what's going on here is just feeding all the information we need in order to make the correct decision so this is the workflow we were looking at for the demo we're not going to dive into this one because it's just a lot to look at i just wanted to put a ton of MCP servers in one agent and see that even if we had no system prompt if it could understand which one to use and then still understand how to call its tools so I just thought that was a cool experiment obviously what's next is I'm going to try to build some sort of huge you know personal type assistant with a ton of MCP servers but for now let's just kind of break it down as simple as possible by looking at an individual MCP agent and so I I don't know why I called it an MCP agent in this case it's just kind of like a firecrawl agent with access to firecraws MCP server so yeah okay so taking a look at firecraw agent we're going to ask what tools do you have it's hitting the firecrawl actions right now in order to pull back all of the resources and as you can see it's going to come back and say hey we have these you know nine actions you can take i don't know if it's nine but it's going to be something like that it was nine so as you can see we have access to scrape map crawl batch scrape all this other stuff and what's really cool is that if we click into here we can see that we have a description for when to use each tool and what you actually need to send over so if we want to scrape it's a different schema to fill out than if we want to do something like extract so let's try actually asking it to do something so let's say um extract the rewards program name from um chipotle.com so we'll see what it does here obviously it's going to do the same thing listing its actions and then it should be using the firecrawl extract method so we'll see what comes back out of that tool okay it went green hopefully we actually got a response it's hitting it again so we'll see what happened we'll dive into the logs after this okay so on the third run it finally says the rewards program is called Chipotle Rewards so let's take a look at run one it used firecrawl extract and it basically filled in the prompt extract the name of the rewards program it put it in as a string we got a request failed with status code 400 so not sure what happened there run two it did a firecross scrape we also got a status code 400 and then run three what it did was a firecall scrape once again and it was able to scrape the entire thing and then it used its brain to figure out what the rewards program was called taking a quick look at the firewall documentation we can see that a 400 error code means that the parameters weren't filled out correctly so what happened here was basically it just didn't fill these out exactly correctly the schema of like the prompt and everything to send over and so really these kind of issues just come down to a matter of you know making the tool parameters more robust and also more prompting within the actual firecrawl agent itself but it's pretty cool that it was able to understand okay this didn't work let me just try some other things okay so real quick just wanted to say if you want to hop into Nit and test out these MCP nodes you're going to have to self-host your environment because you need to use the community nodes and you can only access those if you are self-hosted today we're going to be going through the full setup of connecting MCP servers to NN i'm going to walk through how you self-host your NN i'm going to walk through how you can install the community node and then how to actually set up the community node the best part is you don't have to open up a terminal or a shell and type in any install commands all we have to do is connect to the servers through NIND so if that sounds like something that interests you let's dive into it make sure you guys stick around for the end of this one because we're going to talk about the current limitations of these MCP nodes we're going to talk about some problems you may face that no one else is talking about and really what does it mean to actually be able to scale these agents with MCP servers now there are a ton of different platforms that you can use to host NN the reason I'm using Alstio is because it's going to be really simple for deploying and managing open- source software especially with something like NN you can pretty much deploy it in just a few clicks and it's going to take care of installation configuration security backups updates all this kind of stuff so there's no need for you to have that DevOps knowledge because I certainly don't so that's why we're going with Alstio it's also SOCK 2 and GDPR compliant so that's important anyways like I said we're going to be going through the full process so I'm going to click on free trial i'm going to sign up with a new account so I'm going to log out and sign up as a new user okay now that I entered that we're already good to go the first thing I'm going to do is set up a payment method so that we can actually spin up a service so I went down to my account in the lefth hand side and then I clicked on payment options and I'm going to add a card real quick now that that's been added it's going to take a few minutes for our account to actually be approved so I'm just going to wait for that you can see we have a support ticket that got opened up which is just waiting for account activation also here's the approval email I got just keep in mind it says it'll be activated in a few minutes during business hours but if you're doing this at night or on the weekends it may take a little longer okay there we go we are now activated so I'm going to come up here to services and I'm going to add a new service what we're going to do is just type in nadn and it's going to be a really quick oneclick install basically I'm going to just be deploying on htzner as a cloud provider i'm going to switch to my region and then you have different options for service plans so these options obviously have different numbers of CPUs different amount of RAM and storage i'm going to start right now on just the medium i would keep in mind that MCP servers can be kind of resource intensive so if you are running multiple of them and your environment is crashing then you're probably just going to want to come in here and upgrade your service plan so we can see down here here is the estimated hourly price here's the plan we're going with and I'm going to go ahead and move forward now we're going to set up the name so this will pop up as your domain for your NAND environment then I went ahead and called this Nad- demo what you can do here is you can add more volume so if you wanted to you could increase the amount of storage and as you can see down here it's going to increase your hourly price i'm not going to do that but you do have that option and then of course you have some advanced configuration for software updates and system updates once again I'm just going to leave that as is and then you can also choose the level of support that you need you can scan through your different options here obviously you'll have a different price associated with it but on the default plan I'm just going to continue with level one support and now I'm going to click on create service okay so I don't have enough credits to actually deploy this service so I'm going to have to go add some credits in my account so back in the account I went to add credits and now that I have a card I can actually add some credits so I'm going to agree to the terms and add funds payment successful nice we have some money to play with down here we can see 10 credits this is also where we'll see how much we're spending per hour once we have this service up and running unfortunately we have to do that all again so let me get back to the screen we were just on okay now we're back here i'm going to click create service we're deploying your service please wait and this is basically just going to take a few minutes to spin up okay so now what we see is the service is currently running we can click into the service and we should be able to get a link that's going to take us to our NN instance so here's what it looks like we can see it's running and we have all these different tabs and all these different things to look through we're going to keep it simple today and not really dive into it but what we're going to do is come down here to our network and this is our actual domain to go to so if I select all of this and I just click go to this app it's going to spin up our NN environment and because this is the first time we're visiting it we just have to do the setup okay so once we have that configured going to hit next we have to do some fun little onboarding where it's going to ask us some questions right here so then when you're done with that you just got to click get started and you now have this option to get some paid features for free i'm going to hit skip and we're good to go we are in NAN so what's next is we need to install a community node so if you come down here to your settings and you click on settings um you can see you're on the community plan we can go all the way down here to community nodes and now we have to install a community node so in the description we have the GitHub repository for this NAD nodes MCP that was made by Nerding and you can see there's some information on how to actually install this but all we have to do is basically just copy this line right here i'm just going to copy NAN- Nodes MCP click on install community node put that in there hit understand and so the reason you can only do this on self-hosted is because these nodes are not a native verified node from Naden so it's just like you know we're downloading it from a public source at least the code and then we hit install package installed we can now see we have one community node which is the MCP cool so I'm going to leave my settings and I'm going to open up a new workflow and we're just going to hit tab to see if we have the actual node so if I type in MCP we can see that we have MCP client and we have this little block which just means that it is part of the community node so I'm going to click into here and we can see we have some different options we can execute a tool we can get a prompt template we can list available prompts list available resources list available tools and read a resource right now let's go with list available tools um the main one we'll be looking at is listing tools and then executing tools so quick plug for the school community if you're looking for a more hands-on learning experience as well as wanting to connect with over 700 members who are also dedicated to this rapidly evolving space then definitely give this community a look we have great discussions great guest speakers as you can see we also have a classroom section with stuff like building agents vector databases APIs and HTTP request step-by-step builds all the live calls are recorded all this kind of stuff so if this sounds interesting to you then I'd love to see you in a live call anyways let's get back to the video so obviously we have the operation but we haven't set up a credential yet so now what you're going to do is go to a different link in the description which is the GitHub repository for different MCP servers and we can pretty much connect to any of these like I said without having to run any code in our terminal and install some stuff at least because we're hosting in the cloud if we're hosting locally it may be a little different okay so I've seen a ton of tutorials go over like Brave Search or Firecrawl um so let's try to do something a little more fun i think first we'll start off with Airbnb because this one is going to be free you don't even have to go get an API key so that's really cool so I'm going to click into this Airbnb MCP server there's a bunch of stuff going on here and if you understand GitHub and repositories and some code you can look through like the Docker file and everything which is pretty cool but for us non techies all we have to do is come down here it's going to tell us what tools are available but we just need to look at how to actually install this and so all we're looking for is the MPX type installer and so after my testing I tried this one first but it wouldn't let us execute the tool because we need to use this thing that is ignore robots text which just basically lets us actually access the platform so you can see here we have a command which is npx and then we have an array of arguments which is -y this open B&B thing and then also the ignore robots text so first of all I'm just going to grab the command which is npx copy that go back and edit in and we're going to create a new credential this one's going to be for Airbnb so I'm just going to name this so we have it kept and then we're just going to paste the command right into there mpx now we can see we have arguments to fill out so I'm going to go back into that documentation we can see the arguments are -ash-y and then the next one is the open B&B and then the next one is ignore robots text so we're going to put them in one by one so first is the dashy now I'm going to go back and grab the at@ openb put a space and then paste it in there and then I'm going to put another space and then we're going to grab this last part which is the ignore robots txt so once we paste that in there we can basically just hit save as you can see we've connected successfully um the credential is now in our space and we didn't have to type in anything in a terminal and now if we hit test step we should be able to pull in the tools that this MCP server gives us access to so it's as easy as that as you can see there are two tools the first one is Airbnb search here's when you use it and then here's the schema to send over to that tool and then the second one is Airbnb listing details here's when you want to use that and then here's the schema that you would send over and now from here which is really cool we can click on another node which is going to be an MCP client once again and this time we want to execute a tool we already have our credential set up we just did that together and now all we have to do is configure the tool name and the tool parameters so just as a quick demo that this actually works the tool name we're going to drag in Airbnb search as you can see and then for the parameter we can see these are the different things that we need to fill out and so all I'm going to do is just send over a location so I obviously hardcoded in location equals Los Angeles that's all we're going to try and now we're going to hit test step and we should see that we're getting Airbnbs back that are in Los Angeles there we go we have um ton of different items here so let's actually take a look at this listing so if I just copy this into the browser we should see an Airbnb arts district guest house this is in Culver City California and obviously we could make our search more refined if we were able to also put in like a check-in and checkout date how many adults how many children how many pets we could specify the price all this kind of stuff okay cool so that was an example of how we search through an MCP server to get the tools and then how we can actually execute upon that tool but now if we want to give our agent access to an MCP server what we would do is obviously we're going to add an AI agent we are first of all going to come down here give it a chat input so we can actually talk to the agent so we'll add that right here and now we obviously need to connect a chat model so that the agent has a brain and then give it the MCP tools so first of all just to connect a chat model I'm just going to grab an open AI i'm sorry for being boring but all we have to do is create a credential so if you go to your OpenAI account and grab an API key so here's my account as you can see I have a ton of different keys but I'm just going to create a new one this is going to be MCP test and then all we have to do is copy that key come back and end it in and we're going to paste that right in here so there's our key hit save we'll go green we're good to go we're connected to OpenAI and now we can choose our model so for Mini is going to work just fine here now to add a tool once again we're going to add the MCP client tool right here and let's just do Airbnb one more time so we're connected to Airbnb list tools and I'm just going to say what tools do I have and what's going to happen is it errored because the NAND nodes MCP tool is not recognized yet even though the MCP nodes are so we have to go back into Alstio real quick and change one thing so coming back into the GitHub repository for the NN MCP node we can see it gives us some installation information right but if we go all the way down to how to use it as a tool um if I can scroll all the way down here so here is an example of using it as a tool you have to set up the environment variable within your hosting environment so whether it's Allesio or Render or Digital Ocean or wherever you're doing it it'll be a little different but you just have to navigate down to where you have environment variables we have to set nad community package_allow tool usage we have to set that to equal true so I'm going to come back into our Alstio service and right here we have the software which is NAN version latest and what we can do is we can you know restart view app logs we can change the version here or we can update the config which if we open this up it may look a little intimidating but all we're looking for is right here we have environment and we can see we have like different stuff with our Postgress with our web hook tunnel URLs all this kind of stuff and so at the bottom I'm just going to add a new line and I'm just going to paste in that command we had which was nadn community packages allow and then instead of an equal I'm going to put a colon and now we have that nadn community packages allow is set to true and I'm just adding a space after the colon so now it's link and all we're just going to do is hit update and restart and so this is going to respin up our instance okay so it looks like we are now finished up i'm going to go ahead and close out of this we can see that our instance is running so now I'm going to come back into here and I actually refresh this so our agent's gone so let me get him back real quick all right so we have our agent back we're going to go ahead and add that MCP tool once again right here we are going to have our credential already set up the operation is list tools and now let's try one more time asking it what tools do you have and it knows to use this node because it's the operation here is list tools so it's going to be pretty intelligent about it now it's able to actually call that tool because we set up that environment variable so let's see what Airbnb responds with as far as what tools it actually can use cool so I have access to the following tools airbnb search and listing details now let's add the actual tool that's going to execute on that tool so Airbnb um once again we have a credential already set up the operation we're going to choose execute tool instead and now we have to set up what is going on within this tool so the idea here is that when the client responds with okay I have Airbnb search and I have Airbnb listing details the agent will then figure out based on what we asked which one do I use and the agent has to pass that over to this next one which is actually going to execute so what we want to do here is the tool name cannot be fixed because we want to make this dynamic so I'm going to change this to an expression and I'm going to use the handy from AI function here which is basically we're just going to tell the AI agent okay you know based on what's going on you choose which tool to use and you're going to put that in here so I'm going to put in quotes tool and then I'm going to just define what that means and in quotes after a comma I'm going to say the tool selected so we'll just leave it as simple as that and then what's really cool is for the tool parameters this is going to change based on the actual tool selected because there's different schemas or parameters that you can send over to the different tools so we're going to start off by just hitting this button which lets the model define this parameter it's going to get back what not only what tool am I using but what schema do I need to send over so it should be intelligent enough to figure it out for simple queries so let's change this name to Airbnb execute i'm going to change this other one to Airbnb tools and then we'll have the agent try to figure out what's going on and just a reminder there's no system prompt in here it literally just says your helpful assistant so we'll see how intelligent this stuff is okay so I'm asking it to search for Airbnbs in Chicago for four adults let's try that off we should obviously be using the Airbnb search tool and then we want to see if it can fill out the parameters with a location but also how many adults are going to be there because earlier all we did was location so we got a successful response already back once this finishes up we should see potentially a few links down here that actually link to places so here we go um luxury designer penthouse Gold Coast it's apartment it has three bedrooms eight beds so that definitely fits four guests and you can also see it's going to give us the price per night as well as you know the rating and just some other information so let's click into this one real quick and we'll take a look make sure it actually is in Chicago and it has all the stuff this one does have 10 guests so awesome and we can see we got five total listings so without having to configure you know here's the API documentation and here's how we set up our HTTP request we're already able to do some pretty cool Airbnb searches so let's take a look in the Airbnb execute tool we can see that what it sent over was a location as well as a number of adults which is absolutely perfect the model was able to determine how to format that and send it over as JSON and then we got back our actual search results and now we're going to do something where you actually do need an API key because most of these you are going to need an API key so we're going to go ahead and do Brave search because you can search the web um using Brave Search API so we're going to click into this and all we have to do is once again we can see the tools here but we want to scroll down and see how you actually configure it so the first step is to go to Brave Search and get an API key you can click on this link right here and you'll be able to sign in and get 2,000 free queries and then you'll grab your API key so I'm going to log in real quick so it may send you a code to your email to verify it you'll just put in the code of course and then we're here as you can see I've only done one request so far i'm going to click on API keys on this lefth hand side and we're just going to copy this token and then we can put it into our configuration so let's walk through how we're going to do that so I'm going to come in here and add a new tool we're going to add another MCP client tool and we're going to create a new credential because we're no longer connecting to Airbnb's server we're connecting to Brave Search Server so create new credential let me just name this one real quick so we don't get confused and then of course we have to set up our command our arguments and our environments and this is where we're going to put our actual API key okay so first things first the command coming back into the Brave Search MCP server documentation we can see that we can either do Docker but what we're doing every time we're connecting to this in NN is going to be MPX so our command once again is MPX copy that paste it into the command and now let's go back and get our arguments which is always going to start off with -ashy then after that put a space we're going to connect to this MCP server which is the Brave Search and then you can see that's it in the Airbnb one we had to add the robots text in this one we didn't so everyone is going to configure a little bit differently but all you have to do is just read through the command the arguments and then the environment variables and in this case unlike the Airbnb one we actually do need an API key so what we're going to do is we're going to put in all caps brave_api_key so in the environment variables I'm going to change this to an expression just so we can actually see brave API_key and then I'm going to put an equals and then it says to put your actual API key so that's where we're going to paste in the API key from Brave Search okay so I put in my API key obviously I'm going to remove that after this video gets uploaded but now we'll hit save and we'll make sure that we're good to go cool and now we're going to actually test this out so I'm going to call this Brave Search Tools um and then before we add the actual execute tool I'm just going to ask and make sure it works so what Brave Search tools do you have and it knows of course to hit the brave search because we gave it a good name and it should be pulling back with its different functions which I believe there are two okay so we have Brave web search and we have Brave local search we also have you know of course the description of when to use each one and the actual schemas to send over so let's add a tool and make sure that it's working we're going to click on the plus we're going to add an MCP client tool we already have our Brave credential connected we're going to change the operation to execute tool and once again we're going to fill in the tool name and the parameters so for the tool name same exact thing we're going to do from AI and once again this is just telling the AI what to fill in here so we're going to call it tool we're going to give it a very brief description of the tool selected and then we are just going to enable the tool parameters to be filled out by the model automatically final thing is just to call this Brave search execute cool there we go so now we have um two functions for Airbnb two for Brave search and let's make sure that the agent can actually distinguish between which one to use so I'm going to say search the web for information about AI agents so we'll send that off looks like it's going straight to the Brave Search execute so we may have to get into the system prompt and tweak it a little bit now it's going back to the Brave Search tools to understand okay what actions can I take and now it's going back to the Brave Search execute tool and hopefully this time it'll get it right so it looks like it's going to compile an answer right now based on its search result and then we'll see exactly what happened there we go so we have looks like Oh wow it gave us nine different articles um what are AI agents by IBM we can click into here to read more so this takes us straight to IBM's article about AI agents we have one also from AWS we can click into there there's Amazon and let's go all the way to the bottom we also have one on agents from Cloudflare so let's click into here and we can see it took us exactly to the right place so super cool we didn't have to configure any sort of API documentation as you can see in Brave Search if we wanted to connect to this a different way we would have had to copy this curl command statically set up the different headers and the parameters but now with this server we can just hit it right away so let's take a look in the agent logs though because we want to see what happened so the first time it tried to go straight to the execute tool and as you can see it filled in the parameters incorrectly as well as the actual tool name because it didn't have the information from the server then it realized okay I need to go here first so that I can find out what I can do i tried to use a tool called web search as you can see earlier web search but what I needed to do was use a tool called brave web search so now on the second try back to the tool it got it right and it said brave web search it also filled out some other information like how many articles are we looking for and what's the offset so if we were to come back in here and say get me one article on dogs let's see what it would do so hopefully it's going to fill in the count as one once again it went straight to the tool and it may I was going to say if we had memory in the agent it probably would have worked because it would have seen that it used brave web search previously but there's no memory here so it did the exact same pattern and we would basically just have to prompt in this agent hey search the MCP server to get the tools before you try to execute a tool but now we can see it found one article it's called it's just Wikipedia so we can click in here and see it's dog on Wikipedia but if we click into the actual Brave search execute tool we can see that what it filled out for the query was dogs and it also knew to make the count one rather than last time it was 10 okay okay so something I want you guys to keep in mind is when you're connecting to different MCP servers the setup will always be the same where you'll look in the GitHub repository you'll look at the command which will be npx you'll look at the arguments which will be -ashy space the name of the server and then sometimes there'll be more and then after that you'll do your environment variable which is going to be a credential some sort of API key so here what we did was we asked Air Table to list its actions and in this case as you can see it has 13 different actions and within each action there's going to be different parameters to send over so when you start to scale up to some of these MCP servers that have more actions and more parameters you're going to have to be a little more specific with your prompting as you can see in this agent there's no prompting going on it's just your helpful assistant and what I'm going to try is in my Air Table I have a base called contacts a table called leads and then we have this one record so let's try to ask it to get that record okay so I'm asking it to get the records in my Air Table base called contacts in my table called leads okay so we got the error receive tool input did not match expected schema and so this really is because what has to happen here is kind of complex it has to first of all go get the bases to grab the base ID and then it has to go grab the tables in that base to get the table ID and then it has to formulate that over in a response over here as you can see if the operation was to list records it has to fill out the base ID and the table ID in order to actually get those records back so that's why it's having trouble with that and so a great example of that is within my email agent for my ultimate assistant in order to do something like label emails we have to send over the message ID of the email that we want to label and we have to send over the ID of the label to actually add to that message and in order to do those two things we first have to get all emails to get the message ID and then we have to get labels to get the label ID so it's a multi-step process and that's why this agent with minimal prompting and not a super robust parameter in here it's literally just defining by the model it's a little bit tough but if I said something like get my air table bases we'll see if it can handle that because that's more of a one-step function and it looks like it's having trouble because if we click into this actions we can see that the operation of listing bases sends over an empty array so it's having trouble being able to like send that data over okay so I'm curious though i went into my Air Table and I grabbed a base ID now I'm going to ask what tables are in this air table base ID and I gave it the base ID directly so it won't have to do that list basis function and now we can see it actually is able to call the tool hopefully so it's green and it probably put in that base ID and we'll be able to see what it's doing here but this just shows you there are still obviously some limitations and I'm hoping that Nad will make a native you know MCP server node but look what it was able to do now is it has here are the tables within the air table base ID that we provided and these are the four tables and this is correct and so now I'm asking it what records are in the air table base ID of this one and the table ID of this one and it should be able to actually use its list records tool now in order to fill in those different parameters and hopefully we can see our record back which should be Robert California so we got a successful tool execute as you can see let's wait for this to pop back into the agent and then respond to us so now we have our actual correct record robert California Saber custom AI solution all this kind of stuff and as you can see that's exactly what we're looking at within our actual Air Table base and so I just thought that that would be important to show off here how this is like really cool but it's not fully there yet so I definitely think it will get there especially if we get some more native integrations with Naden but I thought that that would be a good demo to show the way that it needs to fill in these parameters in order to get records and you know this type of example applies to tons of different things that you'll do within MCP servers so there's one more thing I want to show you guys real quick just so you will not be banging your head against the wall the way I was a couple days ago when I was trying to set up Perplexity so because you have all these different servers to choose from you may just trust that they're all going to be the exact same and they're going to work the same so when I went to set up the Plexity ask MCP server I was pretty excited command was mpx i put in my arguments i put in my environment variable which was my perplexity API key and you can see I set this up exactly as it should be my API keys in there i triple checked to make sure it was correct and then when I went to test step basically what happened was couldn't connect to the MCP server connection closed and so after digging into what this meant because I set up all these other ones as you can see in here I did these and I have more that I've connected to the reason why this one isn't working I imagine is because on the server side of things on Perplexity side of things it's either going undergoing maintenance or it's not fully published yet and it's not anything wrong with the way that you're deploying it so I just wanted to throw that out there because there may be some other ones in this big list that are not fully there yet so if you are experiencing that error and you know that you're filling out that you know MPX and the arguments and the environment variable correct then that's probably why don't spend all day on it just wanted to throw that out there because you know I had I had a moment the other day well it's been a fun journey i appreciate you guys spending all this time with me we've got one more section to close off on and this is going to be kind of just the biggest lessons that I had learned over the first six months of me building AI agents as a non-programmer let's go because everyone's talking about this kind of stuff there's a lot of hype and there's a lot of noise to cut through so the first thing I want to do is talk about the hard truths about AI agents and then I'll get into the seven lessons that I've learned over the past six months building these things so the first one is that most AI agent demos online are just that they're demos so the kind of stuff that you're going to see on LinkedIn blog posts YouTube admittedly my own videos as well these are not going to be productionready builds or productionready templates that you could immediately start to plug into your own business or try to sell to other businesses you'll see all sorts of cool use cases like web researchers salespeople travel agents just for some context these are screenshots of some of the videos I've made on YouTube this one is like a content creator this one is a human and loop calendar agent we've got a technical analyst we have a personal assistant with all its agents over here stuff like that but the reality is that all of these pretty much are just going to be you know proof of concepts they're meant to open everyone's eyes to what this kind of stuff looks like visually how you can spin this kind of stuff up the fundamentals that go into building these workflows and at least me personally my biggest motivation in making these videos is to show you guys how you can actually start to build some really cool stuff with zero programming background and so why do I give all those templates away for free it's because I want you guys to download them hit run see the data flow through and understand what's going on within each node rather than being able to sell that or use it directly in your business because everyone has different integrations everyone's going to have different system prompting and different little tweaks that they need for an automation to be actually high value for them besides that a lot of this is meant to be within a testing environment but if you push it into production and you expose it to all the different edge cases and tons of different users things are going to come through differently and the automation is going to break and what you need to think about is even these massive companies in the space like Apple Google Amazon they're also having issues with AI reliability like what we saw with Apple intelligence having to be delayed so if a company like this with a massive amount of resources is struggling with some of these productionready deployments then it's kind of unrealistic to think that a beginner or non-programmer in these tools can spin up something in a few days that would be fully production ready and by that I just mean like the stuff you see online you could easily get into nodn build something test it and get it really robust in order to sell it that's not what I'm saying at all just kind of the stuff you see online isn't there yet now the second thing is being able to understand the difference between AI agents and AI workflows and it's one of those buzzwords that everyone's kind of calling everything an agent when in reality that's not the truth so a lot of times people are calling things AI agents even if they're just sort of like an AI powered workflow now what's an AI powered workflow well as you can see right down here this is one that I had built out and this is an AI powered workflow because it's very sequential as you can see the data moves from here to here to here to here to here to here and it goes down that process every time even though there are some elements in here using AI like this basic chain and this email writing agent now this has a fixed amount of steps and it flows in this path every single time whereas something over here like an AI agent it has different tools that it's able to call and based on the input we're not sure if it's going to call each one once or it's going to call this one four times or if it's going to call this one and then this one so that's more of a non-deterministic workflow and that's when you need to use something like an AI agent the difference here is that it's choosing its own steps the process is not predefined meaning every time we throw an input we're not sure what's going to happen and what we're going to get back and then the agent also loops calls its tools it observes what happens and then it reloops and thinks about it again until it realizes okay based on the input I've done my job now I'm going to spit something out and so here's just a different visualization of you know an AI agent with an input the agent has decision and then there's an output or this AI workflow where we have an input tool one LLM call tool two tool three output where it's going to happen in that process every single time and the truth is that most problems don't require true AI agents they can simply be solved with building a workflow that is enhanced with AI and a common mistake and I think it's just because of all the hype around AI agents is that people are opting straight away to set up an agent like in this example right here let's say the input is a form trigger where we're getting a form response we're using this tool to clean up the data we're using this LLM call so it's an AI enhanced workflow to actually write a personalized email we're using this to update the CRM and then we're using this to send the email and then we get the output back as the human we could also set this up as a AI agent where we're getting the form response we're sending this agent the information and it can choose okay first I'm going to clean the data and then I'm going to come back here and think about it and then I'm going to update the CRM and then I'm going to create an email and then I'm going to send the email and then I'm going to output and respond to the human and tell it that you know we we did that job for you but because this process is pretty linear it's going to be a lot more consistent if we do a workflow it's going to be easier to debug whereas over here the agent may mess up some tool calls and do things in the wrong order so it's better to just structure it out like that and so if we start approaching using these no code tools to build AI workflows first then we can start to scale up to agents once we need more dynamic decision-m and tool calling okay but that's enough of the harsh truths let's get into the seven most important lessons I've learned over the six months of building AI agents as a non-programmer so the first one is to build workflows first and notice I don't even say AI workflows here I say workflows so over the past six months of building out these systems and hopping on discovery calls with clients where I'm trying to help them implement AI into their business processes we always start by you know having them explain to me some of their pain points and we talk through processes that are repetitive and processes that are a big time suck and a lot of times they'll come in you know thinking they need an AI agent or two and when we really start to break down this process I realize this doesn't need to be an agent this could be an AI workflow and then we break down the process even more and I'm like we don't even need AI here we just need rule-based automation and we're going to send data from A to B and just do some manipulation in the middle so let's look at this flowchart for example here we have a form submission we're going to store data we're going to route it based on if it's sales support or general we'll have that ticket or notification send an automated acknowledgement and then we'll end the process so this could be a case where we don't even need AI if we're having the forms come through and there's already predefined these three types which are either sales support or general that's a really easy rules-based automation meaning does inquiry type equal sales if yes we'll go this way and so on and so forth now maybe there's AI we need over here to actually send that auto acknowledgement or it could be as simple as an automated message that we're able to define based on the inquiry type now if this the form submission is just a a block of text and we need an AI to read it understand it and decide if it's sales support or general then we would need AI right here and that's where we would have to assess what the data looks like coming in and then what we need to do with the data so it's always important to think about do we even need AI here because a lot of times when we're trying to cut off some of that lowhanging fruit when we realize that we're doing some of this stuff too manually we don't even need AI yet we're just going to create a few workflow automations and then we can start getting more advanced with adding AI in certain steps so hopefully this graphic adds a little more color here on the left we're looking at a rule-based sort of filter and on the right we're looking at an AI powered filter so let's take a look at the left one first we have incoming data so let's just say we're routing data off based on if someone's budget is greater than 10 or less than 10 hopefully it's greater than 10 um so the filter here is is X greater than 10 if yes we'll send it up towards tool one if no we're going to send it down towards tool two and those are the only two options because those are the only two buckets that a number can fit into unless I guess it's exactly equal to 10 i probably should have made this sign a greater than or equal to but anyways you guys get the point now over here if we're looking at an AI powered sort of filter right here we're using a large language model to evaluate the incoming data answer some sort of question and then route it off based on criteria so incoming data we have to look at or sorry not we the AI is looking at what type of email this is because this uses some element of reasoning or logic or decision-m something that actually needs to be able to read the context and understand the meaning of what's coming through in order to make that decision this is where before AI we would have to have a human in the loop we'd have to have a human look at this data and analyze which way it's going to go rather than being able to write some sort of code or filter to do so because it's more than just like what words exist it's actually like when these words come together in sentences and paragraphs what does it mean so AI is able to read that and understand it and now it can decide if it's a complaint if it's billing or if it's promotion and then based on what type it is we'll send it off to a different tool to take the next action so the big takeaway here is to find the simplest approach first you may not even need an agent at all so why would you add more complexity if you don't have to and also if you start to learn the fundamentals of workflow automation data flow logic creative problem solving all that kind of stuff it's going to make it so much easier when you decide to scale up and start building out these multi-aggentic systems as far as you know sending data between workflows and understanding routing your life's going to be a lot easier so only use AI where it actually is going to provide value and also using AI and hitting an LLM isn't free typically and I mean if you're self-hosting but anyways it's not free so why would you want to spend that extra money in your workflow if you don't have to you can scale up when you need the system to decide the steps on its own when you need it to handle more complex multi-step reasoning and when you needed to control usage dynamically and I highlighted those three words because that's very like human sounding right decide reason dynamic okay moving on to lesson number two this is to wireframe before you actually get in there and start building one of the biggest mistakes that I made early on and that I see a ton of people making early on is jumping straight into their builder whatever it is and trying to get the idea in their head onto a canvas without mapping it out at all and this causes a lot of problems so the three main ones here are you you start to create these messy over complicated workflows because you haven't thought out the whole process yet you're going to get confused over where you actually need AI and where you don't and you may end up spending hours and hours debugging trying to revise um all this kind of stuff because you didn't consider either a certain integration up front or a certain functionality up front or you didn't realize that this could be broken down into different workflows and it would make the whole thing more efficient i can't tell you how many times when I started off building these kind of things that I got almost near the end and I realized I could have done this with like 20 less nodes or I could have done this in two workflows and made it a lot simpler so I end up just deleting everything and restarting so what we're looking at right here are a different Excalibraw wireframes that I had done as you can see I kind of do them differently each time there's not really a you know defined way that you need to do this correctly or correct color coding or shapes the idea here is just to get your thoughts from your head onto a paper or onto a screen and map it out before you get into your workflow builder because then in the process of mapping things out you're going to understand okay there may be some complexities here or I need all of this functionality here that I didn't think of before and this isn't really to say that there's one correct way to wireframe as you can see sometimes I do it differently um there's not like a designated schema or color type or shape type that you should be using whatever makes sense to you really but the idea here is even if you don't want to wireframe and visually map stuff out it's just about planning before you actually start building so how can you break this whole project you know a lot of people ask me I have an input and I know what that looks like and I know what I want to get over here but in between I have no idea what that looks like so how can we break this whole project into workflows and each workflow is going to have like individual tasks within that workflow so breaking it down to as many small tasks as possible makes it a lot more easy to handle makes it a lot less overwhelming than looking at the entire thing at once and thinking how do I get from A to Z and so what that looks like to either wireframe or to just write down the steps is you want to think about what triggers this workflow how does this process start and what does the data look like coming in that triggers it from there how does the data move where does it go am I able to send it down one path do I have to send it off different ways based on some conditional logic do I need some aspect of AI to take decisions based on the different types of data coming through you know what actions have to be taken where do we need rag or API calls involved where do we need to go out somewhere to get more external data to enrich the context going through to the next LLM what integrations are involved so if you ask yourself these kind of questions while you're writing down the steps or while you're wireframing out the skeleton of the build you are going to answer so many more questions especially if it comes to you know you're trying to work with a client and you're trying to understand the scope of work and understand what the solution is going to look like if you wireframe it out you're going to have questions for them that they might have not have thought of either rather than you guys agree on a scope of work and you start building this thing out and then all of a sudden there's all these complexities maybe you priced way too low maybe you don't know the functionality and the idea here is just to completely align on what you're trying to build and what the client wants or what you're trying to build and what you're actually going to do in your canvas so there's multiple use cases but the idea here is that it's just going to be so so helpful and because you're able to break down every single step and every task involved you'll have a super clear idea on if it's going to be an agent or if it's going to be a workflow because you'll see if the stuff happens in the same order or if there's an aspect of decision-m involved so when I'm approaching a client build or an internal automation that I'm trying to build for myself there is no way that more than half my time is spent in the builder pretty much upfront I'm doing all of the wireframing and understanding what this is going to look like because the goal here is that we're basically creating a step-by-step instruction manual of how to put the pieces together you should think of it as if you're putting together a Lego set so you would never grab all the pieces from your bag of Legos rip it open and just start putting them together and trying to figure out where what goes where you're always going to have right next to you that manual where you're looking at like basically the step-by-step instructions and flipping through so that's what I do with my two monitors on the left I have my wireframe on the right I have my NADN and I'm just looking back and forth and connecting the pieces where I know the integrations are supposed to be you need a clear plan otherwise you're not going to know how everything fits together it's like you were trying to you know build a 500 piece puzzle but you're not allowed to look at the actual picture of a completed puzzle and you're kind of blindly trying to put them together you can do it it can work but it's going to take a lot longer moving on to number three we have context is everything the AI is only going to be as good as the information that you provide it it is really cool the tech has come so far these AI models are super super intelligent but they're pre-trained so they can't just figure things out especially if they're operating within a specific domain where there's you know industry jargon or your specific business processes it needs your subject matter expertise in order to actually be effective it doesn't think like we do it doesn't have past experiences or intuition at least right away we can give it stuff like that it only works with the data it's given so garbage in equals garbage out so what happens if you don't provide high quality context hallucination the AI is going to start to make up stuff tool misuse it's not going to use the tools correctly and it's going to fail to achieve your tasks that you need it to do and then vague responses if it doesn't have clear direction and a clear sight of like what is the goal what am I trying to do here it is just not going to be useful it's going to be generic and it's going to sound very obviously like it came from a chat GBT so a perfect example here is the salesperson analogy let's say you hire a superstar salesman who is amazing great sales technique he understands how to build rapport closing techniques communication skills just like maybe you're taking a GPT40 model out of the box and you're plugging it into your agent now no matter how good that model is or the salesperson is there are going to be no closed sales without the subject matter expertise the business process knowledge you know understanding the pricing the features the examples all that kind of stuff so the question becomes how do you actually provide your AI agents with better context and there are three main ways here the first one is within your agent you have a system prompt so this is kind of like the fine-tuning of the model where we're training it on this is your role this is how you should behave this is what you're supposed to do then we have the sort of memory of the agent which is more of the short-term memory we're referring to right here where it can understand like the past 10 interactions it had with the user based on the input stuff like that and then the final aspect which is very very powerful is the rag aspect where it's able to go retrieve information that it doesn't currently have but it's able to understand what do I need to go get and where can I go get it so it can either hit different APIs to get real-time data or it can hit its knowledge base that hopefully is syncing dynamically and is updated so either way it's reaching outside of its system prompt to get more information from these external sources so anyways preloaded knowledge this is basically where you tell the agent its job its description its role as if on day one of a summer internship you told the intern "Okay this is what you're going to do all summer." You would define its job responsibilities you would give key facts about your business and you would give it rules and guidelines to follow and then we move on to the user specific context which is just sort of its memory based on the person it's interacting with so this reminds the AI what the customer has already asked previous troubleshooting steps that have been taken maybe information about the customer and without this user context specific memory the AI is going to ask the same questions over and over it's going to forget what's already been conversated about and it'll probably just annoy the end user with repetitive information and not very tailored information so we're able to store these past interactions so that the AI can see it before it responds and before it takes action so that it's actually more seamless like a human conversation it's more natural and efficient and then we have the aspect of the real-time context this is because there's some information that's just too dynamically changing or too large to fit within the actual system prompt of the agent so instead of relying on this predefined knowledge we can retrieve this context dynamically so maybe it's as simple as we're asking the agent what the weather is so it hits that weather API in order to go access real-time current information about the weather it pulls it back and then it responds to us or it could be you know we're asking about product information within a database so it could go hit that knowledge base what that has all of our product information and it will search through it look for what it needs and then pull it back and then respond to us with it so that's the aspect of Rag and it's super super powerful okay and this is a great segue from Rag now we're talking about vector databases and when not to use a vector database so I think something similar happened here with vector databases as the same way it happened with AI agents is that it was just some cool magic buzzword and it sounded like almost too good to be true so everyone just started overusing them and overusing the term and that's definitely something that I have to admit that I fell victim to because when I first started building this stuff I was taking all types of data no matter what it was and I was just chucking it into a vector database and chatting with it and because you know 70% of the time I was getting the right answers i was like this is so cool because it's that you know as you can see based on this illustration it is sort of like that multi-dimensional data representation it's a multi-dimensional space where the data points that you were storing are stored as these little vectors these little dots everywhere and they're not just placed in there they're placed in there intelligently because the actual context of the chunk that you're putting into the vector database it's placed based on its meaning so it's embedded based on all these numerical representations of data as you can see like right up here this is what the sort of um embedding dimensions look like and each point has meaning and so it's placed somewhere where other things are placed that are similar they're placed near them so over here we have like you know animals cat dog wolf those are placed similarly we have like fruits over here but also like tech stuff because Google's here and Apple which isn't the fruit but it's also the tech brand so you know it also kind of shifts as as you embed more vectors in there so it's just like multi-changing it's very intelligent and the agent's able to scan everything and grab back all the chunks that are relevant really quickly and like I said it's just kind of one of those buzzwords that super cool however even though it sounds cool after building these systems for a while I learned that vector databases are not always necessary for most business automation needs if your data is structured and it needs exact retrieval which a lot of times company data is very structured and you do need exact retrieval a relational database is going to be much better for that use case and you know just because it's a buzzword that's exactly what it is a buzz word so that doesn't always mean it's the best tool for the job so because in college I studied business analytics I've had a little bit of a background with like databases relational databases and analytics um but if you don't really understand the difference between structured and unstructured data and what a relational database is we'll go over it real quick structured data is basically anything that can fit into rows and columns because it has an organized sort of predictable schema so in this example we're looking at customer data and we have two different tables and this is relational data because over here we have a customer ID column so customer ID 101 is Alice and we have Alice's email right here customer ID 102 is Bob we have Bob's email and then we have a different table that is able to relate back to this customer lookup table because we match on the fields customer ID anyways this is an order table it looks like so we have order one by customer ID 101 and the product was a laptop and we may think okay well we're looking at order one who was that we can relate it back to this table based on the customer ID and then we can look up who that user was so there's a lot of use cases out there when I said you know a lot of business data is going to be structured like user profiles sales records you know invoice details all this kind of stuff you know even if it's not a relational aspect of linking two tables together if it's structured data which is going to be you know a lot of chart stuff number stuff um Excel sheets Google Sheets all that kind of stuff right and if it's structured data it's going to be a lot more efficient to query it using SQL rather than trying to vectorize it and put it into a vector database for semantic search so we said as a non-programmer if you're you know I'm sure you've been hearing SQL quering and maybe you don't understand exactly what it is this is what it is right so we're almost kind of using natural language to extract information but we could have you know half a million records in a table and so it's just a quicker way to actually filter through that stuff to get what we need so in this case let's say the SQL query we're doing is based on the user question of can you check the status of my order for a wireless mouse placed on January 10th on the left we have an orders table and this is the information we need these are the fields but there may be 500,000 records so we have to filter through it really quickly and how we would do this is we would say okay first we're going to do a select statement which just means okay we just want to see order ID order date order status because those are the only columns we care about we want to grab it from the orders table so this table and then now we set up our filters so we're just looking for only rows where product name equals wireless mouse because that's the product she bought and then um and the order date is January 10 2024 so we're just saying whenever these two conditions are met that's when we want to grab those records and actually look at them so that's an example of like what a SQL query is doing and then on the other side of things we have unstructured data which is usually the best use case for unstructured data going into a vector database based on my experience is just vectorizing a ton of text so big walls of text chunking them up throwing them into a vector database and they're placed you know based on the meaning of those chunks and then can be grabbed back semantically intelligently by the agent but anyways this is a quick visualization that I made right over here let's say we have um a ton tons of PDFs and they're just basically policy information we take that text we chunk it up so we're just splitting it based on the characters within the actual content and then each chunk becomes a ve a vector which is just one of these dots in this threedimensional space and they're placed in different areas like I said based on the actual meaning of these chunks so super cool stuff right so then when the agent wants to you know look in the vector database to pull some stuff back it basically makes a query and vectorizes that query because it will be placed near other things that are related and then it will grab like everything that's near it and that's how it pulls back if we're doing like a nearest neighbor search but don't want to get too technical here i wanted to show an example of like why that's beneficial so on the left we have product information about blankets and on the right we also have product information about blankets and we just decided on the right it's a vector database on the left it's a relational database and so let's say we hooked this up to you know a customer chatbot on a website and the customer asked I'm looking for blankets that are fuzzy now if it was a relational database the agent would be looking through and querying for you know where the description contains the word fuzzy or Maybe material is contains the word fuzzy and because there's no instances of the word fuzzy right here we may get nothing back but on the other side of things when we have the vector database because each of these vectors are placed based on the meaning of their description and their material the agent will be able to figure out okay if I go over here and I pull back these vectors these are probably fuzzy because I understand that it's cozy fleece or it's um you know handwoven cotton so that's like why there's some extra benefits there because maybe it's not a word for word match but the agent can still intelligently pull back stuff that's similar based on the actual context of the chunks and the meaning okay moving on to number five why prompting is critical for AI agents um we already talked about it a little bit I guess in the context is everything section because prompting is giving it more context but this should be a whole lesson in itself because it is truly an art and you have to find that fine line between you don't want to over prompt it and you want to minimize your token usage but you also want to give it enough information but um when people think of prompting they think of chatgbt as you can see right here where you have the luxury of talking to chat it's going to send you something back you can tell it hey make that shorter or hey make it more professional it'll send it back and you can keep going back and forth and making adjustments until you're happy with it and then you can finally accept the output but when we're dealing with AI agents and we're trying to make these systems autonomous we only have one shot at it so we're going to put in a system prompts right here that the agent will be able to look at every time there's like an input and we have to trust that the output and the actions taken before the output are going to be high quality and so like I said this is a super interesting topic and if you want to see a video where I did more of a deep dive on it you can check it out i'll tag it right here um where I talked about like this lesson but the biggest thing I learned building these agents over the past six months was reactive prompting is way better than proactive prompting admittedly when I started prompting I did it all wrong i was lazy and I would just like grab a custom GPT that I saw someone use on YouTube for you know a prompt generator that generates the most optimized prompts for your AI agents i think that that's honestly a bunch of garbage i even have created my own AI agent system prompt architect and I posted it in my community and people are using it but I wouldn't recommend to use it to be honest um nowadays I think that the best practice is to write all of your prompts from scratch by hand from the beginning and start with nothing so that's what I meant by saying reactive prompting because if you're grabbing a whole you know let's say you have 200 lines of prompts and you throw it in here into your system prompt and then you just start testing your agent you don't know what's going on and why the agent's behaving as it is you could have an issue pop up and you add a different line in the system prompt and the issue that you originally were having is fixed but now a new issues popped up and you're just going to be banging your head against the wall trying to debug this thing by taking out lines testing adding lines testing it's just going to be such a painful process when in reality what you should do is reactive prompt so start with nothing in the system prompt give your agent a tool and then test it throw in a couple queries and see if you're liking what's coming back you're going to observe that behavior and then you have the ability to correct the system prompt reactively so based on what you saw you can add in a line and say "Hey don't do that." Or you know this worked let's add another tool and add another prompt now or another line in the prompt because what we know right now is that it's working based on what we have that way if we do add a line and then we test and then we observe the behavior and we see that it broke we know exactly what broke this automation and we can pinpoint it rather than if we threw in a whole pre-generated system prompt so that's the main reason why I don't do that anymore and then it's just that loop of test reprompt test again reprompt um and what's super cool about this is because you can basically hard prompt your agent with things in the system prompt because you're able to show it examples of you know hey I just asked you this and you took these steps that was wrong don't do that again this is what you should have done and basically if you give it that example within the system prompt you're training this thing to not behave like that and you're only improving the consistency of your agent's performance so the the key elements of a strong AI agent prompt and this isn't like every single time these are the five things you should have because every agent's different for example if you're creating a context creation agent you wouldn't need a tool section really if it's not if it doesn't have any tools you' just be prompting it about its output and about its role but anyways the first one that we're talking about is role this is sort of just like telling the AI who it is so this could be as simple as like you're a legal assistant specializing in corporate law your job is to summarize contracts in simple terms and flag risky clauses something like that it gives the AI clear purpose and it helps the model understand the tone and the scope of its job without this the AI is not going to know how to frame responses and you're going to get either very random outputs or you're going to get very vague outputs that are very clearly generated by AI then of course you have the context which is going to help the agent understand you know what is actually coming in every time because essentially you're going to have different inputs every time even though the system prompt is the same so saying like this is what you're going to receive this is what you're going to do with it um this is your end goal so that helps tailor the whole process and make it more seamless as well that's one common mistake I actually see with people's prompting when they start is they forget to define what are you going to be getting every time because the agency they're going to be getting a ton of different emails or maybe a ton of different articles but it needs to know okay this information that you're throwing at me what is it why am I getting it then of course the tool instructions so when you're building a tools agent this is the most important thing in my mind yes it's good to add rules and show like when you use each thing but having an actual section for your tools is going to increase the consistency a lot at least that's what I found because this tells the AI exactly what tools are available when to use them how they work um and this is really going to ensure correct tool usage rather than the AI trying to go off of like these sort of guidelines because it's a nondeterministic workflow and um trying to trying to guess of which one will do what and um yeah have a tool section and define your tools then you've got your rules and constraints and this is going to help prevent hallucination it's going to help the agent stick to sort of like a standard operating procedure now you just have to be careful here because you don't want to say something like do all of these in this order every time because then it's like why are you even using an agent you should just be using a workflow right but anyways just setting some foundational like if X do Y if Z do A like that sort of thing and then finally examples which I think are super super important but I would never just put these in here blind i would only use examples to directly counter and directly uh correct something that's happened so what I alluded to earlier with the hard prompting so let's say you give the agent an input it calls tool one and then it gives you an output that's just incorrect completely incorrect you'd want to give it in the example you could show okay here's the input I just gave you now here's what you should have done call tool two and then call tool three and then give me the output and then it knows like okay that's what I did this is what I should have done so if I ever get an input similar to this I can just call these two tools because I know that's an example of like how it should behave so hard prompting is really really going to come in handy and not just in the examples but also just with the rest of your system prompt all right moving on to number six we have scaling agents can be a nightmare and this is all part of like one of the hard truths I talked about earlier where a lot of the stuff you see online is a great proof of concept a great MVP but if you were to try to push this into production in your own business you're going to notice it's not there yet because when you first build out these AI agents everything can seem to work fine it's a demo it's cool it really opens your eyes to you know the capabilities but it hasn't usually gone under that rigorous testing and evaluation and setting up these guard rails um and all of that you know continuous monitoring that you need to do to evaluate its performance before you can push it out to all you know 100 users that you want to eventually push it out to you know on a single user level if you have a few hallucinations every once in a while it's not a huge deal but as you scale the use case you're just going to be scaling hallucinations and scaling problems and scaling all these failures so that's where it gets tricky you can start to get retrieval issues as your database grows it's going to be harder for your agent to cut through the noise and grab what it needs so you're going to get more you know inaccuracies you're going to have some different performance bottlenecks and the agents you know latency is going to increase you're going to start to get inconsistent outputs and you're going to experience all those edge cases that you hadn't thought of when you were the only one testing because you know there's just an infinite amount of scenarios that an agent could be exposed to so a good little lesson learned here would be to scale vertically before you start to try to scale horizontally which um we'll break that down and I made this little visualization so we can see what that means so let's say we want to help this business with their customer support sales inventory and HR management rather than building out little building blocks of tools within each of these processes let's try to perfect one area first vertically and then we'll start to move across the organization and look at doing other things and scaling to more users so because we can focus on this one area we can set up a knowledge base and set up like the data sources and build that automated pipeline we can set up how this kind of stuff gets organized with our sub workflows we can set up you know an actual agent that's going to have different tool calls and within this process what we have over here are evaluations monitoring performance and then setting up those guard rails because we're testing throughout this you know ecosystem vertically and and getting exposure to all these different edge cases before we try to move into other you know areas where we need to basically start this whole process again we want to have done the endto-end system first understand you know the problems that may arise how to make it robust and how to evaluate and you know iterate over it before we start making more automations and so like I alluded to earlier if you try to start scaling horizontally too quick before you've done all these testing you are going to notice that hallucinations are going to increase your retrieval quality is going to drop as more users users come in the agent's handling more memory it's handling more um more knowledge in its database to try to cut through your response times are going to slow and then you're just going to get more inconsistent results and so you can do things like you know setting strict retrieval rules and guard rails you could do stuff like segmenting your data into different vector databases based on the context or different name spaces or different you know relational databases you could use stuff like um asynchronous processing or caching in order to improve that response time and then you could also look at doing stuff like only you know um having an agent evaluate and making sure that the confidence on these responses are above a certain threshold otherwise we'll you know request human help and not actually respond ourselves or the agent wouldn't respond itself so the seventh one is that no code tools like nadn have their limits they're super great they're really empowering non-developers to get in here and spin up some really cool automations and it's really like the barrier to entry is so low you can learn how to build this stuff really quickly which is why I think it's awesome and you know it's the main tool that I use um personally and also within my agency but when you start to get into what we just talked about with lesson number six scaling and making these things really robust and production ready you may notice some limits with no code tools like NE now the reason I got into building stuff like this is because you know obviously non-programmer and it has a really nice drag and drop interface where you can build these workflows very visually without writing scripts so Nen is you know basically open source because you can self-host it the code is accessible um and it's built on top of Langchain which is just like a basically a language that helps connect to different things and create these like agents um and because of that it's just wrapped up really pretty for us in a graphical user interface where we can interact with it in that drag and drop way without having to get in there and hands- on keyboard write code and it has a ton of pre-built integrations as you can see right here connect anything to everything um I think there's like a thousand integrations right here and all of these different integrations are API calls they're just wrapped up once again in a pretty way for us in a user interface and like I talked about earlier when I started I didn't even know what an API was so the barrier entry was super low i was able to configure this stuff easily and besides these built-in integrations they have these really simple tool calls so development is really fast with building workflows compared to traditional coding um the modularity aspect because you can basically build out a workflow you can save that as a tool and then you can call that tool from any other workflow you want so once you build out a function once you've basically got it there forever and it can be reused which is really cool and then my favorite aspect about n and the visual interface is the visual debugging because rather than having 300 lines of code and you know you're getting errors in line 12 and line 45 you're going to see it's going to be red or it's going to be green and you know if it's green you're good and if you see red there's an error so you know exactly usually you know exactly where the problem's coming from and you're able to get in there look at the execution data and get to the bottom of it pretty quick but overall these no code platforms are great they allow us to connect APIs we can connect to pretty much anything because we have an HTTP request within NADN um they're going to be really really good for rulebased decision-m like super solid um if we're creating workflows that's just going to do some data manipulation and transferring data around you know your typical ETL based on the structured logic super robust you can make some really really awesome basic AI powered workflows where you're integrating different LLMs you've got all the different chat models basically that you can connect to um for you know different classification or content generation or outreach anything like that um your multi-agentic workflows because like I said earlier you have the aspect of creating different tools um as workflows as well as creating agents as workflows that you can call on from multiple agents so you can really get into some cool multi-agentic inception thing going on with with agents calling agents calling agents um and passing data between different workflows and then just the orchestration of AI services coordinating multiple AI tools within a single process so that's the kind of stuff that NN is going to be super super good at and now the hidden limitations of these noode AI workflow/ aent builders let's get into it now in my opinion this stuff really just comes down to when we're trying to get into like enterprise solutions at scale with a ton of users and a ton of authentication and a ton of data because if you're building out your own internal automations you're going to be solid like there's not going to be limitations if you're building out you know proof of concepts and MVPs um YouTube videos creating content like you can do it all I would say but when you need to start processing you know massive data sets that are going to scale to thousands or millions of users your performance can slow down or even fail and that's maybe where you'd want to rely on some custom code backend to actually spin up these more robust functionalities in these agentic systems tool calling is really really critical the agent needs to be able to decide which one to use and do it efficiently and like I talked about Nen is built on top of lang chain it provides a structured way to call AI models and APIs but it lacks some of that flexibility of writing that really custom code within there for complex decision-m and then when it comes to authentication at scale it can struggle with like secure large scale authentication and data access control obviously you can hook up to external systems to help with some of that processing but when it comes to maybe like handling OOTH tokens and all these encrypted credentials and session management not that it's not doable with NN um it just seems like getting in there with some custom code it could be quicker and more robust and also that's coming from someone who doesn't actually do that myself um just some stuff I've heard and you know with what's going on within the agency now ultimately it seems like if you are delivering this stuff at scale for some big clients um the best approach is going to be a mix a hybrid of no code and custom code because you can use NN to spin up stuff really quick you've got that modularity you can orchestrate automate you know connect to anything you need but then working in every once in a while some custom Python script for some of that complex you know large scale processing and data handling and when you combine these two together you're going to be able to spin some stuff up a lot quicker and that's going to be pretty robust and powerful thanks so much for making it all the way to the end of this course i know it's pretty massive but I wanted to pack it with a ton of value and hopefully you guys did find it valuable as well and you feel a lot more comfortable right now building AI workflows and AI agents than when you started this course if you enjoyed or if you learned something new please give it a like and a subscribe it definitely helps me out a ton um like I said super happy that you made it to the end of the course and if you did and if you appreciate my teaching style or you want to even go more in depth than this course right here then definitely check out my paid community the link for that is down in the description it's a community full of people who are learning how to build and are building a automations using naden and a lot of them are coming from no code backgrounds as well so great place to get some questions answered brainstorm people collaborate on projects stuff like that and we also have five live calls per week so make sure you jump in there and meet other people in the space as well as make sure you're not getting stuck and you can get your questions answered on a call like I said would be great to see you in the community but anyways thanks so much for making it to the very end of this huge course appreciate you guys and I will see you in the next video thanks so much everyone 
